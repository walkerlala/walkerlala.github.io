<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Yubin's Blog</title>
        <description>
            The Fastdrivers Organization.
        </description>
        <link>http://fastdrivers.org/</link>
        <atom:link href="http://fastdrivers.org/feed.xml" rel="self" type="application/rss+xml" />
        <!--
        <pubDate>Mon, 12 Mar 2018 02:05:09 +0800</pubDate>
        <lastBuildDate>Mon, 12 Mar 2018 02:05:09 +0800</lastBuildDate>
        -->
        <copyright> Copyright Â© Yubin Ruan </copyright>
        <webMaster>Yubin Ruan, ablacktshirt@gmail.com </webMaster>
        <managingEditor>Yubin Ruan, ablacktshirt@gmail.com </managingEditor>
        <generator>By-hand</generator>

        <item>
            <title>A Few Words About Concurrency (Part II)</title>
            <description> In the first one of this series I wrote about locking. In this essay, I would like to talk about memory model.  </description>
            <pubDate>Mon, 08 May 2017 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/A-Few-Words-About-Concurrency-II.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/A-Few-Words-About-Concurrency-II.html</guid>
        </item>
        <item>
            <title>A Few Words About Concurrency (Part I)</title>
            <description> Concurrency has always been a big topic ever since the 1960s. I learned about this topic from my Operating System courses one year ago but never feel confident to tell any other people that I really understand it. I do have some insights into this topic and have read a few books/articles related to it. However, the more I read and know about it, the more it seems to be left unknown. I suppose this is probably the reason for the old saying "the consequence of knowing too much".  Nevertheless, I want to summarize and present some \"cases\" that I find really interesting these days as I read and think. I will try to show you how we can  get into the "dark" side of those techniques, with some necessary theories. Specifically, in this essay, I would try show you how to implement a lock in the kernel, and what techniques and theories are required.</description>
            <pubDate>Tue, 25 April 2017 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/A-Few-Words-About-Concurrency-I.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/A-Few-Words-About-Concurrency-I.html</guid>
        </item>
        <item>
            <title>What If Two Processes Write to the Same File Simultaneously</title>
            <description> What if your open the same file in several processes and you write to it simultaneously? What is the result? Do these process share the same file offset when they try to write? What about writing to the same file in the same process using different threads?(Take Linux for example.)</description>
            <pubDate>Fri, 17 February 2017 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/what-if-write-to-the-same-file.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/what-if-write-to-the-same-file.html</guid>
        </item>
        <item>
            <title>Thinking cross entropy</title>
            <description>I discover that the concept of cross entropy is used widely than many people think. In this essay, I want to talk about some of my thoughts about cross entropy.</description>
            <pubDate>Fri, 30 December 2016 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/thinking-cross-entropy.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/thinking-cross-entropy.html</guid>
        </item>
        <item>
            <title>Gradient descent of 4 Layers FNN</title>
            <description>Derivation of gradient descent of a 4 layers FNN for my Machine Learning course</description>
            <pubDate>Fri, 30 December 2016 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/NN-four-layer-gradient-descent.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/NN-four-layer-gradient-descent.html</guid>
        </item>
        <item>
            <title>A Recurrent Neural Network Tutorial</title>
            <description>What exactly is Recurrent Neural Network(RNN) and how to use/implement is</description>
            <pubDate>Mon, 12 December 2016 00:00:00 GMT</pubDate>
            <link>http://fastdrivers.org/archive/rnn-explain-impl.html</link>
            <guid isPermaLink="true">http://fastdrivers.org/archive/rnn-explain-impl.html</guid>
        </item>
    </channel>
</rss>
