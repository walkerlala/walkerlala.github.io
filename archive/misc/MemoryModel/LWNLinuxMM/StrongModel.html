<!-- DO NOT HAND EDIT. -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/html4/loose.dtd">
        <html>
        <head><title>A Strong Formal Model of Linux-Kernel Memory Ordering[LWN.net]</title>
        <meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
	<META NAME="robots" CONTENT="noindex">
        <link rel="icon" href="/images/favicon.png" type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="http://lwn.net/headlines/newrss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="http://lwn.net/headlines/418853/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        

        </head>
        <body bgcolor="#ffffff" link="Blue" VLINK="Green" alink="Green">
<h1>A Strong Formal Model of Linux-Kernel Memory Ordering</h1>
<table class="Page">
<tr>
<td><table><tr>
<td class="MidColumn">
           <div class="Printable">
<div class="ArticleText">
<div class="GAByline">
           <p>January 24, 2017</p>
           <p>This article was contributed by Jade Alglave,
	   Paul E. McKenney, Alan Stern, Luc Maranget, and Andrea Parri</p>
           </div>


<h2>Introduction</h2>

<p>
This article is organized as follows, with the intended audience
for each section in parentheses:

<ol>
<li>	<a href="#Introduction to the Linux-Kernel Memory Models">
	Introduction to the Linux-Kernel Memory Models</a>
	(people interested in understanding the memory model).
<li>	<a href="#Design of the Strong Model">Design of the Strong Model</a>
	(people interested in the ideas behind the formal memory model).
<li>	<a href="#Adjustments for the DEC Alpha">Adjustments for the
	DEC Alpha</a>
	(people interested in how the memory model had to be changed to
	match the Alpha architecture).
<li>	<a href="#Adjustments for ARM">Adjustments for ARM</a>
	(people interested in how the memory model had to be changed to
	match the ARM architecture).
<li>	<a href="#Adjustments for other architectures">Adjustments for
	other architectures</a>
	(people interested in the future evolution of the memory model).
<li>	<a href="#Strong-Model Bell File">Strong-Model Bell File</a>
	(masochists and other people interested in a deep understanding
	of the Linux-kernel memory model).
<li>	<a href="#Strong-Model Cat File">Strong-Model Cat File</a>
	(masochists and other people interested in a deep understanding
	of the Linux-kernel memory model).
<li>	(More TBD.)
</ol>

<p>
This is followed by the inevitable
<a href="#Answers to Quick Quizzes">answers to the quick quizzes</a>.

<h2><a name="Introduction to the Linux-Kernel Memory Models">
Introduction to the Linux-Kernel Memory Models</a></h2>

<p>
This section is mostly concerned with the strong memory model.
The weak (but still fairly strong as these things go)
model is derived from the strong one by relaxing several of the
less-important constraints.

<p>
The strong Linux-kernel memory model started out as an operational
model, based on the PPCMEM model for PowerPC as presented in
two papers (&ldquo;Understanding POWER Multiprocessors&rdquo; 
<a href="http://www.cl.cam.ac.uk/~pes20/ppc-supplemental/pldi105-sarkar.pdf">[pdf]</a>
and &ldquo;Synchronising C/C++ and POWER&rdquo;
<a href="http://www.cl.cam.ac.uk/~pes20/cppppc-supplemental/pldi010-sarkar.pdf">[pdf]</a>)
by Susmit Sarkar, Peter Sewell, and others.
Our model was a modified version of theirs, changed to take into account
the requirements of the kernel.
<tt>herd</tt>-style Bell and Cat files
were developed as a formal axiomatization of this model.
The model then was modified to handle the peculiarities of the DEC Alpha,
and the Cat file was modified accordingly.

<p>
Some time later we incorporated ideas from the
Flowing and POP models for ARM, as presented in &ldquo;Modelling the
ARMv8 Architecture, Operationally: Concurrency and ISA&rdquo;
<a href="http://www.cl.cam.ac.uk/~pes20/popl16-armv8/top.pdf">[pdf]</a>
by Shaked Flur, Peter Sewell, and others
(together with the supplementary material
<a href="http://www.cl.cam.ac.uk/~sf502/popl16/model_full.pdf">[pdf]</a>).
This design proved to be so different from the PowerPC-oriented
operational model that there was no reasonable way to unify the two.
Instead, we abandoned our operational model and concentrated on the
formal <tt>herd</tt> model, weakening it so that it would accept litmus
tests allowed by the ARM architecture as defined by the Flowing model.
Nevertheless, the original operational model offers a very good basis
for understanding our formal model and so we present it here,
along with a discussion of the changes needed to adapt it to Alpha and
the issues raised by ARM.

<p>
The operational model divides a computer system into two parts:
the processors (or CPUs), which execute instructions,
and the memory subsystem,
which propagates information about writes and barriers among the
CPUs and is also responsible for determining the coherence order.
When a CPU executes a write or certain kinds of barriers,
it tells the memory subsytem.
And when a CPU needs to load a value from memory or cache to execute a read,
it asks the memory subsystem to provide the value.

<h3>The Processor Subsystem</h3>

<p>
Although the underlying operations involved in executing an instruction
on a modern CPU can be quite complicated,
nevertheless there always comes a point where the CPU has finished
evaluating all of the instruction's inputs and outputs and commits
itself irrevocably to using those values.
Conceptually, each instruction that gets executed is <i>committed</i>
at a single, precise moment in time.
(Instructions that don't get executed, such as those started speculatively
in what turns out to be the unused arm of a conditional branch,
are not committed.)

<p>
Instructions may commit in any order and at any rate, subject to certain
constraints.
For example, an instruction controlled by a conditional branch can't
be committed before the branch is, because until that time
the CPU hasn't decided for certain whether the branch will be taken.
The full set of constraints on the order of instruction execution
(which is almost but not quite the same as comittal, differing only
for read instructions) is listed
<a href="#Program Order Requirements">below</a>.
For instructions involving only quantities that are local to the CPU,
such as those computing register-to-register arithmetic,
that's all there is to it:
The CPU carries out the operations required
by the instruction when the inputs are available,
eventually commits to the result, and moves on.
But some instructions need more.
In particular, some require the CPU to communicate with the memory subsystem.

<p>
Writes and memory barriers are the simplest case.
When a CPU commits a write instruction, it tells the memory subsystem
the target address of the write and the value to be stored there.
It can't do this before the write commits, because once the information
has been sent to the memory subsystem there's no way to take it back.
Similarly, when a CPU commits one of the barriers that affect
write-propagation order, it informs the memory subsystem, which then
uses that information to control the way writes get propagated.

<p><a name="Quick Quiz 1"><b>Quick Quiz 1</b>:</a>
But couldn't a CPU designer create a memory subsystem that did
allow writes to be taken back?
<br><a href="#qq1answer">Answer</a>

<p>
Reads are more complicated.
When a CPU starts to execute a read instruction,
it first has to calculate the target address, which may involve
adding index or base register values to a constant offset.
It then checks to see if the most recent write (in program order)
to that target address is still uncommitted;
if it is then the CPU takes the value to be stored by that write
and uses it as the value for the read.
This is called <i>store forwarding</i>, and it is a form of out-of-order
execution (the read can be committed before the program-earlier write).
But if there was no prior write to that address or the most recent one
has already been committed, then the CPU has to
ask the memory subsystem to retrieve the value at the target address.
Either way, we say that the read is <i>satisfied</i>,
and this also takes place at a precise moment in time.
A read instruction cannot commit until it has been satisfied.

<p>
There's more to it than that, however.
The act of satisfying a read is not irrevocable.
It may turn out, for example, that the values used in calculating the
target address were themselves not yet committed and hence are still
subject to change.
If that happens, the read instruction will need to be <i>restarted</i>:
The target address must be recalculated and the read must be satisfied again.
This can happen several times before the read is committed.
In fact, it can even happen several times without the read ever being
committed, if the read was started speculatively and then abandoned.
Of course, once a read has been committed then it can no longer be restarted.

<p>
Thus, a CPU carries out a read instruction by satisfying it
(perhaps more than once) and eventually committing it.
For most other instruction types, execution only involves committing the
instruction, but there is one exception.
A strong memory barrier (such as <tt>smp_mb()</tt>)
is not finished when it commits.
Instead, the CPU has to wait for the strong barrier to be
<i>acknowledged</i> by the memory subsystem.
This doesn't happen until the memory subsystem has propagated the
barrier to all the other CPUs in the system,
and the CPU is not allowed to begin executing any instructions that
come after the strong barrier in program order until then.
This is what makes these barriers so strong (and so slow!).

<p><a name="Quick Quiz 2"><b>Quick Quiz 2</b>:</a>
Why can't CPU designers use speculation to hide the slowness of
strong barriers?
<br><a href="#qq2answer">Answer</a>

<h3>The Memory Subsystem</h3>

<p>
The memory subsystem accepts write, read, and barrier requests from the CPUs.
It propagates the write and barrier requests to all the CPUs in the system
and provides responses to read requests.
It also determines the coherence order of all writes to each variable
and provides a mechanism for making certain operations atomic.

<p>
Handling read requests is quite simple.
When a CPU submits a read request for a specified target address,
the memory subsystem finds the latest write
(in the target address's coherence order) that has propagated to the
CPU and returns the value stored by that write.
This means, among other things, that a CPU cannot read from a write
until the write has propagated to that CPU, as you would expect.
It's important that the write be the coherence-latest;
otherwise the system could violate the read-read
<a href="LinuxMMModel.html#coherence rules">coherence rule</a>
if a po- (program order-) earlier read had already read from
the coherence-latest write.

<p>
Accepting a write request from a CPU is a little more complicated.
To begin with, the memory subsystem has to decide where the write
will fit into the coherence order for the target address.
Specifically, it must ensure that the write is assigned to a position
in the coherence order that is after any other writes to the same address
which have already propagated to that CPU.
This is necessary because the CPU might already have executed a po-earlier
instruction which read from one of those
other writes; if the new write were to be come before that other write
in the coherence order then it would violate the read-write
coherence rule.

<p>
In addition, the memory subsystem has to
propagate the write to all the other CPUs
(a write or barrier is considered to &ldquo;propagate&rdquo; to its own CPU
at the time it is committed) and to the coherence point.
The <i>coherence point</i> is a notional place in the system where
writes and barriers get sent,
in much the same way that they are propagated to CPUs.
If you like, you can think of the coherence point as being the place
where writes finally pass out of all the internal caches and buffers,
down into memory for storage.
The key aspect of the coherence point is that different writes
to the same address arrive at the coherence point in their coherence order.
In effect, the order of their arrival at the coherence point <i>defines</i>
the coherence order.
Whether this is because the memory subsystem first decides on a
coherence order and then sends writes to the coherence point in that
order, or because it sends writes willy-nilly to the coherence point
and then uses the order of their arrival as the coherence order,
doesn't matter.
What does matter is that once a write has reached the coherence point,
its position in the coherence order is fixed; it is impossible for any
future writes to be assigned an earlier position.

<p><a name="Quick Quiz 3"><b>Quick Quiz 3</b>:</a>
Isn't this single coherence point a huge bottleneck on large systems?
<br><a href="#qq3answer">Answer</a>

<p>
This fact is crucial for atomic operations.
The memory model represents an atomic read-modify-write (RMW) operation as
two events: a read <tt>R</tt> followed by a write <tt>W</tt>
(or conditionally followed by a write, for operations like <tt>cmpxchg()</tt>).
What makes the operation atomic is that no other writes to that address,
from any CPU, are allowed to intervene between <tt>R</tt> and <tt>W</tt>.
In other words, the memory subsystem guarantees that the write immediately
preceding <tt>W</tt> in the coherence order is the write which <tt>R</tt>
reads from.
The operational model specifies that it does this, in part, by arranging for
<tt>W</tt> to reach the coherence point at the time when it commits
(as opposed to some arbitrarily later time, like an ordinary write).
As a result, no future write will be able to sneak in before <tt>W</tt>
in the coherence order, and avoiding such &ldquo;sneak writes&rdquo;
is what enforces the atomic property.

<p><a name="Quick Quiz 4"><b>Quick Quiz 4</b>:</a>
But how could the system possibly prevent some other write on some other
CPU from taking place between the time the RMW's read and write execute?
Is there some Big System Lock implemented in hardware that will totally
destroy scalability???
<br><a href="#qq4answer">Answer</a>

<p>
Other than these requirements and the constraints imposed by memory barriers,
the order in which writes are propagated to CPUs and reach the coherence point
is unrestricted.
In particular, these orders don't have to bear any resemblance to the order
in which the write requests were originally sent to the memory subsystem.
It's entirely possible for two CPUs to write to the same address at
different times and have the second write come before the first in the
coherence order or be propagated before the first to a third CPU.

<h3><a name="Memory barriers">Memory barriers</a></h3>

<p>
The kernel memory model has two broad categories of memory barriers:
those whose effects are entirely local to a single CPU and those that
interact with the memory subsystem.
Barriers in the first category can only constrain the order in which
the CPU executes instructions, whereas those in the second group
can also affect the order of propagation of writes.

<p>
Associated with each memory barrier are two sets of instructions,
called the barrier's <i>pre-set</i> and its <i>post-set</i>.
These sets vary according to the type of barrier, but all barriers
other than the three &ldquo;read-dependency&rdquo; barriers
share these features:

<ul>
<li>	A barrier cannot commit until every instruction in its pre-set
	has committed, and
<li>	An instruction in the barrier's post-set cannot commit or be
	satisfied until the barrier has committed.
</ul>

<p>
The various barriers included in this memory model,
and their types and pre- and post-sets, are listed
in the following table in order of increasing strength.
(Contrary to what you might expect, <tt>smp_load_acquire()</tt>,
<tt>rcu_dereference()</tt>, and <tt>lockless_dereference()</tt>
are represented in the memory subsystem as a read request followed by a
separate barrier request.
Similarly, <tt>smp_store_release()</tt> and <tt>rcu_assign_pointer()</tt>
are represented as a barrier request followed by a separate write request.
Thus, each requires the CPU to issue two requests to the memory subsystem.)

<a name="barrier-properties">
<table cellpadding="3" border=3 align="center"><tbody>
<tr>	<th>Barrier</th>
	<th>Type</th>
	<th>Pre-set</th>
	<th>Post-set</th>
</tr>
<tr>	<th><pre>rcu_dereference(),
lockless_dereference()</pre></th>
	<td>Read-dependency</td>
	<td>itself</td>
	<td>all po-later reads with a dependency from this read</td>
</tr>
<tr>	<th><pre>smp_read_barrier_depends()</tt></th>
	<td>Read-dependency</td>
	<td>all po-earlier reads</td>
	<td>all po-later reads with a dependency from a po-earlier read</td>
</tr>
<tr>	<th><tt>smp_load_acquire()</tt></th>
	<td>Execution-order</td>
	<td>itself</td>
	<td>all po-later memory accesses</td>
</tr>
<tr>	<th><tt>smp_rmb()</tt></th>
	<td>Execution-order</td>
	<td>all po-earlier reads</td>
	<td>all po-later reads</td>
</tr>
<tr>	<th><tt>smp_wmb()</tt></th>
	<td>B-cumulative</td>
	<td>all po-earlier writes</td>
	<td>all po-later writes (*)</td>
</tr>
<tr>	<th><pre>smp_store_release(),
rcu_assign_pointer()</pre></th>
	<td>A-cumulative (**)</td>
	<td>all po-earlier memory accesses (*)</td>
	<td>itself and members of its release sequence</td>
</tr>
<tr>	<th><pre>smp_mb(),
synchronize_rcu()</pre></th>
	<td>Strong (A- and B-cumulative)</td>
	<td>all po-earlier memory accesses (*)</td>
	<td>all po-later memory accesses (*)</td>
</tr>
</tbody></table>
</a>

(*) as modified by the cumulativity requirements described below.<br>
(**) also B-cumulative when read by a load-acquire, as described
<a href="#release-acquire-is-B-cumulative">here</a>.

<p><a name="Quick Quiz 5"><b>Quick Quiz 5</b>:</a>
The terms &ldquo;A-cumulativity&rdquo; and &ldquo;B-cumulativity&rdquo;
aren't particularly mnemonic, are they?
<br><a href="#qq5answer">Answer</a>

<p>
The read-dependency and execution-order barriers are purely local to their
own CPU.
(In fact, in this model the read-dependency barriers have no effect at all.
We will see later that they matter only when the model is altered to
work with the DEC Alpha.)
However, when the CPU commits one of the others,
collectively referred to as &ldquo;propagation-order&rdquo; barriers,
it informs the memory subsystem about the barrier, and the memory subsystem
propagates the barrier to all the other CPUs.
This is where the barrier's propagation ordering effects come into play:

<ul>
<li>	The memory subsystem will not propagate a barrier to a CPU until
	all the writes in the barrier's pre-set have been propagated to
	that CPU.
<li>	The memory subsystem will not propagate a write in a barrier's
	post-set to a CPU until the barrier has been propagated to that CPU.
</ul>

The same is true for the order in which writes and barriers reach the
coherence point; in this respect barriers treat the coherence point
much like another CPU.
In addition, the memory subsystem does not <i>acknowledge</i> a strong barrier
until the barrier has been propagated to every CPU
and has reached the coherence point
(and as mentioned above,
the CPU will not satisfy or commit any instructions po-after a strong
barrier until the barrier has been acknowledged).

<p>
<a name="cumulativity">The propagation-order barriers enjoy varying degrees
of cumulativity.
This means that the barriers affect the order of propagations, not just
of writes issued by the barrier's own CPU, but also of writes issued
by other CPUs.
In effect, the barriers' pre- and post-sets are enlarged:

<ul>
<li>	The pre-set of an <i>A-cumulative</i> barrier includes
	all writes that have propagated to the barrier's CPU before
	the barrier is committed.
<li>	The post-set of a <i>B-cumulative</i> barrier includes
	all memory accesses on another CPU that execute after the barrier has
	propagated to that CPU.
</ul>
</a>

<p><a name="Quick Quiz 6"><b>Quick Quiz 6</b>:</a>
By symmetry, shouldn't a B-cumulative barrier's post-set include all writes
that propagate to the barrier's CPU after the barrier is committed?
<br><a href="#qq6answer">Answer</a>

<p>
The memory model adopts the idea of
<a name="release sequences">release sequences</a>
(slightly altered) from C11.
For any store-release instruction (such as <tt>smp_store_release()</tt>,
<tt>rcu_assign_pointer()</tt>, or <tt>xchg_release()</tt>),
the <i>release sequence</i> headed
by that instruction includes the instruction itself as well as
all po-later writes to the same address.
The release sequence also includes, recursively,
any atomic RMW instruction accessing the same address,
on any CPU, that reads from a write in the release sequence.
Every write in the release sequence belongs to the
associated barrier's post-set.

<p>
Some examples of cumulativity and release sequences are presented
<a href="#cumulativity-examples">below</a>.

<p>
To see how this works out in practice, consider this litmus test
(an example of the &ldquo;Store-Buffering&rdquo; pattern):

<blockquote>
<a id="litmus1" href="C-SB+o-mb-o+o-mb-o.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>
<pre>
  1 C C-SB+o-mb-o+o-mb-o.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   int r1;
  9
 10   WRITE_ONCE(*x, 1);
 11   smp_mb();
 12   r1 = READ_ONCE(*y);
 13 }
 14
 15 P1(int *x, int *y)
 16 {
 17   int r2;
 18
 19   WRITE_ONCE(*y, 1);
 20   smp_mb();
 21   r2 = READ_ONCE(*x);
 22 }
 23
 24 exists
 25 (0:r1=0 /\ 1:r2=0)
</pre>
</blockquote>

Using the features of the memory model already discussed, we can
show that this test's &ldquo;exists&rdquo; condition will never be satisfied.

<p>
When the test is executed, one of the two memory barriers must be
acknowledged before or at the same time as the other
(they are both strong barriers).
Suppose the barrier in P0 gets acknowledged first.
Then the following events have to occur in the order listed, for the
reasons shown:

<ul>
<li>	P0's write to <tt>x</tt> propagates to P1 before P0's memory barrier
	does, because the write is in the barrier's pre-set.
<li>	P0's memory barrier propagates to P1 before it is acknowledged,
	because a strong memory barrier is not acknowledged until
	it has propagated to every CPU.
<li>	P0's memory barrier is acknowledged before or at the same time as
	P1's barrier, by assumption.
<li>	P1's read of <tt>x</tt> is satisfied after P1's barrier is
	acknowledged, because the read comes after the barrier
	in program order.
</ul>

Hence the write to <tt>x</tt> propagates to P1 before P1's read is
satisfied.
Since that write is the last one in the coherence order for <tt>x</tt>,
it is the one that will be used to satisfy the read.
Therefore <tt>r2</tt> will end up equal to 1, not 0.
The opposite case (where P1's barrier is acknowledged first) is
symmetrical.
In neither case is it possible for <tt>r1</tt> and <tt>r2</tt> both to
be equal to 0.

<p>
The strong model agrees:

<blockquote>
<a id="litmus1" href="C-SB+o-mb-o+o-mb-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>
<pre>
 1 Test C-SB+o-mb-o+o-mb-o Allowed
 2 States 3
 3 0:r1=0; 1:r2=1;
 4 0:r1=1; 1:r2=0;
 5 0:r1=1; 1:r2=1;
 6 No
 7 Witnesses
 8 Positive: 0 Negative: 3
 9 Condition exists (0:r1=0 /\ 1:r2=0)
10 Observation C-SB+o-mb-o+o-mb-o Never 0 3
11 Hash=a61f698662bb72c2ed1755812580d385
</pre>
</blockquote>

<h3>Processor-Local Ordering Requirements</h3>

<p>
While executing instructions, a CPU observes various ordering requirements.
Some of these are obvious (an instruction can't be executed before the CPU
knows how or whether to execute it, as mentioned
<a href="LinuxMMModel.html#dependencies">earlier</a>).
Others are less obvious but are necessary to avoid violating the four
<a href="LinuxMMModel.html#coherence rules">coherence rules</a>.

<p>
The first and simplest requirement is that a CPU will not commit
an instruction that is po-after a conditional branch
until the branch itself is committed.
At the hardware level this is true even for trivial conditionals;
CPUs do not recognize that expressions like &ldquo;<tt>x == x</tt>&rdquo;
must always hold.
The situation in higher-level languages is not as simple, because
optimizing compilers <i>do</i> recognize such things.
They will happily eliminate the unnecessary test and conditional jump
from the object code entirely,
leaving no ordering requirement for the CPU to obey at runtime.

<p><a name="Quick Quiz 7"><b>Quick Quiz 7</b>:</a>
Given the steadily increasing number of transistors, why couldn't a CPU
analyze code to detect at least some classes of &ldquo;<tt>x == x</tt>&rdquo;
comparisons?
<br><a href="#qq7answer">Answer</a>

<p>
Compilers also realize that code following the end of an
&ldquo;<tt>if (...) then {...} else {...}</tt>&rdquo; statement
will be executed regardless of which branch is taken,
and they are free to move such code up before the start of the
&ldquo;<tt>if</tt>&rdquo; in the absence of any reason not to.
Therefore our memory model applies this ordering requirement
only to the instructions
that are within the &ldquo;<tt>then {...} else {...}</tt>&rdquo;
branches of the conditional, i.e., those that are directly under its control.
These instructions cannot be committed before the instructions that compute
the &ldquo;<tt>if</tt>&rdquo; condition and decide whether to take the branch.

<p>
The memory model has a weakness in this area.
If both branches of an &ldquo;<tt>if</tt>&rdquo; statement
write the same value to the same variable,
an optimizing compiler may replace both writes with a single write
that is executed before the &ldquo;<tt>if</tt>&rdquo; statement branches.
This resulting single write then would not be subject to the ordering
requirement at runtime, even though the model says it should be.

<p>
(We must emphasize that this requirement applies only to <i>committing</i>
instructions.  Reads following a conditional branch can be <i>satisfied</i>
before the branch is committed, and they often are.
Even if a read belongs to the arm of the branch that is ultimately not taken,
the CPU may speculatively start executing the read before it knows
which way the branch will go.
Although all architectures have barriers that can prevent speculative reads,
such as the <tt>isb</tt> and <tt>isync</tt> instructions on ARM and PowerPC,
respectively, the Linux kernel does not include any facility
specifically meant for this purpose.
If you really want to prevent a read in a conditional branch
from being satisfied speculatively, you can always use <tt>smp_rmb()</tt>.)

<p>
The preceding requirement was about <i>whether</i> a CPU should execute
an instruction.
The next ordering requirement is about <i>how</i> an instruction should
be executed.
If an instruction has a
<a href="LinuxMMModel.html#dependencies">dependency</a>
from a po-earlier read, then the instruction cannot commit until the
read does.
This is simply because the address or data the instruction will use isn't
irrevocable until the earlier read commits.

<p>
The next pair of requirements affect only writes.
A write cannot commit until all sources of address dependencies to a
memory-access instruction po-before the write have committed.
This is necessary because the po-earlier memory access might generate
an invalid-address exception, in which case the write should not be executed.
However, the CPU can't know whether the earlier access's target
address will turn out to be invalid until the target address is fully
determined, which means that all sources of an address dependency have
to be committed.

<p>
Furthermore, a write cannot commit until all po-earlier instructions
accessing the same address have committed.
This requirement is necessary to enforce the coherence rules.
If two writes to the same address committed and were sent to the memory
subsystem out of order,
the memory subsystem would put the po-earlier write later in the
address's coherence order, which would violate write-write coherence.
And if a write committed before a po-earlier read of the same address
was satisfied, the memory subsystem would use the value stored by the write
(or something even later in the coherence order) to satisfy the
read request, which would violate read-write coherence.
But since the po-earlier read may be restarted (and thus satisfied again)
at any time up until it commits,
this means the write must not commit until the read is committed.

<p>
The next three requirements are concerned with restarting reads.
A read instruction <tt>R</tt> must be restarted after:

<ul>
<li>	A po-earlier read <tt>R'</tt> is satisfied, where <tt>R'</tt> is
	the source of an address dependency to <tt>R</tt>, or the source
	of an address or data dependency to a write that was forwarded
	to <tt>R</tt>.
<li>	A po-earlier read <tt>R'</tt> of the same address is satisfied,
	unless <tt>R</tt> read from the same write as <tt>R'</tt> or
	was forwarded from a write that is po-after <tt>R'</tt>.
<li>	A po-earlier write <tt>W</tt> to the same address is committed,
	unless <tt>R</tt> was forwarded from <tt>W</tt> or
	from a write that is po-after <tt>W</tt>.
</ul>

It follows that <tt>R</tt> cannot commit until each of the <tt>R'</tt>
or <tt>W</tt>
accesses mentioned here has committed (because until then, <tt>R'</tt>
might restart and thus be satisfied again or <tt>W</tt> might commit,
requiring <tt>R</tt> to restart).
The reason for the first case is pretty obvious; the other two
are more obscure.

<p>
For the second case,
suppose <tt>R'</tt> is po-before <tt>R</tt> and they read from different
writes, <tt>W'</tt> and <tt>W</tt> respectively.
Assuming <tt>W</tt> was not forwarded to <tt>R</tt>, this means that
<tt>W</tt> was the most recent write in the coherence order to have
propagated to the CPU as of the time when <tt>R</tt> was satisfied.
Similarly, either <tt>R'</tt> was forwarded from <tt>W'</tt> or else
<tt>W'</tt> was the most recent write in the coherence order to have
propagated to the CPU as of the time when <tt>R'</tt> was satisfied.
But if <tt>R'</tt> was satisfied after <tt>R</tt>, then
<tt>W'</tt> must come after <tt>W</tt> in the coherence order&mdash;if
it came before then <tt>R'</tt> would have read from <tt>W</tt> instead
of <tt>W'</tt>.
(We can discount the possibility that <tt>W'</tt> was forwarded to
<tt>R'</tt>; if it had been then it or a write po-after <tt>R'</tt>
would been forwarded to <tt>R</tt>.)
But <tt>W'</tt> being coherence-later than <tt>W</tt>
would be a violation of read-read coherence.
Thus <tt>R'</tt> must be satisfied before <tt>R</tt>, and the only
way to guarantee this is to require that <tt>R</tt> be restarted after
<tt>R'</tt> is satisfied.

<p>
For the third case, suppose <tt>W</tt> was the last write before
<tt>R</tt> (in program order) to access the same address,
and <tt>R</tt> was satisfied before <tt>W</tt> committed but
was not forwarded from it.
(This could happen if <tt>W</tt>'s target address had not yet been
been determined at the time <tt>R</tt> was satisfied.)
Then <tt>R</tt> would have either read from some other write <tt>W'</tt>
which had already propagated to the CPU, or else been forwarded from
some other write <tt>W'</tt> that was po-earlier than <tt>W</tt>.
Either way, when <tt>W</tt> did commit later on,
it would be assigned a position in the coherence order after <tt>W'</tt>.
This would violate write-read coherence.
Thus <tt>R</tt> must be satisfied at some time after <tt>W</tt> commits,
and the only way to guarantee this is to
require that <tt>R</tt> be restarted when <tt>W</tt> commits.

<p>
The last two ordering requirements reflect the operation of memory barriers.
That is, instructions in the barrier's pre-set must commit before the
barrier does, and operations in the post-set must commit after.

<p>
When we express these ordering requirements in the memory model,
it turns out that when a read instruction commits is relatively unimportant;
what really matters is when the read is satisfied for the last time.
Therefore we will say that a read <i>executes</i> when it is last
satisfied, whereas all other instructions execute when they commit.
In these terms, the ordering requirements take the following form.

<p>
<a name="Program Order Requirements">
Let <tt>A</tt> and <tt>B</tt> be instructions with <tt>A</tt> before
<tt>B</tt> in program order.
Then <tt>A</tt> must execute before <tt>B</tt> if any of the following hold:

<ol>
<li>	<tt>A</tt> is a conditional branch and <tt>B</tt> is a write
	instruction controlled by <tt>A</tt>.
<li>	There is a dependency from <tt>A</tt> to <tt>B</tt>.
<li>	There is a dependency from <tt>A</tt> to a write that is
	forwarded to <tt>B</tt>.
<li>	<tt>B</tt> is a write and <tt>A</tt> is the source of an
	address dependency to a memory access instruction between them.
<li>	<tt>B</tt> is a write and <tt>A</tt> accesses the same address
	as <tt>B</tt>.
<li>	<tt>A</tt> and <tt>B</tt> are reads of the same address, and
	<tt>B</tt> does not read from the same write as <tt>A</tt> and
	is not forwarded from a write that is between them.
<li>	<tt>A</tt> is a write and <tt>B</tt> is a read of the same address,
	and <tt>B</tt> is not forwarded from <tt>A</tt> or from a write
	that is between them.
<li>	<tt>B</tt> is a barrier and <tt>A</tt> is in its pre-set.
<li>	<tt>A</tt> is a barrier and <tt>B</tt> is in its post-set.
</ol></a>

(Taken together, requirements 8 and 9 say that <tt>A</tt> must
execute before <tt>B</tt> whenever they are separated in program order
by a suitable barrier, such that <tt>A</tt> is in the barrier's pre-set
and <tt>B</tt> is in the barrier's post-set.)

<p>
Collectively these are called <i>Preserved Program Order</i> (PPO) requirements,
because they force the CPU to execute certain instructions in program order.
The PPO requirements were expressed almost verbatim in the
original version of the strong kernel memory model.
Together with the description of how the memory subsystem works,
they suffice to guarantee that the four coherence rules will always be obeyed.
The resulting model applied quite nicely to x86, Sparc, and PowerPC;
however, it was not accurate for some other architectures.

<p><a name="Quick Quiz 8"><b>Quick Quiz 8</b>:</a>
Given all these constraints, how can weak-memory CPUs possibly expect to
attain any benefits of any sort compared to strong-memory CPUs?
<br><a href="#qq8answer">Answer</a>

<h3><a name="cumulativity-examples">Examples of cumulativity and
release sequences</a></h3>

<p>
The following litmus tests illustrate the ideas behind A- and B-cumulativity
and release sequences.

<blockquote>
<a id="litmus2" href="C-wmb-is-not-A-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#2</a>
<pre>
  1 C C-wmb-is-not-A-cumulative.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x)
  7 {
  8   WRITE_ONCE(*x, 1);
  9 }
 10
 11 P1(int *x, int *y, int *z)
 12 {
 13   r1 = READ_ONCE(*x);
 14   WRITE_ONCE(*z, r1);
 15   smp_wmb();
 16   WRITE_ONCE(*y, 1);
 17 }
 18
 19 P2(int *x, int *y)
 20 {
 21   r2 = READ_ONCE(*y);
 22   smp_rmb();
 23   r3 = READ_ONCE(*x);
 24 }
 25
 26 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

This test's <tt>exists</tt> clause can be satisfied.
Even though <tt>P0</tt>'s write to <tt>x</tt> propagates to <tt>P1</tt>
before <tt>P1</tt> reads <tt>x</tt>
(as proved by the fact that <tt>r1=1</tt> at the end),
and a data dependency forces the read to occur before <tt>z</tt> is written,
which happens before the <tt>smp_wmb()</tt> barrier commits,
the write to <tt>x</tt> is not in the barrier's pre-set
because <tt>smp_wmb()</tt> is not A-cumulative.
As a result, the barrier and the write to <tt>y</tt> are allowed to
propagate to <tt>P2</tt> before the write to <tt>x</tt> does
(although not before the write to <tt>z</tt>).
In the end, this is just a fancy way of saying that <tt>smp_wmb()</tt>
doesn't order two writes if the first write was executed on a different
CPU from that which executed the <tt>smp_wmb()</tt>.

<blockquote>
<a id="litmus3" href="C-release-is-A-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#3</a>
<pre>
  1 C C-release-is-A-cumulative.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x)
  7 {
  8   WRITE_ONCE(*x, 1);
  9 }
 10
 11 P1(int *x, int *y)
 12 {
 13   r1 = READ_ONCE(*x);
 14   smp_store_release(y, 1);
 15 }
 16
 17 P2(int *x, int *y)
 18 {
 19   r2 = READ_ONCE(*y);
 20   smp_rmb();
 21   r3 = READ_ONCE(*x);
 22 }
 23
 24 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

By contrast, this test's <tt>exists</tt> clause cannot be satisfied.
Because <tt>smp_store_release()</tt> is A-cumulative and because
<tt>P0</tt>'s write to <tt>x</tt> propagates to <tt>P1</tt>
before the <tt>smp_store_release()</tt> commits, the write is in the
release barrier's pre-set.
Consequently the new value of <tt>x</tt> must propagate to <tt>P2</tt>
before the store to <tt>y</tt> can.
Since <tt>P2</tt> is forced to read <tt>x</tt> after reading <tt>y</tt>
(by the <tt>smp_rmb()</tt>), and since it sees the new value of
<tt>y</tt>, it must also see the new value of <tt>x</tt>.

<blockquote>
<a id="litmus4" href="C-wmb-is-B-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#4</a>
<pre>
  1 C C-wmb-is-B-cumulative.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_wmb();
 10   WRITE_ONCE(*y, 1);
 11 }
 12
 13 P1(int *y, int *z)
 14 {
 15   r1 = READ_ONCE(*y);
 16   WRITE_ONCE(*z, r1);
 17 }
 18
 19 P2(int *x, int *z)
 20 {
 21   r2 = READ_ONCE(*z);
 22   smp_rmb();
 23   r3 = READ_ONCE(*x);
 24 }
 25
 26 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

B-cumulativity refers to writes that occur after the barrier.
Even though we don't tend to think of <tt>smp_wmb()</tt> as ordering
writes carried out by other CPUs, in every Linux-supported architecture
for which we know the details, it does, courtesy of the fact that
<tt>smp_wmb()</tt> is B-cumulative.

<p>
In this example, the write to <tt>x</tt>, the <tt>smp_wmb()</tt> barrier,
and the write to <tt>y</tt> must propagate from <tt>P0</tt> to <tt>P1</tt>
in order.
The data dependency from <tt>P1</tt>'s read of <tt>y</tt> to its write
of <tt>z</tt> forces the write to occur after the new value of <tt>y</tt>
has been seen, and hence after the <tt>smp_wmb()</tt> barrier has propagated
to <tt>P1</tt>.
As a result, the write to <tt>z</tt> is in the barrier's post-set,
so the barrier must propagate to <tt>P2</tt> before the write can.
That's what being B-cumulative means.
Before <tt>P2</tt> can read the new value of <tt>z</tt>, the barrier and
hence the new value of <tt>x</tt> must have propagated there.
Therefore <tt>P2</tt>'s read of <tt>x</tt> must see the new value,
and so the <tt>exists</tt> clause cannot be satisfied.

<blockquote>
<a id="litmus5" href="C-release-is-not-B-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#5</a>
<pre>
  1 C C-release-is-not-B-cumulative.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_store_release(y, 1);
 10 }
 11
 12 P1(int *y, int *z)
 13 {
 14   r1 = READ_ONCE(*y);
 15   WRITE_ONCE(*z, r1);
 16 }
 17
 18 P2(int *x, int *z)
 19 {
 20   r2 = READ_ONCE(*z);
 21   smp_rmb();
 22   r3 = READ_ONCE(*x);
 23 }
 24
 25 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

As before, the write to <tt>x</tt>, the <tt>smp_store_release()</tt>'s
barrier, and the write to <tt>y</tt> must propagate from <tt>P0</tt>
to <tt>P1</tt> in order, and so the write to <tt>z</tt> must occur
after the barrier has reached <tt>P1</tt>.
Nevertheless, because <tt>smp_store_release()</tt> is not B-cumulative,
the write to <tt>z</tt> isn't in the barrier's post-set,
and so the new value of <tt>z</tt> is allowed to propagate to <tt>P2</tt>
before either the barrier or the new value of <tt>x</tt>.
Consequently it is possible for <tt>P2</tt> to read the new value of
<tt>z</tt> followed by the old value of <tt>x</tt>.

<p>
<a name="release-acquire-is-B-cumulative">Despite what the previous
example shows, in this memory model
<tt>smp_store_release()</tt> <i>is</i> B-cumulative along pathways where
it is read by <tt>smp_load_acquire()</tt>.</a>
The following example illustrates this point.

<blockquote>
<a id="litmus6" href="C-release-acquire-is-B-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#6</a>
<pre>
  1 C C-release-acquire-is-B-cumulative.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_store_release(y, 1);
 10 }
 11
 12 P1(int *y, int *z)
 13 {
 14   r1 = smp_load_acquire(y);
 15   WRITE_ONCE(*z, 1);
 16 }
 17
 18 P2(int *x, int *z)
 19 {
 20   r2 = READ_ONCE(*z);
 21   smp_rmb();
 22   r3 = READ_ONCE(*x);
 23 }
 24
 25 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

In this litmus test, <tt>P0</tt>'s <tt>smp_store_release()</tt> is read
by <tt>P1's</tt> <tt>smp_load_acquire()</tt>.
As a result, the release barrier acts B-cumulatively and so <tt>P1</tt>'s
write of <tt>z</tt> cannot propagate to <tt>P2</tt> until the barrier has.
Hence it is not possible for <tt>P2</tt> to read the new value of <tt>z</tt>
followed by the old value of <tt>x</tt>.

<p>
Note that this applies only along the pathway of the
<tt>smp_load_acquire()</tt>.
This example:

<blockquote>
<a id="litmus7" href="C-release-B-cumulative-only-on-acquire-path.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#7</a>
<pre>
  1 C C-release-B-cumulative-only-on-acquire-path.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_store_release(y, 1);
 10 }
 11
 12 P1(int *y, int *z)
 13 {
 14   r1 = READ_ONCE(*y);
 15   WRITE_ONCE(*z, r1);
 16 }
 17
 18 P2(int *x, int *z)
 19 {
 20   r2 = READ_ONCE(*z);
 21   smp_rmb();
 22   r3 = READ_ONCE(*x);
 23 }
 24
 25 P3(int *y)
 26 {
 27   r4 = smp_load_acquire(y);
 28 }
 29
 30 exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0 /\ 3:r4=1)
</pre>
</blockquote>

is the same as the
<a href="#litmus5">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#5</a>
example above, except that it has a fourth thread P3 which uses
<tt>smp_load_acquire()</tt> to read the value of <tt>y</tt> stored
by <tt>P0</tt>.
However, this interaction does not cause the release barrier's effect
on <tt>P1</tt> to be B-cumulative;
the <tt>exists</tt> clause is still allowed to succeed.
(The barrier's effect on P3 <i>is</i> B-cumulative, but the example
does not probe this fact.)

<p>
The following litmus test shows a non-trivial use of a release sequence.

<blockquote>
<a id="litmus8" href="C-relseq.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#8</a>
<pre>
  1 C C-relseq.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_store_release(y, 1);
 10   WRITE_ONCE(*y, 2);
 11 }
 12
 13 P1(int *y)
 14 {
 15   r1 = xchg_relaxed(y, 3);
 16 }
 17
 18 P2(int *x, int *y)
 19 {
 20   r2 = READ_ONCE(*y);
 21   smp_rmb();
 22   r3 = READ_ONCE(*x);
 23 }
 24
 25 exists (1:r1=2 /\ 2:r2=3 /\ 2:r3=0)
</pre>
</blockquote>

The release sequence headed by <tt>P0</tt>'s <tt>smp_store_release()</tt>
to <tt>y</tt> includes <tt>WRITE_ONCE(*y, 2)</tt>, because that
write is po-after the store-release.
It also includes the atomic <tt>xchg_relaxed()</tt> operation in <tt>P1</tt>,
because that operation accesses <tt>y</tt> and reads from a write in the
release sequence (the <tt>WRITE_ONCE()</tt>).
Consequently <tt>P1</tt>'s atomic write belongs to the release barrier's
post-set, and it cannot propagate to <tt>P2</tt> before the
barrier and the write to <tt>x</tt> do.

<p>
Note that <tt>smp_store_release()</tt> barriers do not become B-cumulative
along paths where <tt>smp_load_acquire()</tt> reads from an arbitrary
member of the release sequence,
but only when the load-acquire reads directly from the store-release itself.
This is illustrated by the following example.

<blockquote>
<a id="litmus9" href="C-relseq-not-B-cumulative.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#9</a>
<pre>
  1 C C-relseq.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*x, 1);
  9   smp_store_release(y, 1);
 10   WRITE_ONCE(*y, 2);
 11 }
 12
 13 P1(int *y)
 14 {
 15   r1 = xchg_relaxed(y, 3);
 16 }
 17
 18 P2(int *y, int *z)
 19 {
 20   r2 = smp_load_acquire(y);
 21   WRITE_ONCE(*z, 1);
 22 }
 23
 24 P3(int *x, int *z)
 25 {
 26   r3 = READ_ONCE(*z);
 27   smp_rmb();
 28   r4 = READ_ONCE(*x);
 29 }
 30
 31 exists (1:r1=2 /\ 2:r2=3 /\ 3:r3=1 /\ 3:r4=0)
</pre>
</blockquote>

Here the <tt>smp_load_acquire()</tt> in P2 reads from the
<tt>xchg_relaxed()</tt> in P1, which is part of the
<tt>smp_store_release()</tt>'s release sequence as before.
But because it does not read directly from the <tt>smp_store_release()</tt>
instruction, it does not cause the barrier to act B-cumulatively.
Hence P2's write to <tt>z</tt> is allowed to propagate to P3 before
P0's release barrier or write to <tt>x</tt>.


<h2><a name="Design of the Strong Model">Design of the Strong Model</h2>

<p>
The strong kernel model essentially consists of checks for six types
of forbidden cycles, related to cache coherence, atomic operations,
instruction execution times, write and barrier propagation,
arrival at the coherence point, and
<a href="RCUguarantees.html">the RCU guarantee</a>.
The last one is concerned more with how RCU is implemented in the kernel
than with hardware instruction processing, so we will not discuss it here.

<h3><a name="Cache coherence: the coherence check">Cache coherence: the &ldquo;coherence&rdquo; check</a></h3>

<p>
The model treats
<a href="LinuxMMModel.html#cache coherence">cache coherence</a>
in exactly the same way as in the
<a href="coherent-RMO.cat">Coherent-RMO</a> model did,
by defining the <tt>coherence-order</tt> relation and including a
&ldquo;coherence&rdquo; check that requires the union of <tt>po-loc</tt>
and <tt>coherence-order</tt> to have no cycles.

<h3><a name="Atomic operations: the atomic check">Atomic operations: the &ldquo;atomic&rdquo; check</a></h3>

<p>
The treatment of atomic RMW operations is even simpler.
What makes these operations atomic is that no write from another CPU
is allowed to intervene (in the coherence order) between
the write that the RMW operation reads from and the RMW's own write.
The model defines a relation that links the read event of each RMW instruction
to the instruction's write event by way of such an intervening write,
and includes an &ldquo;atomic&rdquo; check that requires this relation
to be empty.

<h3><a name="Execution ordering: the happens-before check">Execution ordering: the &ldquo;happens-before&rdquo; check</a></h3>

<p>
Instruction execution ordering comes in several different forms.
For now we'll consider the easiest version, as defined for the original
PowerPC-oriented operational memory model.
Because we are designing a memory model, we are especially concerned
with ordering of memory accesses,
and we will ignore other kinds of instructions.
The conditions which require one memory access to execute after another
can be grouped in four general categories (listed along with the relations
the model uses to express them):

<ul>
<li>	A read that reads from a write on another CPU must execute after
	that write (the <tt>rfe</tt> relation).
<li>	An access in a non-read-dependency memory barrier's post-set
	must execute after an access in the barrier's pre-set (the
	<tt>ordering-fence</tt> relation).
<li>	Any of the
	<a href="#Program Order Requirements">Preserved Program Order
	requirements</a> listed earlier can force a CPU to execute
	one access after another (the <tt>ppo</tt> relation).
<li>	A barrier's write-propagation properties can justify an
	argument by contradiction showing that under the right circumstances,
	if two accesses are on the same CPU then the first could not
	have executed after the second; it follows that the second must have
	executed after the first (the <tt>obs</tt> relation).
</ul>

The <tt>hb</tt> relation incorporates these requirements.
If there is a sequence of <tt>hb</tt> links from <tt>A</tt> to <tt>B</tt>,
it means that <tt>A</tt> must execute before <tt>B</tt>.
As mentioned
<a href="LinuxMMModel.html#Specifying a Memory Model in Terms of Prohibited Cycles">earlier</a>,
any cycle in the times of execution of instructions is prohibited;
accordingly, the memory model contains a &ldquo;happens-before&rdquo; check
that requires the <tt>hb</tt> relation not to have any cycles.

<p>
It may seem a little odd to group the <tt>ordering-fence</tt>
relation separately from the <tt>ppo</tt> relation, since they
are essentially the same sort of thing;
doing it this way seems to be historical practice.
Grouping the <tt>rfe</tt> relation separately from the others makes much
more sense, because it is the only way to directly relate two accesses
on different CPUs.
(Although a barrier's pre- and post-sets may be considered to contain
accesses from other CPUs, thanks to cumulativity, the <tt>ordering-fence</tt>
relation only affects accesses on the barrier's own CPU.
Cumulativity is handled separately.)

<h3><a name="Execution ordering: Preserved Program Order and fences">Execution ordering: Preserved Program Order and fences</a></h3>

<p>
The <tt>ppo</tt> relation requires an in-depth discussion.
It is where the differences between the PowerPC, Alpha, and ARM architectures
show up most strongly.
We'll begin with an approach tailored to the PowerPC-oriented model
and then later discuss the changes required for Alpha and ARM.

<p>
In a nutshell, the memory model defines a relation for each of the types
of PPO links listed earlier, except the ones involving barriers:

<ol>
<li>	The builtin <tt>ctrl</tt> relation links a read access to any
	memory access in a conditional branch that depends on the value
	of the read.
	The memory model computes <tt>(ctrl & (R*W))</tt> to limit the
	targets of these control dependencies to write accesses.
<li>	The builtin <tt>addr</tt> and <tt>data</tt> relations link
	a read access to any later accesses with an address or data dependency
	from the read.
	The <tt>dep</tt> relation is defined as the union of these two.
<li>	The model defines the <tt>dep-rfi</tt> relation as the concatenation
	of a <tt>dep</tt> link and an <tt>rfi</tt> link.
	<tt>rfi</tt> links writes to reads in the same thread that read
	from them.
	These reads may have been satisfied by forwarding the write or by
	going through the memory subsystem, but either way the effect is
	the same: The read at the end of the <tt>rfi</tt> link must execute
	after the read at the start of the <tt>dep</tt> link.
<li>	The <tt>addrpo</tt> relation is defined as the concatenation of an
	<tt>addr</tt> link and a <tt>po</tt> link.
	The memory model computes <tt>(addrpo & (R*W))</tt>, which thus
	connects reads carrying an address dependency to writes that are
	po-after the target of the dependency.
<li>	The builtin <tt>po-loc</tt> relation links a memory access to any
	po-later access of the same address.
	The memory model computes <tt>(po-loc & (M*W))</tt> to limit the
	targets of these links to writes.
<li>	The <tt>rdw</tt> (&ldquo;read different writes&rdquo;) relation
	is defined as <tt>(po-loc & (fre ; rfe))</tt>.
	It thus links two reads of the same address in the same thread,
	if they read from different writes and the po-later read
	takes its value from a write in a different thread.
	Thanks to the coherence rules, this is equivalent to saying that
	the later read was not forwarded from a write between the two reads.
<li>	The <tt>detour</tt> relation is defined as
	<tt>(po-loc & (coe ; rfe))</tt>.
	It thus links a write to a po-later read (of the same address
	in the same thread) that reads from a write in a different thread.
	This certainly implies that the read was not forwarded from the
	write or from another write in between.
	The case where the read does read from the write,
	through the memory subsystem instead of by forwarding,
	is left as an exercise for the reader.
</ol>

The <tt>ppo</tt> relation in the PowerPC-based model is the union of
these relations.

<p><a name="Quick Quiz 9"><b>Quick Quiz 9</b>:</a>
Following up on exercise for the reader in the <tt>detour</tt>
relationship, what happens if the value from the write is forwarded
to that thread's later read?
<br><a href="#qq9answer">Answer</a>

<p>
The <tt>rmb</tt>, <tt>wmb</tt>, <tt>mb</tt>, <tt>sync</tt>,
<tt>acq-po</tt>, and <tt>po-relass</tt> relations are defined
to link accesses in each of the barriers' pre-sets to accesses in the
corresponding post-sets.
(<tt>po-relass</tt> handles both <tt>smp_store_release()</tt> and
<tt>rcu_assign_pointer()</tt>; the kernel implements the latter by means
of the former.)
The <tt>ordering-fence</tt> relation is the union of these.
It thus incorporates all but the read-dependency barriers.

<h3><a name="Execution ordering: write propagation and cumulativity">Execution ordering: write propagation and cumulativity</a></h3>

<p>
Finally, the <tt>hb</tt> relation is taken to be the union of <tt>ppo</tt>,
<tt>ordering-fence</tt>, <tt>rfe</tt>, and one other relation,
called <tt>obs</tt> (short for &ldquo;observation&rdquo;).
In order to explain <tt>obs</tt>, it is necessary to discuss first
the effects of the propagation-order barriers: <tt>synchronize_rcu()</tt>,
<tt>smp_mb()</tt>, <tt>smp_wmb()</tt>, and the various store-release
instructions, such as <tt>smp_store_release()</tt> and
<tt>rcu_assign_pointer()</tt>.

<p>
This is where cumulativity comes into play.
An A-cumulative barrier's pre-set is closed under <tt>(rfe^-1)</tt>.
That is, if <tt>R</tt> is a read in the pre-set of an A-cumulative barrier
and <tt>W &#10230; R</tt> is a link in <tt>rfe</tt> (where <tt>W</tt>
is a write), then <tt>W</tt> must also be in the barrier's pre-set.
The reason is simple.
Because it is in the pre-set, <tt>R</tt> must precede the barrier
in program order and must execute before the barrier does.
The fact that <tt>W</tt> is on another CPU and <tt>R</tt> reads from
<tt>W</tt> means that <tt>W</tt> must have propagated to the barrier's
CPU before <tt>R</tt> executed, hence before the barrier was committed.
By the definition of A-cumulativity, <tt>W</tt> must therefore be a member
of the barrier's pre-set.

<p>
Similarly, a B-cumulative barrier's post-set is closed under <tt>hb</tt>.
That is, if <tt>X</tt> is in the post-set of a B-cumulative barrier
and <tt>X &#10230; Y</tt> is a link in <tt>hb</tt>, then <tt>Y</tt>
must also be in the barrier's post-set.
The fact that <tt>X</tt> is in the post-set means that the barrier
propagates to <tt>X</tt>'s CPU before <tt>X</tt> executes.
If the <tt>hb</tt> link from <tt>X</tt> to <tt>Y</tt>
is anything other than <tt>rfe</tt>, it says that <tt>Y</tt> executes
on the same CPU as <tt>X</tt> and after <tt>X</tt> does, hence after
the barrier propagates to that CPU.
If the link is an instance of <tt>rfe</tt>, it says that <tt>X</tt>
is a write and <tt>Y</tt> reads from <tt>X</tt> on a different CPU.
Since <tt>X</tt> is in the barrier's post-set,
the barrier must propagate to <tt>Y</tt>'s CPU before <tt>X</tt>
does, hence before <tt>Y</tt> executes.
Either way, by the definition of B-cumulativity, <tt>Y</tt> must be a member
of the barrier's post-set.

<p>
(Note that being closed under <tt>hb</tt> is a transitive property.
In other words, if <tt>X &#10230; Y</tt> and <tt>Y &#10230; Z</tt> are
links in <tt>hb</tt>, and if <tt>X</tt> is in a B-cumulative barrier's
post-set, then <tt>Y</tt> and <tt>Z</tt> must both be in the
post-set as well.
By contrast, being closed under <tt>(rfe^-1)</tt> is not transitive.
It is not possible to have <tt>X &#10230; Y</tt> and <tt>Y &#10230; Z</tt>
both be links in <tt>rfe</tt>, because <tt>Y</tt> can't be
both a read event and a write event.)

<p><a name="Quick Quiz 10"><b>Quick Quiz 10</b>:</a>
What about RMW (read-modify-write) instructions, such as <tt>xchg()</tt>
or <tt>atomic_inc()</tt>?
Don't they constitute both a read and a write?
<br><a href="#qq10answer">Answer</a>

<p>
(Incidentally, it is a subtle point worth mentioning that this property of
<tt>hb</tt>&mdash;that B-cumulative post-sets are closed under it&mdash;is
perhaps even more important than the original characterization of
<tt>hb</tt> in terms of one instruction executing before another.
When the instructions are on the same CPU, the two concepts amount to
the same thing.
But when the instructions are on different CPUs, the concepts are definitely
not the same.
In order to have an <tt>hb</tt> link from <tt>X</tt> to <tt>Y</tt> on another
CPU, it is not sufficient for <tt>X</tt> to execute before <tt>Y</tt>.
It is also necessary for every B-cumulative barrier that propagates to
<tt>X</tt>'s CPU before <tt>X</tt> executes to also propagate to
<tt>Y</tt>'s CPU before <tt>Y</tt> executes.
Guaranteeing this requires some sort of causal connection between the CPUs,
such as a write on <tt>X</tt>'s CPU after <tt>X</tt> executes that is read by
<tt>Y</tt>'s CPU before <tt>Y</tt> executes.
This helps explain why the only inter-CPU part of the definition of <tt>hb</tt>
is <tt>rfe</tt>.)

<p>
Putting these ideas together we can define the <tt>propbase</tt> relation,
which links accesses in a propagation-order barrier's pre-set to accesses
in its post-set, taking cumulativity into account.
For simplicity, we'll ignore release sequences
and the effect of load-acquire reading from store-release.
<tt>propbase</tt> then looks like this
(the actual definition of <tt>propbase</tt> in the strong kernel model
is considerably more complicated,
in part because it doesn't ignore these extra factors):

<!-- Obsolete, now AB-cum-hb, etc. -->
<blockquote>
<pre>
let AB-cum-propbase = rfe? ; strong-fence ; hb*
let A-cum-propbase = AB-cum-propbase | (rfe? ; po-relass)
let B-cum-propbase = AB-cum-propbase | (wmb ; hb* )
let propbase = A-cum-propbase | B-cum-propbase
</pre>
</blockquote>

Here <tt>strong-fence</tt> is the union of <tt>mb</tt> and <tt>sync</tt>
(the two types of strong barriers), and <tt>po-relass</tt> covers all
the store-release instructions.
These definitions express the fact that strong barriers are both A- and
B-cumulative, store-release barriers are A-cumulative, and <tt>smp_wmb()</tt>
is B-cumulative.
Thus <tt>AB-cum-propbase</tt> applies to barriers that are both
A-cumulative and B-cumulative, <tt>A-cum-propbase</tt> applies to barriers
that are A-cumulative, <tt>B-cum-propbase</tt> applies to barriers that are
B-cumulative, and <tt>propbase</tt> gives the complete relation.
(The extra space between the &lsquo;<tt>*</tt>&rsquo; and
&lsquo;<tt>)</tt>&rsquo; characters is necessary because <tt>herd</tt>,
following OCaml, reserves &ldquo;<tt>*)</tt>&rdquo; for marking the
end of a comment.)

<p>
Notice that every relation making up the definition of <tt>propbase</tt>
is also part of <tt>hb</tt>.
In fact, <tt>propbase</tt> is a sub-relation of <tt>hb</tt>.
However, it expresses more than the simple fact that one instruction
executes before another.
<a name="Propbase property">
Whenever there is a <tt>propbase</tt> link from a memory access <tt>X</tt>
to another access <tt>Y</tt>, the operational model says that the following
somewhat unwieldy ordering property (which we can call the
&ldquo;Propbase&rdquo; property) holds:

<blockquote>
If <tt>X</tt> is a write, let <tt>W = X</tt>; otherwise let <tt>W</tt>
be any write that propagates to <tt>X</tt>'s CPU before <tt>X</tt> executes.
Then <tt>W</tt> propagates to <tt>Y</tt>'s CPU before <tt>Y</tt>
executes.  In addition, if <tt>Y</tt> is a write then <tt>W</tt> propagates
to any other CPU before <tt>Y</tt> propagates to that CPU, and likewise for the
coherence point.
</blockquote>
</a>

Detailed justification of this property is left to the reader;
it depends on the fact that if a propagation-order barrier's pre-set
can contain a read then the barrier is A-cumulative.
(Load-acquire barriers don't count, because they are only execution-order
barriers, not propagation-order.)

<p>
Details aside, a notable aspect of the Propbase property is that it is
transitive.
In other words, if <tt>X</tt> and <tt>Y</tt> obey the Propbase property
and <tt>Y</tt> and <tt>Z</tt> do so too, then <tt>X</tt> and <tt>Z</tt>
also obey the property.
Verification of this fact is also left as an exercise for the reader.

<h3><a name="Execution ordering: the obs relation">Execution ordering: the <tt>obs</tt> relation</a></h3>

<p>
Now suppose we have the following situation: <tt>A</tt> is a write,
<tt>X</tt> is a write on another CPU to the same address, coming after
<tt>A</tt> in the coherence order, <tt>Y</tt> is also a write connected
to <tt>X</tt> by a series of <tt>propbase</tt> links, and <tt>B</tt>
is a read that reads from <tt>Y</tt>.
We can write this symbolically as:

<blockquote>
<tt>A &#10230;<sub>coe</sub> X &#10230;<sub>propbase+</sub> Y
&#10230;<sub>rfe</sub> B</tt>
</blockquote>

where the subscripts specify the relations indicated by the arrows.
(<tt>propbase+</tt> means a sequence of one or more <tt>propbase</tt>
relations.)
Finally, suppose that <tt>A</tt> and <tt>B</tt> are on the same CPU.

<p>
Because the Propbase property is transitive, <tt>X</tt> and <tt>Y</tt>
must have the Propbase property.
Therefore <tt>X</tt> must propagate to <tt>B</tt>'s (and <tt>A</tt>'s) CPU
before <tt>Y</tt> does, and hence before <tt>B</tt> executes.
Is it possible for <tt>A</tt> to execute after <tt>B</tt>?
No, because if it did, the memory subsystem would be forced to assign
<tt>A</tt> a position after <tt>X</tt> in the coherence order,
since <tt>X</tt> had already propagated to <tt>A</tt>'s CPU when
<tt>A</tt> executed.
But we are assuming that <tt>A</tt> comes before <tt>X</tt> in the
coherence order (the <tt>coe</tt> link between them).

<p>
We conclude that in this situation, <tt>A</tt> must execute before <tt>B</tt>.
The same conclusion would hold if <tt>A</tt> was a read and the link from
<tt>A</tt> to <tt>X</tt> was <tt>fre</tt> rather than <tt>coe</tt>.
In that case, the memory subsystem would satisfy the read <tt>A</tt>
from the coherence-latest write that had already propagated to <tt>A</tt>'s
CPU, and if <tt>A</tt> executed after <tt>B</tt> then that write would be
<tt>X</tt> or something even later.
But the <tt>fre</tt> link from <tt>A</tt> to <tt>X</tt> says that
the write used to satisfy <tt>A</tt> was coherence-earlier than <tt>X</tt>,
and so <tt>A</tt> cannot execute after <tt>B</tt>.

<p>
This is the reasoning behind the <tt>short-obs</tt> relation,
which is defined as

<blockquote>
<pre>
let short-obs = ((coe|fre) ; propbase+ ; rfe) & int
</pre>
</blockquote>

where <tt>int</tt> (short for &ldquo;internal&rdquo;) links any two events
in the same thread.
The model also uses a more general relation, <tt>obs</tt>, defined as:

<blockquote>
<pre>
let obs = short-obs |
	((hb* ; (coe|fre) ; propbase* ; B-cum-propbase; rfe) & int)
</pre>
</blockquote>

The second part of the <tt>obs</tt> relation applies when
the last sequential <tt>propbase</tt> link involves a B-cumulative barrier.
To understand the significance of this, suppose we have:

<blockquote>
<tt>A &#10230;<sub>hb*</sub> U &#10230;<sub>coe</sub> X
&#10230;<sub>propbase*</sub> Z &#10230;<sub>B-cum-propbase</sub> Y
&#10230;<sub>rfe</sub> B</tt>
</blockquote>

with <tt>A</tt> and <tt>B</tt> on the same CPU.
If <tt>A</tt> executed after <tt>B</tt> then by B-cumulativity,
<tt>A</tt> would also be in the final barrier's post-set.
Consequently so would <tt>U</tt>, and thus <tt>X</tt> and <tt>U</tt>
would have the Propbase property.
Just as before, this would contradict the fact that there is a <tt>coe</tt>
link from <tt>U</tt> to <tt>X</tt>.

<p>
Thus we can conclude that whenever there is an <tt>obs</tt> link from
<tt>A</tt> to <tt>B</tt> (which includes the case of <tt>short-obs</tt>),
<tt>A</tt> must execute before <tt>B</tt>.
And since the two events are on the same CPU, this means they
should be ordered by <tt>hb</tt>.
This is why the definition of <tt>hb</tt> incorporates <tt>obs</tt>,
as mentioned earlier.

<p>
(You may have noticed that the definitions of <tt>hb</tt> and <tt>obs</tt>
are mutually recursive; <tt>obs</tt> is a part of <tt>hb</tt>,
and the definition of <tt>obs</tt> involves <tt>B-cum-propbase</tt>,
which uses <tt>hb</tt>.
Fortunately <tt>herd</tt> has no trouble working with recursive definitions!)

<p>
Here is a simple example of <tt>short-obs</tt>, to help cement these ideas.
This is a litmus test we have seen before, the &ldquo;message-passing&rdquo;
pattern:

<blockquote>
<a id="C-MP+o-mb-o+o-mb-o.litmus" href="C-MP+o-mb-o+o-mb-o.litmus">C-MP+o-mb-o+o-mb-o.litmus</a>
<pre>
  1 C C-MP+o-mb-o+o-mb-o
  2
  3 {
  4 }
  5
  6 P0(int *x, int *y)
  7 {
  8   WRITE_ONCE(*y, 1);
  9   smp_mb();
 10   WRITE_ONCE(*x, 1);
 11 }
 12
 13 P1(int *x, int *y)
 14 {
 15   int r1;
 16   int r2;
 17
 18   r1 = READ_ONCE(*x);
 19   smp_mb();
 20   r2 = READ_ONCE(*y);
 21 }
 22
 23 exists
 24 (1:r1=1 /\ 1:r2=0)
</pre>
</blockquote>

If <tt>r1=1</tt> and <tt>r2=0</tt> at the end then there is a
<tt>short-obs</tt> link from the read of <tt>*y</tt> (line&nbsp;20)
to the read of <tt>*x</tt> (line&nbsp;18):
Because <tt>r2</tt> is 0, the read of <tt>*y</tt> does not see the write
in line&nbsp;8, so they are linked by <tt>fre</tt>.
The <tt>smp_mb()</tt> in line&nbsp;9 then provides a <tt>propbase</tt> link
to the write in line&nbsp;10.
And that write is linked by <tt>rfe</tt> to the read in line&nbsp;18,
because <tt>r1</tt> is 1.
Together these constitute an instance of <tt>short-obs</tt>.

<p>This implies that the condition in the &ldquo;exists&rdquo;
clause requires the read in line&nbsp;20 to execute before the read in
line&nbsp;18.
But the <tt>smp_mb()</tt> barrier between them forces the reads to execute
in program order.
We thus have a cycle in <tt>hb</tt>:
Line&nbsp;18 &#10230; line&nbsp;20 because of the memory barrier, and
line&nbsp;20 &#10230; line&nbsp;18 because of the <tt>short-obs</tt> link.
This cycle violates the &ldquo;happens-before&rdquo; check,
and so the memory model says the litmus test cannot succeed.

<p><a name="Quick Quiz 11"><b>Quick Quiz 11</b>:</a>
But this <tt>short-obs</tt> link goes backward from line&nbsp;20 to
line&nbsp;18!
How can a backward link on a single CPU represent a
&ldquo;happens-before&rdquo; ordering relation???
<br><a href="#qq11answer">Answer</a>

<p>
The fact that <tt>obs</tt> plays a role in such a simple litmus test
underlines its importance.
It is the single relation in the memory model that accounts for the
effects of barriers on propagation of writes between CPUs.

<h3><a name="Coherence-point ordering: the propagation check">Coherence-point ordering: the &ldquo;propagation&rdquo; check</a></h3>

<p>
Writes get sent to the coherence point as well as propagating among CPUs,
and if we create a relation that links writes by their order of arrival
at the coherence point, this relation must not contain a cycle.
In the Linux-kernel memory model, this relation is <tt>cpord</tt>
(for &ldquo;coherence-point ordering&rdquo;), and the
&ldquo;propagation&rdquo; check requires that <tt>cpord</tt> be acyclic.

<p>
Some parts of the definition of <tt>cpord</tt> are quite straightforward.
A write in a propagation-order barrier's pre-set must arrive at the
coherence point before a write in the barrier's post-set.
In addition, the fundamental property of the coherence point
says that for any two writes to the same address,
the write that is earlier in the coherence order for that address
must arrive at the coherence point first.
For these reasons, <tt>cpord</tt> contains the relations
<tt>propbase & (W*W)</tt> (that is, the <tt>propbase</tt> relation
restricted to links between two writes) and <tt>co</tt>.

<p>
Another fairly straightforward aspect concerns the write events in
atomic RMW instructions.
According to the operational memory model, such writes
arrive at the coherence point at the same time as they commit;
this is how the model provides atomicity.
As a result, any write which executes after an RMW write must also arrive
at the coherence point after it (since writes can't arrive at the
coherence point before they execute).
The <tt>atomic-hb</tt> relation expresses this idea.
It is defined as:

<blockquote>
<pre>
<tt>let atomic-hb = hb+ & ((RMW & W)*W)</tt>
</pre>
</blockquote>

and was included in the original definition of <tt>cpord</tt>.
It had to be removed later on, however, when we found out that the
ARM architecture does <i>not</i> require atomic RMW writes to reach
the coherence point when they commit.

<p>
The final part of <tt>cpord</tt> is not at all obvious.
At first glance, one wouldn't think that arrival times at the
coherence point would bear any connection to reads, since reads don't
get sent to the coherence point in the way that writes do.
Nevertheless, reads do play an important role in the definition of
<tt>cpord</tt>.
The connection has to do with the unique properties of strong barriers.

<p>
To explore these ideas, let's extend the meaning of <tt>cpord</tt>.
For writes, it will continue to refer to the time when the write arrives
at the coherence point.
For reads, we will let <tt>cpord</tt> simply refer to the time when the
read executes.
So now suppose that there is a <tt>propbase</tt> link from <tt>A</tt>
to <tt>B</tt>, where <tt>A</tt> and <tt>B</tt> can be either reads
or writes.
What can we say about the existence of a <tt>cpord</tt> link from <tt>A</tt>
to <tt>B</tt>?

<p>
The case where <tt>A</tt> is a read is trivial.
The <tt>propbase</tt> link says that <tt>A</tt> executes before <tt>B</tt>
(indeed, <tt>propbase</tt> is a sub-relation of <tt>hb</tt>),
and therefore there must be a <tt>cpord</tt> link from <tt>A</tt> to
<tt>B</tt> regardless of whether <tt>B</tt> is a read or a write.
If <tt>A</tt> and <tt>B</tt> are both writes then we know that <tt>A</tt>
is in the pre-set of the <tt>propbase</tt>'s memory barrier and <tt>B</tt>
is in the post-set; hence <tt>A</tt> must arrive at the coherence point
before <tt>B</tt> and once again we have a <tt>cpord</tt> link.
The most interesting case is the remaining one, where <tt>A</tt> is a write
and <tt>B</tt> is a read.
In this case, although <tt>A</tt> is guaranteed to execute before <tt>B</tt>,
there is no guarantee that <tt>A</tt> will arrive at the coherence point
before <tt>B</tt> executes.
Thus, there need not be a <tt>cpord</tt> link from <tt>A</tt> to <tt>B</tt>.

<p>
But what if the <tt>propbase</tt>'s memory barrier is a strong barrier
(such as <tt>smp_mb()</tt> or <tt>synchronize_rcu()</tt>)?
Instructions in a strong barrier's post-set do not execute until after
the barrier has been acknowledged, and the barrier does not get
acknowledged until every write in its pre-set has propagated to every CPU
and to the coherence point&mdash;this is what makes the barrier
&ldquo;strong&rdquo;.
This means that <tt>B</tt> cannot execute until after <tt>A</tt> has
reached the coherence point, and therefore we do have a <tt>cpord</tt>
link from <tt>A</tt> to <tt>B</tt>.

<p>
A little thought shows that the same is true if <tt>A</tt> and <tt>B</tt>
are connected by a sequence of <tt>propbase</tt> links in which the last
<tt>propbase</tt> involves a strong memory barrier.
And we can even go one step further, by applying an argument
similar to the one underlying <tt>short-obs</tt>:

<p>
Suppose <tt>R</tt> is a read, <tt>A</tt> is a write on another CPU
to the same address, related to <tt>R</tt> by an <tt>fre</tt> link,
and <tt>B</tt> is a read or write connected to <tt>A</tt> by a sequence of
<tt>propbase</tt> links where the barrier in the last <tt>propbase</tt>
is a strong barrier.
In symbols:

<blockquote>
<tt>R &#10230;<sub>fre</sub> A &#10230;
<sub>propbase* ; strong-propbase</sub> B</tt>
</blockquote>

where <tt>strong-propbase</tt> stands for a <tt>propbase</tt> relation
containing a strong barrier.
Strong barriers are both A- and B-cumulative, so expanded out in full,
<tt>strong-propbase</tt> becomes <tt>(rfe? ; strong-fence ; hb* )</tt>.
Unlike the situation with <tt>short-obs</tt>, we do not need to assume that
<tt>R</tt> and <tt>B</tt> are on the same CPU.
Nevertheless, we can still conclude that <tt>R</tt> must execute before
<tt>B</tt> can execute or reach the coherence point, implying that there
is a <tt>cpord</tt> link from <tt>R</tt> to <tt>B</tt>.

<p>
The reasoning is much like before.
By the Propbase property <tt>A</tt> is in the final strong barrier's
pre-set, so it must propagate to every CPU before the barrier is acknowledged.
And since <tt>B</tt> is in the strong barrier's post-set, it cannot
execute or reach the coherence point until after the barrier is acknowledged.
If <tt>R</tt> executed later than <tt>B</tt> then <tt>A</tt> would already
have propagated to <tt>R</tt>'s CPU, and so <tt>R</tt> would read from
<tt>A</tt> (or another write even later in the coherence order).
But this is not possible, because of the <tt>fre</tt> link from
<tt>R</tt> to <tt>A</tt>.

<p>
These ideas are expressed by the <tt>strong-prop</tt> relation, defined as:

<blockquote>
<pre>
<tt>let strong-prop = fre? ; propbase* ; rfe? ; strong-fence ; hb*</tt>
</pre>
</blockquote>

and included in definition of <tt>cpord</tt>.
The initial <tt>fre</tt> link is optional to allow for the case mentioned
earlier, where a sequence of <tt>propbase</tt> links ending in one containing
a strong memory barrier connects a write to a read.
The strong barrier at the end is crucial; without it we could not guarantee
the existence of a <tt>cpord</tt> link.

<p><a name="Quick Quiz 12"><b>Quick Quiz 12</b>:</a>
Readers who go to the trouble of reading the actual definition of
<tt>cpord</tt> in the Linux-kernel strong memory model will see that
it includes the <tt>co</tt>, <tt>propbase & (W*W)</tt>, and <tt>strong-prop</tt>
terms mentioned earlier, but it does not include any terms corresponding to
the &ldquo;trivial&rdquo; case of a <tt>propbase</tt> or <tt>hb+</tt> link
starting from a read.
Why not?
<br><a href="#qq12answer">Answer</a>

<h3>No other checks?</h3>

<p>
The checks we have introduced into the memory model above
(&ldquo;coherence&rdquo;,
&ldquo;atomic&rdquo;,
&ldquo;happens-before&rdquo;, and
&ldquo;propagation&rdquo;)
may seem like an eclectic collection.
Nevertheless, it can be shown that they suffice to duplicate nearly
all the results prescribed by the operational model.

The only shortcoming has to do with some subtle interactions between
B-cumulative memory barriers and the &ldquo;propagation&rdquo; check,
and demonstrating these interactions requires very unrealistic litmus tests
containing cycles that span at least four threads.
We will not examine these issues here.
In any case, it turns out that this small weakness is dwarfed by the compromises
the memory model is forced to accept in order to accomodate the
idiosyncracies of the Alpha and ARM architectures (in addition to
those of PowerPC that are accommodated by our initial memory model)
as we shall see.


<h2><a name="Adjustments for the DEC Alpha">Adjustments for the DEC Alpha</a></h2>

<p>
Alpha deviates from the operational model described above in one
very significant way: It uses a software-visible split data cache.
In terms of the memory model, this means that writes which propagate
to a CPU in one order might be perceived by that CPU in the opposite
order.
For example, suppose that P0 writes to both <tt>x</tt> and <tt>y</tt>,
and the writes propagate in that order to P1.
If <tt>x</tt> and <tt>y</tt> happen to be located in different cache lines
and the two cache lines are handled by different parts of P1's data cache,
it may happen that the part of the cache responsible for handling the
write to <tt>x</tt> is busy while another part of the cache is able to
handle the write to <tt>y</tt> right away.
P1's CPU would then see <tt>y</tt>'s new value before seeing <tt>x</tt>'s,
a result that would not be allowed by the memory model as described above.

<p>
Here's an example litmus test to illustrate the point.

<blockquote>
<a id="litmus10" href="alpha-split-cache-example1.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#10</a>
<pre>
  1 C alpha-split-cache-example1
  2 {
  3 int u = 0;
  4 int v = 0;
  5 int *p = &amp;u;
  6 }
  7
  8 P0(int **p, int *v)
  9 {
 10   WRITE_ONCE(*v, 1);
 11   smp_mb();
 12   WRITE_ONCE(*p, v);
 13 }
 14
 15 P1(int **p)
 16 {
 17   int *r1;
 18   int r2;
 19
 20   r1 = READ_ONCE(*p);
 21   r2 = READ_ONCE(*r1);
 22 }
 23
 24 exists (1:r1=v /\ 1:r2=0);
</pre>
</blockquote>

<p>
The <tt>smp_mb()</tt> in P0 forces the write to <tt>v</tt> to propagate
to P1 before the write to <tt>p</tt>, and
the address dependency from P1's read of <tt>p</tt> to its read of
<tt>*r1</tt> forces these reads to be executed in program order.
Nevertheless, the split-cache arrangement may cause P1 to see the
new value of <tt>p</tt> (i.e., <tt>&amp;v</tt>) and then the
old value of <tt>v</tt> (i.e., 0).
This odd behavior can be observed on real Alpha hardware,
and it shows up when we run the litmus test through the model:

<blockquote>
<a id="litmus10" href="alpha-split-cache-example1.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#10</a>
<pre>
 1 Test alpha-split-cache-example1 Allowed
 2 States 3
 3 1:r1=u; 1:r2=0;
 4 1:r1=v; 1:r2=0;
 5 1:r1=v; 1:r2=1;
 6 Ok
 7 Witnesses
 8 Positive: 1 Negative: 2
 9 Condition exists (1:r1=v /\ 1:r2=0)
10 Observation alpha-split-cache-example1 Sometimes 1 2
11 Hash=b73c984509551a6a5ffe49d86c9a2d04
</pre>
</blockquote>

<p>
Inserting a call to <tt>smp_read_barrier_depends()</tt> (see line&nbsp;21):

<blockquote>
<a id="litmus11" href="alpha-split-cache-example2.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#11</a>
<pre>
  1 C alpha-split-cache-example2
  2 {
  3 int u = 0;
  4 int v = 0;
  5 int *p = &amp;u;
  6 }
  7
  8 P0(int **p, int *v)
  9 {
 10   WRITE_ONCE(*v, 1);
 11   smp_mb();
 12   WRITE_ONCE(*p, v);
 13 }
 14
 15 P1(int **p)
 16 {
 17   int *r1;
 18   int r2;
 19
 20   r1 = READ_ONCE(*p);
 21   smp_read_barrier_depends();
 22   r2 = READ_ONCE(*r1);
 23 }
 24
 25 exists (1:r1=v /\ 1:r2=0);
</pre>
</blockquote>

prevents the unwanted result:

<blockquote>
<a id="litmus11" href="alpha-split-cache-example2.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#11</a>
<pre>
 1 Test alpha-split-cache-example2 Allowed
 2 States 2
 3 1:r1=u; 1:r2=0;
 4 1:r1=v; 1:r2=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (1:r1=v /\ 1:r2=0)
 9 Observation alpha-split-cache-example2 Never 0 2
10 Hash=9dbdccdc417b3ece717775094d822a49
</pre>
</blockquote>

The <tt>smp_read_barrier_depends()</tt> call forces P1 to wait until
all writes that have already propagated to its cache have been fully handled
and are available for reading.
Thus, the new value of <tt>v</tt> is always visible to P1 whenever it
sees <tt>&amp;v</tt> in <tt>p</tt>.

<p><a name="Quick Quiz 13"><b>Quick Quiz 13</b>:</a>
Given how important split caches are for attaining full performance on
superscalar CPUs, why don't any non-Alpha architectures have split caches?
<br><a href="#qq13answer">Answer</a>

<p>
In order to accomodate Alpha's unique behavior, we modified the memory model
to include a delay between the time when a write propagates to a CPU
and the time when the memory subsystem can use that write to satisfy
a read request.
Furthermore, instead of assuming a simple split, the model allows
the cache to be completely fragmented, with an independent segment for
each memory address.

<p>
The model introduces the notion of a <i>horizon time</i>.
Given a read instruction <tt>R</tt> on processor Pn, <tt>horiz(R)</tt>
(the horizon time for <tt>R</tt>) is the most recent time <tt>h</tt>,
before or equal to the time when <tt>R</tt> executes,
such that a write to <tt>R</tt>'s target address propagating to Pn
from another processor by time <tt>h</tt> would be fully handled by the cache
and available for satisfying <tt>R</tt>.
Writes that propagate to Pn after <tt>h</tt> are considered still to be
&ldquo;below the horizon&rdquo; when <tt>R</tt> executes,
and so are not visible and cannot be used for satisfying <tt>R</tt>.
(This restriction does not apply to writes executed by Pn itself;
each processor can see its own writes at any time.)

<p>
The memory model requires that once a write has propagated to Pn and been
fully handled by the cache, it is visible to all future reads.
It follows that for each Pn and each address <tt>A</tt>,
the horizon times of reads on Pn that target <tt>A</tt> must not decrease
over time (figuratively, a write cannot fall back below the horizon after
it has become visible).
If such things were allowed to happen, we could have a violation of the
read-read coherence rule.
The model also requires that every memory barrier other than
<tt>smp_wmb()</tt> behave like
<tt>smp_read_barrier_depends()</tt>, in that it forces the CPU to wait
for all writes that propagated to the CPU before the barrier committed
to become visible.
In other words, if Pn executes a memory barrier at time <tt>t</tt> then
any read instruction <tt>R</tt> in the barrier's post-set will have
<tt>horiz(R) &ge; t</tt>.
If the barrier is a strong one, the CPU is required to wait for all
writes that propagated to the CPU before the barrier was acknowledged
to become visible.

<p>
While the actual values of the horizon times during an execution are
unknowable, we can nevertheless reason about their values.
As mentioned above, we know that <tt>horiz(R) &le; exec(R)</tt>,
where <tt>exec(R)</tt> is the time when <tt>R</tt> executes.
And we know that if <tt>R</tt> and <tt>R'</tt> target the same address
and execute on the same CPU then <tt>exec(R) &le; exec(R')</tt> implies
<tt>horiz(R) &le; horiz(R')</tt>.

<p>
More important is this key fact about horizon times:
If <tt>R</tt> reads from a write <tt>W</tt>
and <tt>W'</tt> is another write to the same address
that comes after <tt>W</tt> in the coherence order,
then <tt>W'</tt> must propagate to <tt>R</tt>'s CPU after <tt>horiz(R)</tt>.
Otherwise <tt>W'</tt> would have been available to satisfy <tt>R</tt>,
so <tt>R</tt> would have read from it instead of from <tt>W</tt>.
This conclusion remains true even if <tt>W</tt> is forwarded to <tt>R</tt>.
In that case, <tt>R</tt> executes before <tt>W</tt> does;
then the fact that <tt>W'</tt> comes after <tt>W</tt> in the coherence order
means that <tt>W'</tt> must propagate to <tt>W</tt>'s (and <tt>R</tt>'s) CPU
after <tt>W</tt> executes, hence after <tt>R</tt> executes
and thus after <tt>horiz(R)</tt>.

<p>
Adding the concept of horizon times complicates the ordering of reads.
When we say that read <tt>A</tt> is ordered before read <tt>B</tt>,
we could now mean any of four things:

<ul>
<li>	<tt>exec(A) &le; horiz(B)</tt>
	(we call this the <tt>Alpha-strong-ppo</tt> relation);
<li>	<tt>horiz(A) &le; horiz(B)</tt>
	(the <tt>Alpha-normal-ppo</tt> relation);
<li>	<tt>exec(A) &le; exec(B)</tt>
	(the <tt>Alpha-weak-ppo</tt> relation);
	or
<li>	<tt>horiz(A) &le; exec(B)</tt>
	(the memory model doesn't use this).
</ul>

These conditions are not mutually exclusive.
<tt>Alpha-normal-ppo</tt> and <tt>Alpha-weak-ppo</tt> both contain
<tt>Alpha-strong-ppo</tt>, because <tt>horiz(A) &le; exec(A)</tt>
and <tt>horiz(B) &le; exec(B)</tt> respectively.
This classification can be extended to cover write instructions
by declaring a write's horizon time simply to be the same as its
execution time.

<p>
We now face a subtle question:
Which of these various PPO relations should be included in <tt>hb</tt>?
To answer this, think back to the Propbase property defined
<a href="#Propbase property">earlier</a>.
If <tt>W</tt> and <tt>R</tt> possess the Propbase property then we know
that <tt>W</tt> propagate's to <tt>R</tt>'s CPU before <tt>R</tt> executes.
But on Alpha, that doesn't mean very much.
We would really like to know that <tt>W</tt> propagates to <tt>R</tt>'s CPU
before <tt>horiz(R)</tt>, so that <tt>W</tt> is available to satisfy <tt>R</tt>.

<p>
Furthermore, we want to retain the principle that a B-cumulative barrier's
post-set is closed under <tt>hb</tt>.
In other words, if <tt>W</tt> and <tt>R</tt> have the Propbase property
(implying that <tt>W</tt> propagates to <tt>R</tt>'s CPU before
<tt>horiz(R)</tt>)
where the relevant memory barrier is B-cumulative,
and if <tt>R &#10230; R'</tt> is a link in <tt>hb</tt>
where <tt>R</tt> and <tt>R'</tt> are on the same CPU,
then <tt>W</tt> and <tt>R'</tt> should also have the Propbase property,
implying that <tt>W</tt> propagates to that CPU before <tt>horiz(R')</tt>.
The only way to guarantee this is to require that
<tt>horiz(R) &le; horiz(R')</tt> whenever there is an <tt>hb</tt> link
from <tt>R</tt> to <tt>R'</tt> on the same CPU.

<p>
Therefore, in order to make things work out the way we want,
we will redefine <tt>hb</tt> to include <tt>alpha-normal-ppo</tt>,
not <tt>Alpha-weak-ppo</tt>.
However, this doesn't mean we can ignore <tt>Alpha-weak-ppo</tt> entirely.
Suppose there is an <tt>Alpha-weak-ppo</tt> link from <tt>A</tt> to <tt>B</tt>
followed by an <tt>Alpha-strong-ppo</tt> link from <tt>B</tt> to <tt>C</tt>.
Then we have <tt>exec(A) &le; exec(B) &le; horiz(C)</tt>,
so effectively there is an <tt>Alpha-strong-ppo</tt> link from <tt>A</tt>
to <tt>C</tt> and thus we should have <tt>A &#10230; C</tt> in <tt>hb</tt>.

<p>
<a name="Alpha ppo modifications">To see how this works out in practice</a>,
let's consider each of the
<a href="#Program Order Requirements">program order requirements</a>
mentioned earlier and determine how each one falls under this classification.

<p>
<ol>
<li>	<tt>A</tt> is a read, <tt>B</tt> is a write, and there is a
	control dependency from <tt>A</tt> to <tt>B</tt>
	(i.e., whether <tt>B</tt> gets executed depends on which leg
	of some conditional branch is taken, and the branch's condition
	depends on the value read by <tt>A</tt>).
	Since <tt>A</tt>'s value isn't known until <tt>A</tt> executes,
	we have <tt>exec(A) &le; exec(B) = horiz(B)</tt>.
	Thus there is an <tt>Alpha-strong-ppo</tt> link from <tt>A</tt>
	to <tt>B</tt>.
<li>	There is an address or data dependency from <tt>A</tt> to <tt>B</tt>.
	Then <tt>B</tt> can't execute until <tt>A</tt>'s value is known,
	so <tt>exec(A) &le; exec(B)</tt>.
	If <tt>B</tt> is a read then this yields only an
	<tt>Alpha-weak-ppo</tt> link, whereas if <tt>B</tt> is a write
	then as above it yields an <tt>Alpha-strong-ppo</tt> link.
<li>	There is an address or data dependency from <tt>A</tt> to a write
	that is forwarded to <tt>B</tt>.
	The write can't be forwarded to <tt>B</tt> before <tt>A</tt>'s
	value is known, so again we have <tt>exec(A) &le; exec(B)</tt>
	and this yields an <tt>Alpha-weak-ppo</tt> link.
<li>	<tt>B</tt> is a write and <tt>A</tt> is the source of an
	address dependency to a memory access instruction between them.
	Then <tt>B</tt> can't execute until it is known whether the
	intervening memory access will generate an addressing exception,
	which requires <tt>A</tt>'s value to be known.
	Thus <tt>exec(A) &le; exec(B) = horiz(B)</tt>, so this yields
	an <tt>Alpha-strong-ppo</tt> link.
<li>	<tt>B</tt> is a write and <tt>A</tt> accesses the same address
	as <tt>B</tt>.
	Then <tt>B</tt> can't execute until <tt>A</tt> does.
	As before, since <tt>B</tt> is a write this yields an
	<tt>Alpha-strong-ppo</tt> link.
<li>	<tt>A</tt> and <tt>B</tt> read from different writes to the same
	address, and <tt>B</tt> is not forwarded from a write that is
	between them.
	In this situation, the ordering requirement states that the CPU must
	execute <tt>B</tt> after it executes <tt>A</tt>, so
	<tt>exec(A) &le; exec(B)</tt> and we have an <tt>Alpha-weak-ppo</tt>
	link.
	But the read-read coherence rule says that the write which <tt>B</tt>
	reads from must come later in the coherence order
	than the write which <tt>A</tt> reads from.
	Then by the key fact about horizon times,
	<tt>B</tt>'s write must have propagated to the CPU
	at a time after <tt>horiz(A)</tt>, but before <tt>horiz(B)</tt>
	as otherwise <tt>B</tt> would not have read from it.
	This means it must also be true that <tt>horiz(A) &le; horiz(B)</tt>,
	and so in this case we also have an <tt>Alpha-normal-ppo</tt> link
	from <tt>A</tt> to <tt>B</tt>.
<li>	<tt>A</tt> is a write and <tt>B</tt> is a read of the same address,
	and <tt>B</tt> is not forwarded from <tt>A</tt> or from a write
	that is between them.
	Since the write that <tt>B</tt> reads from must come later in the
	coherence order than <tt>A</tt>, it must have propagated to the CPU
	after <tt>A</tt> executed.
	But since it propagated to the CPU at or before <tt>horiz(B)</tt>,
	we see that <tt>exec(A) &le; horiz(B)</tt>.
	Thus this case yields an <tt>Alpha-strong-ppo</tt> link.
<li>	There is a memory barrier with <tt>A</tt> in the pre-set and
	<tt>B</tt> in the post-set.
	Then <tt>A</tt> executes before the barrier does and <tt>B</tt>'s
	horizon time is later than the barrier execution time,
	so <tt>exec(A) &le; horiz(B)</tt> and again we have an
	<tt>Alpha-strong-ppo</tt> link.
</ol>

<p>
The same type of analysis can be applied to the other two relations
that make up <tt>hb</tt>, namely, <tt>rfe</tt> and <tt>obs</tt>.
If <tt>A</tt> is a write and <tt>B</tt> reads from <tt>A</tt> on another CPU
then <tt>A</tt> must propagate to <tt>B</tt>'s CPU before <tt>horiz(B)</tt>.
Thus <tt>exec(A) &le; horiz(B)</tt>, so <tt>rfe</tt> is analogous to
<tt>Alpha-strong-ppo</tt> (if we overlook the fact that PPO relations
only apply to instructions on the same CPU).

<p>
As for <tt>obs</tt>, consider first a <tt>short-obs</tt> scenario:

<blockquote>
<tt>A &#10230;<sub>fre</sub> X &#10230;<sub>propbase</sub> Y
&#10230;<sub>rfe</sub> B</tt>
</blockquote>

where <tt>A</tt> and <tt>B</tt> are on the same CPU.
We know that <tt>Y</tt> propagates to this CPU before <tt>horiz(B)</tt>
because of the <tt>rfe</tt> link between them.
The <tt>propbase</tt> link from <tt>X</tt> to <tt>Y</tt> implies that
<tt>X</tt> propagates to this CPU before <tt>Y</tt> does.
But the <tt>fre</tt> link from <tt>A</tt> to <tt>X</tt> says that
<tt>X</tt> comes later in the coherence order than the write which
<tt>A</tt> reads from.
So by the key fact about horizon times, <tt>X</tt> propagates to <tt>A</tt>'s
CPU after <tt>horiz(A)</tt>, which means that
<tt>horiz(A) &lt; horiz(B)</tt>.
Thus <tt>strict-obs</tt> yields an <tt>Alpha-normal-ppo</tt> link.

<p>
In a more general <tt>obs</tt> scenario we might have:

<blockquote>
<tt>A &#10230;<sub>hb*</sub> U &#10230;<sub>fre</sub> X
&#10230;<sub>B-cum-propbase</sub> Y &#10230;<sub>rfe</sub> B</tt>
</blockquote>

with <tt>A</tt> and <tt>B</tt> on the same CPU.
If <tt>horiz(B) &le; horiz(A)</tt> then there would be an
<tt>Alpha-normal-ppo</tt> link from <tt>B</tt> to <tt>A</tt>,
and hence an <tt>hb</tt> link.
Together with the <tt>rfe</tt> from <tt>Y</tt> to <tt>B</tt>,
this would provide a sequence of <tt>hb</tt> links connecting
<tt>Y</tt> all the way to <tt>U</tt>.
Then by B-cumulativity, <tt>U</tt> would be in the post-set of the
<tt>B-cum-propbase</tt>'s memory barrier, implying that <tt>X</tt>
would propagate to <tt>U</tt>'s CPU before <tt>horiz(U)</tt>.
But this would contradict the fact that <tt>U</tt> reads from a write
that is earlier than <tt>X</tt> in the coherence order, as expressed
by the <tt>fre</tt> link from <tt>U</tt> to <tt>X</tt>.
Therefore we must have <tt>horiz(A) &le; horiz(B)</tt>, meaning that
<tt>obs</tt> in general yields an <tt>Alpha-normal-ppo</tt> link.
A similar analysis of <tt>short-obs</tt> and <tt>obs</tt> applies when
the link to <tt>X</tt> is <tt>coe</tt> rather than <tt>fre</tt>.

<p>
To sum up, most PPO relations give rise to <tt>Alpha-strong-ppo</tt> links.
The exceptions are:

<ul>
<li>	<tt>obs</tt> yields an <tt>Alpha-normal-ppo</tt> link.
<li>	<tt>addr</tt> between two reads and <tt>dep-rfi</tt>
	yield <tt>Alpha-weak-ppo</tt> links.
<li>	<tt>rdw</tt> yields a link that is in both <tt>Alpha-weak-ppo</tt>
	and <tt>Alpha-normal-ppo</tt>, but not in <tt>Alpha-strong-ppo</tt>.
</ul>

The <tt>hb</tt> relation can contain arbitrary sequences of PPO links,
with one exception:
There must not be an <tt>Alpha-weak-ppo</tt> link followed by an
<tt>Alpha-normal-ppo</tt> link.
For example, if we had <tt>A &#10230; B</tt> in <tt>Alpha-weak-ppo</tt>
and <tt>B &#10230; C</tt> in <tt>Alpha-normal-ppo</tt>,
the meaning would be that <tt>exec(A) &le; exec(B)</tt> and
<tt>horiz(B) &le; horiz(C)</tt>.
But since <tt>exec(B) &ge; horiz(B)</tt>,
we would not be able to deduce any ordering between <tt>A</tt> and <tt>C</tt>.
In fact, this is exactly what happens in
<a href="#litmus10">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#10</a>
above.
In that litmus test there is a cycle consisting of a <tt>short-obs</tt>
link followed by an <tt>addr</tt> link between two reads.
As we saw, such cycles are allowed on Alpha.
This suggests redefining <tt>hb</tt> somewhat along these lines:

<blockquote>
<tt>let hb = Alpha-normal-ppo | (ppo* ; Alpha-strong-ppo) | rfe</tt>
</blockquote>

where <tt>ppo</tt> is the union of all the various PPO relations.

<p>
There is one additional wrinkle.
Suppose we have a sequence of <tt>Alpha-weak-ppo</tt> links with
a read-dependency barrier somewhere in the middle, such as this:

<blockquote>
<pre>
int **r1, **g;
int *r2;
int r3;

r1 = READ_ONCE(g);             /* A */
smp_read_barrier_depends();    /* B */
r2 = READ_ONCE(*r1);           /* C */
r3 = READ_ONCE(*r2);           /* D */
</pre>
</blockquote>

Here there are address dependencies between reads <tt>A</tt> and <tt>C</tt>
and between reads <tt>C</tt> and <tt>D</tt>.
On a PowerPC system, this would already give an <tt>hb*</tt> link from
<tt>A</tt> to <tt>D</tt>.
On Alpha, all we can conclude is that
<tt>exec(A) &le; exec(C) &le; exec(D)</tt>.
However, on Alpha the read-dependency memory barrier at <tt>B</tt>
forces the horizon times for all po-later reads to be after the execution time
of the barrier, which in turn is after the execution time of <tt>A</tt>.
This means <tt>exec(A) &le; exec(B) &le; horiz(D)</tt>,
which gives us an <tt>Alpha-strong-ppo</tt> link from <tt>A</tt> to <tt>D</tt>
and therefore an <tt>hb</tt> link.
Thus, in this peculiar situation we always have an <tt>hb*</tt> link from
<tt>A</tt> to <tt>D</tt>, even though the reasons for the link are different
on different types of system.

<p>
The memory model takes this into account by defining a new relation
(how else?) with the unwieldy name &ldquo;<tt>rd-addr-dep-rfi</tt>&rdquo;:

<blockquote>
<tt>let rd-addr-dep-rfi = (addr | dep-rfi)+ &amp; rd-dep-fence</tt>
</blockquote>

This expresion omits <tt>rdw</tt> because of issues related to the
ARM memory model,
but otherwise it captures the idea of a sequence of <tt>Alpha-weak-ppo</tt>
links with an intervening read-dependency barrier.
The definition of <tt>Alpha-strong-ppo</tt> can then include
<tt>rd-addr-dep-rfi</tt>, giving the desired results.

<p>
This extended memory model for Alpha reduces to the original
if we assume the horizon times for different memory addresses are always equal
(i.e., the cache is not segmented).
Under this assumption the extended model will allow the same set of behaviors
as the original,
which is reassuring; it means the model still applies as before
to architectures other than Alpha.

<h2><a name="Adjustments for ARM">Adjustments for ARM</a></h2>

<p>
Unfortunately, the memory model as developed above is
not a very good fit for the ARM architecture.
The published memory models for ARMv8 differ in a number of important respects
from the model we have described so far.
Most of the differences involve the memory subsystem,
and most of the differences that affect the processor subsystem
are concerned with how it interacts with the memory subsystem.

<p>
The difference with perhaps the most widespread ramifications involves
how the memory subsystem responds to read requests.
Earlier we said that the response would be the value stored by the
coherence-latest write that has propagated to the CPU making the request,
because otherwise the read might observe a coherence-earlier value than
a po-earlier read of the same address did, violating the read-read
<a href="LinuxMMModel.html#coherence rules">coherence rule</a>.
But this requirement is stronger than necessary; all we really need
is that the response to a read request should be coherence-later than
(or the same as) any po-earlier read responses or committed writes
for the same address.
It doesn't have to be the very latest write available,
and on ARM it often isn't.

<p>
Furthermore, the ARM memory model does not include any feature
analogous to acknowledging a strong memory barrier.
Instructions following such a barrier can be executed as soon as
the barrier has been committed.
These two facts have some rather subtle effects on the ordering properties
of memory accesses.
For example, either one of them invalidates the reasoning we used
when analyzing
<a href="#litmus1">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>
above.
The test remains forbidden even on ARM, but not for the reasons we gave.

<p>
Instead, the ARM memory model guarantees that
if a write <tt>W</tt> reaches the coherence point before a strong
(<tt>smp_mb()</tt>) barrier, then the response to any read that is
po-after the barrier and accesses the same address as <tt>W</tt> will be
the value stored by <tt>W</tt> or a coherence-later write.
(No similar guarantee is made by the PowerPC-based memory model
presented above,
which is an indication of how much ARM differs from PowerPC.)
This is enough to show that the &ldquo;exists&rdquo; clause in
<a href="#litmus1">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>
will never be satisfied.

<p>
When the test is executed, one of the two memory barriers must reach
the coherence point before the other.
Suppose the barrier in P0 gets there first.
Since P0's write to <tt>x</tt> is in the barrier's pre-set,
it will reach the coherence point before the barrier does
and hence before P1's barrier does.
Thus P1's read of <tt>x</tt>, which is po-after the barrier,
is guaranteed to see P0's write (there aren't any coherence-later
writes to <tt>x</tt> in the test program),
and so <tt>r2</tt> will end up equal to 1, not 0.
As before, the opposite case is symmetrical.

<p>
<a name="ARM obscured writes">Another difference concerns the way CPUs execute writes</a>.
On ARM, two writes to the same address are permitted to commit
out of program order.
Earlier we said that if this happened, it would cause the memory subsystem
to put the po-later write earlier in the coherence order,
thereby violating the write-write coherence rule.
ARM gets around this problem in a very straightforward way:
When a write <tt>W</tt> commits after a po-later write <tt>W'</tt>
to the same address, the CPU simply skips sending <tt>W</tt>
to the memory subsystem!
As a result, <tt>W</tt> never gets assigned an explicit location
in the coherence order (effectively, it ends up ordered immediately before
the next write, in program order, to the same address),
it never reaches the coherence point,
and it never gets propagated to any other CPUs.
We say that <tt>W</tt> has been <i>obscured</i> by <tt>W'</tt>,
or more colloquially, <i>erased</i>.
Its effects don't disappear entirely, because the value stored by
<tt>W</tt> can still be forwarded to reads that lie between <tt>W</tt>
and <tt>W'</tt>.
But this is the next best thing;
from a system-wide standpoint, the end result is practically the same
as if <tt>W'</tt> had followed so closely on the heels of <tt>W</tt> that
<tt>W</tt> was overwritten before any other CPU had a chance to
read from it.

<p>
There are certain circumstances in which a write <tt>W</tt>
cannot be obscured.
For example, if the CPU encounters a memory barrier that orders <tt>W</tt>
before some other write <tt>W'</tt> to the same address,
then <tt>W'</tt> cannot commit until after the barrier does,
and the barrier cannot commit until after <tt>W</tt> does,
so the writes cannot commit out of program order
and <tt>W'</tt> will not obscure <tt>W</tt>.
Also, the writes associated with store-release instructions
(<tt>smp_store_release()</tt> or <tt>rcu_assign_pointer()</tt>)
or atomic RMW instructions are not allowed to be obscured.
More trivially, <tt>W</tt> will not be obscured if there are no
po-later writes to the same address in its process to obscure it.
Taking all of this into account will complicate the final memory model,
as you might imagine.

<p>
There are some other, less important, differences in the operation
of the CPU subsystem in the ARM model:

<ul>
<li>	When a store-release instruction is committed,
	the CPU does not issue a barrier request followed by a write request;
	instead it issues a write request that is specially marked
	as being a store-release.
<li>	Similarly, a load-acquire instruction gives rise to
	a single read request that is specially marked as being a load-acquire.
<li>	An <tt>smp_rmb()</tt> instruction does not act entirely within the CPU;
	it causes the CPU to issue a barrier request to the memory subsystem.
<li>	The rules for restarting a read instruction after a po-earlier
	instruction has accessed the same address are slightly looser;
	the read does not need to be restarted if it was issued after the
	po-earlier instruction was.
<li>	A write instruction that accesses the same address as a po-earlier read
	may be committed before the read is committed, provided the read has
	already been issued and the CPU knows that it will not be restarted.
</ul>

<p>
To better understand the ARM model,
we must examine how the memory subsystem works in some detail.
It is more highly structured than the memory subsystem in the PowerPC model,
consisting of a hierarchical arrangement of buffers lying between
the CPUs at the top and the memory at the bottom.
There is a buffer immediately below each CPU; these feed down into
some buffers below them, and then buffers below those, and so on,
down to the lowermost buffer, which feeds into memory.
The coherence point is the place at the bottom of the lowest buffer.

<p>
For example, a four-processor system would have four buffers at
the topmost layer, then at the next layer there might be
a buffer below CPUs 0 and 1 and another below CPUs 2 and 3,
and a single buffer below all the CPUs
in the final layer, as shown in this figure (panel A):

<p><img src="ARM-memory-subsystem.svg" width="90%"></p>

Other arrangements of buffers (such as that in panel B) are possible,
provided they follow the general hierarchical arrangement:
buffers always feed down, never up;
a buffer can receive input from multiple buffers above it but can
provide output only to a single buffer below; and there is a single
lowermost buffer which all the others eventually lead to.
The memory models do not specify the buffer sizes or topology,
and in practice you cannot even rely on the topology remaining unchanged
over time, because the scheduler can migrate a process from one CPU to another,
effectively altering the arrangement of the buffers below that process.

<p>
(The essential difference between the Flowing and POP models is that
the Flowing model assumes a fixed buffer topology,
whereas the POP model does not keep explicit track of the buffers
and thus is compatible with any arrangement.
The POP model is more general, but the Flowing model is easier to
reason about.)

<p>
A key point of this design is that the memory subsystem does not provide
the response to a read request immediately.
Issuing a read request and receiving the response (which is then used
to satisfy the read) are two separate events, and the CPU is free
to work on other instructions in between.

<p>
When a CPU issues a write, barrier, or read request, the request
enters the CPU's buffer at the top, flows through the buffer and then
down into the top of the buffer below, and so on, eventually passing
out the bottom of the lowermost buffer, to memory.
Thus, the coherence order is simply the order in which write requests
flow down to memory.
When a write request reaches memory, the value in the request gets
stored at the write's target address.
When a barrier request reaches memory, its job is finished and it disappears.
And when a read request reaches memory, a response is generated using
the value held in memory at the read's target address.

<p>
However, the response to a read request may be generated before
the request reaches memory, while it is still flowing through a buffer.
If the request immediately below the read in the buffer
is a write to the same address,
the memory subsystem can respond to the read using the value stored
by that write.
When this happens, the memory subsystem deletes the read request,
but it keeps track of the fact that the write request was used
to satisfy the read.
(Exception: a load-acquire request is not allowed to be satisfied by
a store-release request while still in a buffer.
The only way for a load-acquire instruction to read the value written
by a store-release instruction is for the load-acquire request to flow
all the way down to memory.)
Either way, the read request is gone when the response is generated;
the memory subsystem never generates more than one response to a request.

<p>
The flow of requests down through a buffer is not always
First-In-First-Out.
Subject to certain restrictions, a request is allowed to exchange
places with the request immediately below it (it <i>passes</i>
the lower request).
The complete list of reorder restrictions is rather elaborate;
among the most important ones are:

<ul>
<li>	A read or write request may not pass another read or write request
	with the same target address.
<li>	No barrier request may pass another barrier request.
<li>	No request may pass an <tt>smp_mb()</tt> barrier or vice versa.
<li>	An <tt>smp_wmb()</tt> barrier request may not pass a write request
	from its own CPU, and it may not be passed by any write request.
<li>	An <tt>smp_rmb()</tt> barrier request may not pass a read request
	from its own CPU, and it may not be passed by a write or read request
	from its own CPU.
<li>	A store-release write request may not pass any write or read request.
<li>	A load-acquire read request may not be passed by a write or read
	request from its own CPU.
</ul>

In addition, if a read request <tt>R</tt> is not allowed to pass some
other request <tt>A</tt> then neither is the write request (if any)
that was used to satisfy <tt>R</tt>, and if <tt>A</tt> is not allowed
to pass <tt>R</tt> then it's not allowed to pass the write request (if any)
that was used to satisfy <tt>R</tt>.

<p>
A write is said to propagate to a CPU when its request flows into
a buffer below that CPU, because before that time there is no way for the CPU
to read from the write,
whereas afterward it is possible for a read
request issued by the CPU to be satisfied by the write request,
whether in a buffer or in memory.
This picture explains why a read might not be satisfied by
the coherence-latest write to have propagated to the read's CPU.
A read request <tt>R</tt> for the value of <tt>x</tt>, for example,
might not be satisfied until it reaches memory and obtains an old value,
even though a write request <tt>W</tt> containing a new value for <tt>x</tt>
may already have flowed down to a buffer below <tt>R</tt>'s CPU.
Provided that <tt>W</tt> lies higher than <tt>R</tt> in the
chain of buffers leading from the CPU to memory,
<tt>R</tt> will be unable to read the value stored by <tt>W</tt>:
The write request can't pass the read request
because they have the same target address,
so it can never reach a buffer position immediately below <tt>R</tt>
and it cannot reach memory before <tt>R</tt> does.
Thus <tt>R</tt> will end up being satisfied by an earlier value of <tt>x</tt>
even though the coherence-later value in <tt>W</tt> had already
propagated to <tt>R</tt>'s CPU by that time.

<p>
Now we can understand how the ARM memory model enforces
the strong-barrier guarantee mentioned above.
Suppose <tt>F</tt> is a strong fence and <tt>R</tt> is a read that is
po-after <tt>F</tt>.
Suppose also that <tt>W</tt> is a write to the same address as <tt>R</tt>,
and <tt>W</tt> reaches the coherence point before <tt>F</tt> does.
Then <tt>W</tt> must flow down to memory before <tt>F</tt>, and since
<tt>R</tt> cannot pass <tt>F</tt>, it cannot reach memory before <tt>W</tt>.
Thus, if <tt>R</tt> is satisfied from memory then it must read the value
stored by <tt>W</tt> or a coherence-later write.

<p>
But what if <tt>R</tt> is satisfied while it is still in a buffer?
Let <tt>W'</tt> be the write request that satisfies <tt>R</tt>.
Since it is immediately below <tt>R</tt> in the buffer at the time
that <tt>R</tt> is satisfied, it must also be above <tt>F</tt>.
And since <tt>W'</tt> cannot pass <tt>F</tt>, it must reach memory
after <tt>W</tt>, which means it must be coherence-later than <tt>W</tt>.
The case where <tt>R</tt> is not issued at all, but is forwarded from a
po-earlier write, is left to the reader.
Regardless, no matter how things work out, in the end <tt>R</tt> will
read from <tt>W</tt> or a coherence-later write, as guaranteed.

<p>
One other aspect of the storage subsystem needs mentioning.
In the PowerPC-based operational model, the write part of an atomic RMW
instruction reaches the coherence point at the time it commits.
In the ARM memory model this is not true; RMW writes flow down through
the buffers just like any other.
Instead, the architecture relies on an intricate system of interlocks
to prevent other write requests to the same address from flowing down
into the wrong buffer at the wrong time and thereby &ldquo;sneaking&rdquo;
in ahead of the RMW write, violating the atomic property.

<p>
Like we saw with the Alpha, the fact that reads are issued and satisfied
at different times leads to an ambiguity when we want to order read
instructions.
If we say that instruction <tt>A</tt> is ordered before <tt>B</tt>,
where one or both is a read, we could mean:

<ul>
<li>	<tt>exec(A) &le; issue(B)</tt>
	(<a href="#Program Order Requirements">ordering requirements
	2, 7, and 9-10 with one exception</a>);
<li>	<tt>issue(A) &le; issue(B)</tt>
	(<a href="#Program Order Requirements">requirements 6 and
	9 where <tt>A</tt> is load-acquire and <tt>B</tt> is read</a>);
<li>	<tt>exec(A) &le; exec(B)</tt>;
	(<a href="#Program Order Requirements">requirements 3-4 and 8</a>);
	or
<li>	<tt>issue(A) &le; exec(B)</tt>
	(<a href="#Program Order Requirements">requirement 5</a>).
</ul>

where <tt>issue(A)</tt> is the time when <tt>A</tt>'s read request is
issued to the memory subsystem, and <tt>exec(A)</tt> is the time when
<tt>A</tt> is executed (which is the time when the read response is
received, if <tt>A</tt> is a non-forwarded read).

<p>
TO BE CONTINUED...


<h2><a name="Adjustments for other architectures">Adjustments for other architectures</a></h2>

<p>
Currently there are none.
This may change in the future as we become aware of the individual
requirements of other CPU families.

<p><a name="Quick Quiz 14"><b>Quick Quiz 14</b>:</a>
Why weren't adjustments needed for PowerPC, given that it has a weak
memory model?
<br><a href="#qq14answer">Answer</a>

<p><a name="Quick Quiz 15"><b>Quick Quiz 15</b>:</a>
Why weren't adjustments needed for Itanium, given that it allows
reads to the same variable to be reordered?
<br><a href="#qq15answer">Answer</a>

<p><a name="Quick Quiz 16"><b>Quick Quiz 16</b>:</a>
But what if some new CPU had an even weaker memory model than
Alpha, ARM, and PowerPC?
Mightn't that invalidate a lot of Linux-kernel code?
<br><a href="#qq16answer">Answer</a>



<h2><a name="Strong-Model Bell File">Strong-Model Bell File</a></h2>

<p>The full
<a href="herd.html#Bell">Bell</a>
file for Alan Stern's strong model
is as follows:

<blockquote>
<a id="strong-kernel.bell" href="strong-kernel.bell">strong-kernel.bell</a>
<pre>
  1 "Linux kernel strong memory model"
  2
  3 (*
  4  * Copyright (C) 2016 Alan Stern &lt;stern@rowland.harvard.edu&gt;,
  5  *          Andrea Parri &lt;parri.andrea@gmail.com&gt;
  6  *
  7  * This program is free software; you can redistribute it and/or modify
  8  * it under the terms of the GNU General Public License as published by
  9  * the Free Software Foundation; either version 2 of the License, or
 10  * (at your option) any later version.
 11  *
 12  * This program is distributed in the hope that it will be useful,
 13  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 14  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 15  * GNU General Public License for more details.
 16  *
 17  * You should have received a copy of the GNU General Public License
 18  * along with this program; if not, you can access it online at
 19  * http://www.gnu.org/licenses/gpl-2.0.html.
 20  *)
 21
 22 enum Accesses = 'once (*READ_ONCE,WRITE_ONCE,ACCESS_ONCE*) ||
 23     'release (*smp_store_release*) ||
 24     'acquire (*smp_load_acquire*) ||
 25     'assign (*rcu_assign_pointer*) ||
 26     'deref (*rcu_dereference*) ||
 27     'lderef (*lockless_dereference*)
 28 instructions R[{'once,'acquire,'deref,'lderef}]
 29 instructions W[{'once,'release,'assign}]
 30 instructions RMW[{'once,'acquire,'release}]
 31
 32 enum Barriers = 'wmb (*smp_wmb*) ||
 33     'rmb (*smp_rmb*) ||
 34     'mb (*smp_mb*) ||
 35     'rb_dep (*smp_read_barrier_depends*) ||
 36     'rcu_read_lock (*rcu_read_lock*)  ||
 37     'rcu_read_unlock (*rcu_read_unlock*) ||
 38     'sync (*synchronize_rcu*)
 39 instructions F[Barriers]
 40
 41 (* Treat 'release and 'assign identically; same for 'deref and 'lderef *)
 42 let ReleaseAssign = Release | Assign
 43 let XDeref = Deref | Lderef
 44
 45 let rmb = fencerel(Rmb) &amp; (R*R)
 46 let wmb = fencerel(Wmb) &amp; (W*W)
 47 let mb = fencerel(Mb)
 48 let sync = (po &amp; (_ * Sync)) ; (po?)
 49
 50 let rb-dep = fencerel(Rb_dep) &amp; (R*R)
 51 let acq-po = po &amp; (Acquire*_)
 52 let xderef-po = po &amp; (XDeref*M)
 53 let po-relass = po &amp; (_*ReleaseAssign)
 54
 55 let rd-dep-fence = rb-dep | xderef-po
 56 let strong-fence = mb | sync
 57
 58 (* Compute matching pairs of nested Rcu_read_lock and Rcu_read_unlock *)
 59 let matched = let rec
 60       unmatched-locks = Rcu_read_lock \ domain(matched)
 61   and unmatched-unlocks = Rcu_read_unlock \ range(matched)
 62   and unmatched = unmatched-locks | unmatched-unlocks
 63   and unmatched-po = (unmatched * unmatched) &amp; po
 64   and unmatched-locks-to-unlocks = (unmatched-locks *
 65       unmatched-unlocks) &amp; po
 66   and matched = matched | (unmatched-locks-to-unlocks \
 67     (unmatched-po ; unmatched-po))
 68   in matched
 69
 70 (* Validate nesting *)
 71 flag ~empty Rcu_read_lock \ domain(matched) as unbalanced-rcu-locking
 72 flag ~empty Rcu_read_unlock \ range(matched) as unbalanced-rcu-locking
 73
 74 (* Outermost level of nesting only *)
 75 let crit = matched \ (po^-1 ; matched ; po^-1)
</pre>
</blockquote>

<p>Taking this one piece at a time:

<ol>
<li>	<a href="#Bell File: Memory Accesses">Bell File: Memory Accesses</a>.
<li>	<a href="#Bell File: Barriers">Bell File: Barriers</a>.
<li>	<a href="#Bell File: Relating Barriers and Memory Accesses">
	Bell File: Relating Barriers and Memory Accesses</a>.
<li>	<a href="#Bell File: Relating One-Sided Barriers and Memory Accesses">
	Bell File: Relating One-Sided Barriers and Memory Accesses</a>.
<li>	<a href="#Bell File: Classes of Fences">
	Bell File: Classes of Fences</a>.
<li>	<a href="#Bell File: RCU Read-Side Critical Sections">
	Bell File: RCU Read-Side Critical Sections</a>.
</ol>

<h3><a name="Bell File: Memory Accesses">Bell File: Memory Accesses</a></h3>

<p>The &ldquo;<tt>"Linux kernel strong memory model"</tt>&rdquo; is a name
that has no effect on the model's meaning.

<p>The following portion of the Bell file defines the
types of memory accesses, which correspond to the Linux kernel's
<tt>READ_ONCE()</tt>,
<tt>WRITE_ONCE()</tt>,
<tt>ACCESS_ONCE()</tt>,
<tt>smp_store_release()</tt>,
<tt>smp_load_acquire()</tt>,
<tt>rcu_assign_pointer()</tt>,
<tt>rcu_dereference()</tt>, and
<tt>lockless_dereference()</tt> primitives:

<blockquote>
<pre>
 22 enum Accesses = 'once (*READ_ONCE,WRITE_ONCE,ACCESS_ONCE*) ||
 23     'release (*smp_store_release*) ||
 24     'acquire (*smp_load_acquire*) ||
 25     'assign (*rcu_assign_pointer*) ||
 26     'deref (*rcu_dereference*) ||
 27     'lderef (*lockless_dereference*)
 28 instructions R[{'once,'acquire,'deref,'lderef}]
 29 instructions W[{'once,'release,'assign}]
 30 instructions RMW[{'once,'acquire,'release}]
</pre>
</blockquote>


<p>The &ldquo;<tt>enum Accesses</tt>&rdquo; statement defines the
types of memory references, corresponding to the C functions listed
in the comments.
These correspondences are defined in <tt>herd</tt>'s
<tt><a href="linux.def">linux.def</a></tt>
macro file.
The &ldquo;<tt>instructions R</tt>&rdquo; identifies which of the above
types of memory references may be associated with a read instruction,
the &ldquo;<tt>instructions W</tt>&rdquo; identifies which may be associated
with a write instruction, and the &ldquo;<tt>instructions RMW</tt>&rdquo;
identifies which may be associated with a read-modify-write instruction.
For example, the association of <tt>'acquire</tt> with the <tt>R</tt>
set of instructions corresponds to the Linux kernel's
<tt>smp_load_acquire()</tt> primitive.

<p>
Note well that the above code simply defines names for the Linux-kernel
memory-access primitives.
The <tt>herd</tt> tool also uses this code to check the instruction
annotations in the <tt><a href="linux.def">linux.def</a></tt> file,
for example, <tt>__load{acquire)</tt> is legal but <tt>__load(release)</tt>
is not.
Later code in both the Bell and Cat files will define their effect on
memory ordering.

<h3><a name="Bell File: Barriers">Bell File: Barriers</a></h3>

<p>The next portion of the Bell file defines the
types of barrier-like constructs, namely
<tt>smp_wmb()</tt>,
<tt>smp_rmb()</tt>,
<tt>smp_mb()</tt>,
<tt>smp_read_barrier_depends()</tt>,
<tt>rcu_read_lock()</tt>,
<tt>rcu_read_unlock()</tt>, and
<tt>synchronize_rcu()</tt>.

<blockquote>
<pre>
 32 enum Barriers = 'wmb (*smp_wmb*) ||
 33     'rmb (*smp_rmb*) ||
 34     'mb (*smp_mb*) ||
 35     'rb_dep (*smp_read_barrier_depends*) ||
 36     'rcu_read_lock (*rcu_read_lock*)  ||
 37     'rcu_read_unlock (*rcu_read_unlock*) ||
 38     'sync (*synchronize_rcu*)
 39 instructions F[Barriers]
 40
 41 (* Treat 'release and 'assign identically; same for 'deref and 'lderef *)
 42 let ReleaseAssign = Release | Assign
 43 let XDeref = Deref | Lderef
</pre>
</blockquote>

<p>The &ldquo;<tt>enum Barriers</tt>&rdquo; defines the types of barriers
corresponding to the C functions listed in the comments
(as set up in the
<tt><a href="linux.def">linux.def</a></tt>
macro file).
The &ldquo;<tt>instructions F[Barriers]</tt>&rdquo; says that these
types may be used in various sorts of barrier instructions.

<p><a name="Quick Quiz 17"><b>Quick Quiz 17</b>:</a>
Given that this is about memory barriers, why
&ldquo;<tt>instructions F[Barriers]</tt>&rdquo; instead of perhaps
&ldquo;<tt>instructions B[Barriers]</tt>&rdquo;?
<br><a href="#qq17answer">Answer</a>

<p>
The definition of <tt>ReleaseAssign</tt> allows the model to treat
the <tt>smp_store_release()</tt>, <tt>rcu_assign_pointer()</tt>,
and the write portions of <tt>xchg()</tt> and <tt>xchg_release()</tt>
identically from a memory-ordering perspective, and the
definition of <tt>XDeref</tt> does likewise for
<tt>lockless_dereference()</tt> and <tt>rcu_dereference()</tt>.

<p>
As with the memory accesses, the above code only defines names.
These barrier-like constructs' ordering properties will be defined by
later code in the Bell and Cat files.

<h3><a name="Bell File: Relating Barriers and Memory Accesses">
Bell File: Relating Barriers and Memory Accesses</a></h3>

<p>The next portion of the Bell file defines the relation between a given
barrier-like construct and its process's surrounding memory accesses:

<blockquote>
<pre>
 45 let rmb = fencerel(Rmb) &amp; (R*R)
 46 let wmb = fencerel(Wmb) &amp; (W*W)
 47 let mb = fencerel(Mb)
 48 let sync = (po &amp; (_ * Sync)) ; (po?)
</pre>
</blockquote>

<p>
The <tt>fencerel(S)</tt> function in <tt>herd</tt>'s standard library returns
a relation containing
all pairs of events in which the first event precedes (in program order)
an event in the <tt>S</tt> set
(for example, an &ldquo;<tt>Rmb</tt>&rdquo; event
in the case of the line&nbsp;26 above)
and the second follows it, with all three events being in the same thread.
As an example, the following snippet:

<blockquote>
<pre>
r1 = READ_ONCE(*x);
smp_rmb();
r2 = READ_ONCE(*y);
smp_mb();
WRITE_ONCE(*z, r3);
</pre>
</blockquote>

would produce an &ldquo;<tt>rmb</tt>&rdquo; relation containing only one link:

<ul>
<li>	<tt>r1 = READ_ONCE(*x)</tt> &#10230;
		<tt>r2 = READ_ONCE(*y)</tt>
</ul>

and an &ldquo;<tt>mb</tt>&rdquo; relation containing three links:

<ul>
<li>	<tt>r1 = READ_ONCE(*x)</tt> &#10230;
		<tt>WRITE_ONCE(*z, r3)</tt>,
<li>	<tt>smp_rmb()</tt> &#10230;
		<tt>WRITE_ONCE(*z, r3)</tt>, and
<li>	<tt>r2 = READ_ONCE(*y)</tt> &#10230;
		<tt>WRITE_ONCE(*z, r3)</tt>.
</ul>

The &ldquo;<tt>rmb</tt>&rdquo; relation doesn't include the other possible
links because of the
&ldquo;<tt>&amp; (R*R)</tt>&rdquo; clause in its definition,
which intersects the full <tt>fencerel(Rmb)</tt> relation
with the relation containing all pairs of reads (<tt>R*R</tt>).
This is appropriate because <tt>smp_rmb()</tt> orders only reads,
not writes.

<p>
(For database programming fans,
the &ldquo;<tt>&amp;</tt>&rdquo; operator can be thought of
as doing a database full equijoin operation, so that the result
is only those elements that appear in both operands.
Similarly, the &ldquo;<tt>*</tt>&rdquo; operator can be thought of as a
database unconstrained join operation, in this case
providing all combinations of pairs of read events.
Later on, we will encounter operations that cannot be easily
represented by
<a href="https://en.wikipedia.org/wiki/SQL">SQL</a>,
so we will shift to the notation used
for mathematical sets.)

<p>The &ldquo;<tt>let wmb = fencerel(Wmb) &amp; (W*W)</tt>&rdquo; definition
acts similarly, but it extracts pairs of writes rather than reads, as required
for <tt>smp_wmb()</tt>.
The &ldquo;<tt>let mb = fencerel(Mb)</tt>&rdquo; definition
keeps all events in the <tt>fencerel(Mb)</tt> relation,
as required for <tt>smp_mb()</tt>.
(It even keeps events that don't correspond to memory accesses,
such as the <tt>smp_rmb()</tt> event in the above example,
although they are irrelevant here.)

<p>
Finally, the &ldquo;<tt>let sync = (po &amp; (_ * Sync)) ; (po?)</tt>&rdquo;
definition uses a modified formula in place of
&ldquo;<tt>fencerel(Sync)</tt>&rdquo;.
It is different from the others in that it also includes pairs
where the second event <i>is</i> the <tt>synchronize_rcu()</tt> call
rather than something following it.
Otherwise it is like the definition of the <tt>mb</tt> relation.

<p><a name="Quick Quiz 18"><b>Quick Quiz 18</b>:</a>
Why wouldn't &ldquo;<tt>let sync = fencerel(Sync)</tt>&rdquo;
work just as well as the modified definition?
<br><a href="#qq18answer">Answer</a>

<p>
This portion of the Bell file relates <tt>smp_rmb()</tt>,
<tt>smp_wmb()</tt>, <tt>smp_mb()</tt>, and <tt>synchronize_rcu()</tt>
to the surrounding code within a given process, but says nothing about
cross-process ordering properties, which will be defined in later
Bell and Cat code.

<h3><a name="Bell File: Relating One-Sided Barriers and Memory Accesses">
Bell File: Relating One-Sided Barriers and Memory Accesses</a></h3>

<p>The next portion of the Bell file defines some relations involving
&ldquo;one-sided&rdquo; barriers
(<tt>smp_load_acquire()</tt>,
<tt>smp_store_release()</tt>,
<tt>rcu_assign_pointer()</tt>,
<tt>smp_read_barrier_depends()</tt>,
<tt>rcu_dereference()</tt>, and
<tt>lockless_dereference()</tt>)
and their surrounding instructions:

<blockquote>
<pre>
 50 let rb-dep = fencerel(Rb_dep) &amp; (R*R)
 51 let acq-po = po &amp; (Acquire*_)
 52 let xderef-po = po &amp; (XDeref*M)
 53 let po-relass = po &amp; (_*ReleaseAssign)
</pre>
</blockquote>

<p>The &ldquo;<tt>acq-po</tt>&rdquo; line defines the relation
appropriate for acquire operations, including <tt>smp_load_acquire()</tt>
and the read portions of <tt>xchg()</tt> and <tt>xchg_acquire()</tt>.
This is the intersection of the program order (<tt>po</tt>) relation with
the set of all pairs of events in which the first is an <tt>Acquire</tt>
and the second can be anything (the &ldquo;<tt>_</tt>&rdquo; wildcard).
The &ldquo;<tt>po-relass</tt>&rdquo; definition works quite similarly, but with
prior memory accesses rather than subsequent ones and with releases
(<tt>smp_store_release()</tt>, <tt>rcu_assign_pointer()</tt>, and
the write portions of <tt>xchg()</tt> and <tt>xchg_release()</tt>)
rather than acquires.

<p>
Consider the following example containing code fragments
running on two threads, where <tt>x</tt>, <tt>y</tt>, and
<tt>z</tt> are all initially zero:

<blockquote>
<pre>
Thread 0                              Thread 1
--------                              --------
WRITE_ONCE(*x, 1);                     r2 = smp_load_acquire(y);
r1 = READ_ONCE(*z);                    r3 = READ_ONCE(*x);
smp_store_release(y, 1);               WRITE_ONCE(*z, 1);
</pre>
</blockquote>

This results in the following <tt>po</tt> links:

<ul>
<li>	<tt>WRITE_ONCE(*x, 1)</tt> &#10230;
		<tt>r1 = READ_ONCE(*z)</tt>,
<li>	<tt>WRITE_ONCE(*x, 1)</tt> &#10230;
		<tt>smp_store_release(y, 1)</tt>,
<li>	<tt>r1 = READ_ONCE(*z)</tt> &#10230;
		<tt>smp_store_release(y, 1)</tt>,
<li>	<tt>r2 = smp_load_acquire(y)</tt> &#10230;
		<tt>r3 = READ_ONCE(x);</tt>,
<li>	<tt>r2 = smp_load_acquire(y)</tt> &#10230;
		<tt>WRITE_ONCE(z, 1)</tt>,
<li>	<tt>r3 = READ_ONCE(*x);</tt> &#10230;
		<tt>WRITE_ONCE(*z, 1)</tt>.
</ul>

<p>The first three links relate events in Thread&nbsp;0 and
the last three relate events in Thread&nbsp;1.
(The number of links in <tt>po</tt> is clearly quadratic
in the number of statements in a given thread, but that is OK because
several other things are exponential!
Knowing this, you can understand
why this sort of verification technique is unlikely to
handle all 20 million lines of the Linux kernel at one go.
Instead, these techniques should be applied to small but critical
segments of code.)

<p>
In this example, there is only one <tt>Acquire</tt> event:
&ldquo;<tt>r2 = smp_load_acquire(y)</tt>&rdquo;.
Intersecting <tt>po</tt> with the set of
all pairs of events in which the first is an <tt>Acquire</tt>
gives the <tt>acq-po</tt> relation:

<ul>
<li>	<tt>r2 = smp_load_acquire(y)</tt> &#10230;
		<tt>r3 = READ_ONCE(x);</tt>,
<li>	<tt>r2 = smp_load_acquire(y)</tt> &#10230;
		<tt>WRITE_ONCE(z, 1)</tt>,
</ul>

This naturally lists all pairs of instructions whose execution order is
constrained by Thread&nbsp;1's <tt>smp_load_acquire()</tt>.

<p>
The &ldquo;<tt>rb-dep</tt>&rdquo; definition is the same as that of
&ldquo;<tt>rmb</tt>&rdquo; earlier,
except that it applies to <tt>smp_read_barrier_depends()</tt>
instead of <tt>smp_rmb()</tt>.
The &ldquo;<tt>xderef-po</tt>&rdquo; definition is the same as that of
&ldquo;<tt>acq-po</tt>&rdquo;, but for <tt>lockless_dereference()</tt>
and <tt>rcu_dereference()</tt> instead of <tt>smp_load_acquire()</tt>.
Note that these three relations do not
correspond exactly to ordering constraints,
because <tt>smp_read_barrier_depends()</tt>, <tt>rcu_dereference()</tt>,
and <tt>lockless_dereference()</tt> only
order pairs of accesses where the second is &ldquo;dependent&rdquo; on the first
(more precisely, where there is an address dependency between them);
this restriction is described in more detail later on.

<p>
Note also that this portion of the Bell file defined only the relationships
between these one-sided barriers and the surrounding code within a
given process.
Cross-process ordering properties are defined by later Bell and Cat code.

<h3><a name="Bell File: Classes of Fences">
Bell File: Classes of Fences</a></h3>

<p>The next portion of the Bell file forms two groups of fences by strength:

<blockquote>
<pre>
 55 let rd-dep-fence = rb-dep | xderef-po
 56 let strong-fence = mb | sync
</pre>
</blockquote>

<p>
The members of the <tt>rd-dep-fence</tt> group
(<tt>smp_read_barrier_depends()</tt>,
<tt>rcu_dereference()</tt>, and
<tt>lockless_dereference()</tt>)
cannot provide any ordering at all unless a dependency is also present.

<p>
In contrast, the members of the <tt>strong-fence</tt> group can enforce full
globally visible transitive ordering.
Pervasive use of the
members of the <tt>strong-fence</tt> family will result in agreement
on the order even of completely unrelated memory references.
In fact, as noted 
<a href="LinuxMMModel.html#Specifying a Memory Model in Terms of Prohibited Cycles">earlier</a>,
placing one of these strong fences between each pair of memory
references in each process will forbid all but SC executions.
On the other hand, stronger fences often incur larger performance penalties.

<p>
These groups will be used in the Cat file to organize the various
ordering requirements.

<h3><a name="Bell File: RCU Read-Side Critical Sections">
Bell File: RCU Read-Side Critical Sections</a></h3>

<p>The final section of the Bell file is the most complex, due to the
fact that <tt>rcu_read_lock()</tt> and <tt>rcu_read_unlock()</tt>
must come in matching pairs within a given process and can be nested.
Therefore, the purpose of the following code is to find the outermost
pair of <tt>rcu_read_lock()</tt> and <tt>rcu_rcu_unlock()</tt> invocations
in a single nested set, and to differentiate correctly between any
unrelated nested sets in a given process.

<blockquote>
<pre>
 58 (* Compute matching pairs of nested Rcu_read_lock and Rcu_read_unlock *)
 59 let matched = let rec
 60       unmatched-locks = Rcu_read_lock \ domain(matched)
 61   and unmatched-unlocks = Rcu_read_unlock \ range(matched)
 62   and unmatched = unmatched-locks | unmatched-unlocks
 63   and unmatched-po = (unmatched * unmatched) &amp; po
 64   and unmatched-locks-to-unlocks = (unmatched-locks *
 65       unmatched-unlocks) &amp; po
 66   and matched = matched | (unmatched-locks-to-unlocks \
 67     (unmatched-po ; unmatched-po))
 68   in matched
 69
 70 (* Validate nesting *)
 71 flag ~empty Rcu_read_lock \ domain(matched) as unbalanced-rcu-locking
 72 flag ~empty Rcu_read_unlock \ range(matched) as unbalanced-rcu-locking
 73
 74 (* Outermost level of nesting only *)
 75 let crit = matched \ (po^-1 ; matched ; po^-1)
</pre>
</blockquote>

<p>
The &ldquo;<tt>matched</tt>&rdquo; relation is defined by the
mutually recursive set of definitions on lines&nbsp;61-70.
The idea behind this code is to associate an unmatched
<tt>Rcu_read_lock</tt> event with a later unmatched <tt>Rcu_read_unlock</tt> event
whenever no unmatched events lie between them,
and to repeat this operation recursively until nothing more can be matched.

<p>
To that end, lines&nbsp;61-64 form the sets of not-yet-matched
<tt>Rcu_read_lock</tt> and <tt>Rcu_read_unlock</tt> events and their union.
Line&nbsp;65 then forms the relation of all pairs of these unmatched
events that occur in the same thread, in program order.
Lines&nbsp;66-67 similarly form the relation of all such pairs
where the first member of the pair is a <tt>Rcu_read_lock</tt> event
and the second is an <tt>Rcu_read_unlock</tt>.

<p>
The interesting part is lines&nbsp;68-69, which take
pairs of unmatched <tt>Rcu_read_lock</tt> and <tt>Rcu_read_unlock</tt> events
and add them to the &ldquo;<tt>matched</tt>&rdquo; relation,
but only if there are no unmatched events in between.
They do this by applying the
&ldquo;<tt>\</tt>&rdquo; (backslash) subtraction operator to remove from
the <tt>unmatched-locks-to-unlocks</tt> relation
any pairs having an
intervening unmatched <tt>Rcu_read_lock</tt> or <tt>Rcu_read_unlock</tt>.
The &ldquo;<tt>;</tt>&rdquo; operator sequences relations
(if relation <tt>x</tt> contains <tt>a&#10230;b</tt>
and relation <tt>y</tt> contains <tt>b&#10230;c</tt>
then (<tt>x ; y</tt>) will contain <tt>a&#10230;c</tt>).
In this case, you can see that
&ldquo;<tt>unmatched-po ; unmatched-po</tt>&rdquo;
contains all pairs <tt>a&#10230;c</tt> of unmatched events for which
a third unmatched event <tt>b</tt> lies between them in program order.

<p>
The only purpose of line&nbsp;70 is to prevent the
<tt>unmatched-locks</tt>,
<tt>unmatched-unlocks</tt>,
<tt>unmatched</tt>,
<tt>unmatched-po</tt>, and
<tt>unmatched-locks-to-unlocks</tt>
definitions from leaking out to the surrounding context.
(Grammatically speaking, the construction used here is a
<tt>let rec</tt> <i>expression</i> inside a <tt>let</tt> <i>statement</i>.
In fact, <tt>let</tt> or <tt>let rec</tt> expressions
are very much like GCC's statement expressions;
the statement in lines&nbsp;50-59 is syntactically analogous to
&ldquo;<tt>x = ({int x = u; if (x &lt; v) x = v; x;})</tt>&rdquo;.)

<p>
Line&nbsp;73 then checks whether there are any unmatched <tt>Rcu_read_lock</tt> events,
and line&nbsp;74 does the same for unmatched <tt>Rcu_read_unlock</tt> events.
The &ldquo;<tt>flag ~empty</tt>&rdquo; statement flags the litmus test
as containing a semantic error if the specified set isn't empty,
and the &ldquo;<tt>as ...</tt>&rdquo; clause merely
provides a name to identify the particular failure mode.

<p>
Lastly, line&nbsp;77 computes those matching pairs which lie
at the outermost level of nesting.
They are the important ones, because they delimit
RCU read-side critical sections.
It does this by subtracting from &ldquo;<tt>matched</tt>&rdquo;
all pairs which lie entirely between another matched pair.
The &ldquo;<tt>^-1</tt>&rdquo; inversion operator computes the
converse of a given relation; that is, it computes the collection
of all links <tt>a&#10230;b</tt> such that
<tt>b&#10230;a</tt> is in the given relation.
Thus, <tt>po^-1</tt> contains all pairs of events in <i>reverse</i>
program order.
To see how &ldquo;<tt>(po^-1 ; matched ; po^-1)</tt>&rdquo; selects
inner matched pairs, consider the following example:

<blockquote>
<pre>
 1 rcu_read_lock();
 2 rcu_read_lock();
 3 rcu_read_unlock();
 4 rcu_read_unlock();
</pre>
</blockquote>

Starting at line&nbsp;2, a &ldquo;<tt>po^-1</tt>&rdquo; step takes us back to
line&nbsp;1, a &ldquo;<tt>matched</tt>&rdquo; step takes us to line&nbsp;4,
and a second &ldquo;<tt>po^-1</tt>&rdquo; takes us back to line&nbsp;3.
Thus, this expression correctly identifies line&nbsp;2 &#10230 line&nbsp;3
as an inner matched pair.
You can easily see that this mechanism will remove from the
<tt>matched</tt> relation any
matched pairs that are nested within another matched pair.

<p>
We are now ready to proceed to the Cat file.

<h2><a name="Strong-Model Cat File">Strong-Model Cat File</a></h2>

<p>The full
<a href="herd.html#built-in relations">Cat</a>
file for Alan Stern's strong model is as follows:

<blockquote>
<a id="strong-kernel.cat" href="strong-kernel.cat">strong-kernel.cat</a>
<pre>
  1 "Linux kernel strong memory model"
  2
  3 (*
  4  * Copyright (C) 2016 Alan Stern &lt;stern@rowland.harvard.edu&gt;,
  5  *          Andrea Parri &lt;parri.andrea@gmail.com&gt;
  6  *
  7  * This program is free software; you can redistribute it and/or modify
  8  * it under the terms of the GNU General Public License as published by
  9  * the Free Software Foundation; either version 2 of the License, or
 10  * (at your option) any later version.
 11  *
 12  * This program is distributed in the hope that it will be useful,
 13  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 14  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 15  * GNU General Public License for more details.
 16  *
 17  * You should have received a copy of the GNU General Public License
 18  * along with this program; if not, you can access it online at
 19  * http://www.gnu.org/licenses/gpl-2.0.html.
 20  *)
 21
 22 include "cos-opt.cat"
 23 include "lock.cat"
 24
 25 let com = rf | co | fr
 26 let coherence-order = po-loc | com
 27 acyclic coherence-order as coherence
 28
 29 empty rmw &amp; (fre;coe) as atomic
 30
 31
 32 let rf = rf | next-crit
 33 let rfe = rf &amp; ext
 34
 35 let exec-order-fence = rmb | acq-po | lk-po
 36 let propagation-fence = strong-fence | wmb | po-relass | po-ul
 37 let ordering-fence = propagation-fence | exec-order-fence
 38
 39 (* Determine the release sequences *)
 40 let rel-seq = [ReleaseAssign] ; coi? ; (rf ; rmw)*
 41 let po-rel-seq = po ; rel-seq
 42
 43 (* On Alpha, rd-dep-fence makes addr, dep-rfi, and rdw strong *)
 44 let dep = addr | data
 45 let dep-rfi = dep ; rfi
 46 let rd-addr-dep-rfi = (addr | dep-rfi)+ &amp; rd-dep-fence
 47 let rdw = po-loc &amp; (fre ; rfe)
 48 let rd-rdw = rdw &amp; rd-dep-fence
 49 let po-loc-ww = po-loc &amp; (W*W)
 50 let detour = (po-loc &amp; (coe ; rfe)) \ (po-loc-ww ; po-loc)
 51 let addrpo = addr ; po
 52
 53 (* The set of writes that are bounded by the end of the thread
 54    or by a fence before the next write to the same address *)
 55 let BOUNDED-W = W \ domain(po-loc-ww \ ordering-fence)
 56 (* The set of "non-obscurable" writes on ARM *)
 57 let NOW = domain(rfe) | range(rmw) | ReleaseAssign |
 58     BOUNDED-W | domain(detour)
 59 (* The set of "obscurable" writes *)
 60 let OW = W \ NOW
 61 (* The set of reads which might be forwarded from obscurable writes *)
 62 let OR = range(rfi &amp; (OW*R))
 63
 64 let nco = co &amp; (NOW*W)
 65 let ncoe = nco &amp; ext
 66
 67 let strong-ppo = rd-addr-dep-rfi | ordering-fence |
 68     ((dep | ctrl | addrpo) &amp; (R*W))
 69 let Alpha-strong-ppo = strong-ppo | rd-rdw | detour |
 70     (po-loc &amp; ((M\OW\OR)*W))
 71 let ARM-strong-ppo = strong-ppo | addr | dep-rfi
 72 let ppo = Alpha-strong-ppo | ARM-strong-ppo | rdw
 73
 74 let rfe-ppo = strong-ppo | (ARM-strong-ppo ; ppo* ; Alpha-strong-ppo)
 75 let po-relass-acq-hb = (po ; (rfe &amp; (ReleaseAssign*Acquire)) ; rfe-ppo) |
 76                (po-ul ; next-crit ; lk-po)
 77
 78 (* Release paired with Acquire is both A- and B-cumulative *)
 79 let AB-cum-hb = strong-fence | po-relass-acq-hb
 80 let A-cum-hb = AB-cum-hb | po-relass | po-rel-seq
 81 let B-cum-hb = AB-cum-hb | wmb
 82
 83 let hb0 = (ppo* ; Alpha-strong-ppo) | (rfe ; rfe-ppo)
 84 let propbase0 = propagation-fence | (rfe? ; A-cum-hb)
 85
 86 let rec B-cum-propbase = (B-cum-hb ; hb* ) |
 87     (rfe? ; AB-cum-hb ; hb* )
 88     and propbase = propbase0 | B-cum-propbase
 89     and short-obs = ((ncoe|fre) ; propbase+ ; rfe) &amp; int
 90     and obs = short-obs |
 91     ((hb* ; (ncoe|fre) ; propbase* ; B-cum-propbase ; rfe) &amp; int)
 92     and hb = hb0 | (obs ; rfe-ppo)
 93
 94 acyclic hb as happens-before
 95 irreflexive (short-obs ; Alpha-strong-ppo) as observation
 96
 97
 98 let strong-prop = fre? ; propbase* ; rfe? ; strong-fence ; hb* ; obs?
 99 let prop = (propbase &amp; (W*W)) | strong-prop
100 let cpord = nco | prop
101
102 acyclic cpord as propagation
103
104
105 (* Propagation between strong fences *)
106 let rcu-order = hb* ; obs? ; cpord* ; fre? ; propbase* ; rfe?
107
108 (* Chains that can prevent the RCU grace-period guarantee *)
109 let gp-link = sync ; rcu-order
110 let cs-link = po? ; crit^-1 ; po? ; rcu-order
111 let rcu-path0 = gp-link |
112   (gp-link ; cs-link) |
113   (cs-link ; gp-link)
114 let rec rcu-path = rcu-path0 |
115   (rcu-path ; rcu-path) |
116   (gp-link ; rcu-path ; cs-link) |
117   (cs-link ; rcu-path ; gp-link)
118
119 irreflexive rcu-path as rcu
</pre>
</blockquote>

<p><a name="Quick Quiz 19"><b>Quick Quiz 19</b>:</a>
This strong model is insanely complex!!!
How can anyone be expected to understand it???
<br><a href="#qq19answer">Answer</a>

<p>First, the &ldquo;<tt>Linux kernel strong memory model</tt>&rdquo;
is the title,
and the &ldquo;<tt>include "cos.cat"</tt>&rdquo; pulls in some
common definitions, similar to the C language's
&ldquo;<tt>#include &lt;stdio.h&gt;</tt>&rdquo;.

<p>
Again, taking the remainder of the file one piece at a time:

<ol>
<li>	<a href="#Cat File: SC Per Location and Atomics">
	Cat File: SC Per Location and Atomics</a>.
<li>	<a href="#Cat File: More Classes of Fences">
	Cat File: More Classes of Fences</a>.
<li>	<a href="#Cat File: Release Sequences">
	Cat File: Release Sequences</a>.
<li>	<a href="#Cat File: Intra-Thread Ordering">
	Cat File: Intra-Thread Ordering</a>.
<li>	<a href="#Cat File: Obscured Writes">Cat File: Obscured Writes</a>.
<li>	<a href="#Cat File: Preserved Program Order">
	Cat File: Preserved Program Order</a>.
<li>	<a href="#Cat File: Cumulativity">Cat File: Cumulativity</a>.
<li>	<a href="#Cat File: Happens-Before">Cat File: Happens-Before</a>.
<li>	<a href="#Cat File: Coherence Points">Cat File: Coherence Points</a>.
<li>	<a href="#Cat File: RCU">Cat File: RCU</a>.
</ol>

<h3><a name="Cat File: SC Per Location and Atomics">
Cat File: SC Per Location and Atomics</a></h3>

<p>The first section of the <tt>litmus.cat</tt> file defines
SC per location, which again means that all CPUs agree on the
order of reads and writes to any given single location, that is,
<a href="LinuxMMModel.html#cache coherence">cache coherence</a>,
as was provided by the
<a href="coherent-RMO.cat">Coherent-RMO</a> model.
This section also provides ordering constraints for RMW atomic
operations.

<blockquote>
<pre>
25 let com = rf | co | fr
26 let coherence-order = po-loc | com
27 acyclic coherence-order as coherence
28
29 empty rmw &amp; (fre;coe) as atomic
</pre>
</blockquote>

<p>
The first three lines define cache coherence, as discussed
<a href="#Cache coherence: the coherence check">above</a>,
ensuring that per-variable communications relations (<tt>rf</tt>, <tt>co</tt>,
and <tt>fr</tt>) are consistent with program order.
Line&nbsp;28 enforces the
<a href="#Atomic operations: the atomic check">atomicity of RMW operations on a given variable</a>.
Recall that the &ldquo;<tt>rmw</tt>&rdquo; relationship connects a
given RMW operation's read to its write.
Note also that &ldquo;<tt>fre;coe</tt>&rdquo; connects any read to a given
variable to some later write to that same variable, where at least
one of the intervening writes was executed by some other thread.
If the initial read was a given RMW operation's read and the final
write was this same RMW operation's write, atomicity has been violated:
Some other thread's write appeared after the RMW's read but before its
write.
Therefore, the last line prohibits such violations by requiring
that the intersection of &ldquo;<tt>rmw</tt>&rdquo; and
&ldquo;<tt>fre;coe</tt>&rdquo; be empty.

<h3><a name="Cat File: More Classes of Fences">
Cat File: More Classes of Fences</a></h3>

<p>
The next portion of the file defines classes of fences in addition
to those in
<a href="#Bell File: Classes of Fences">the Bell file</a>.

<p><a name="Quick Quiz 20"><b>Quick Quiz 20</b>:</a>
Why aren't these additional classes of fences in the
<a href="strong-kernel.bell">Bell file</a>
where the other classes live?
<br><a href="#qq20answer">Answer</a>

<blockquote>
<pre>
 32 let rf = rf | next-crit
 33 let rfe = rf &amp; ext
 34
 35 let exec-order-fence = rmb | acq-po | lk-po
 36 let propagation-fence = strong-fence | wmb | po-relass | po-ul
 37 let ordering-fence = propagation-fence | exec-order-fence
</pre>
</blockquote>

<p>
The <tt>rf</tt> and <tt>rfe</tt> relations are redefined to include
lock-based critical sections.
This might be pulled into herd's predefined relations at some point,
but handling of locking is currently in prototype stage.

<p>
The members of the <tt>exec-order-fence</tt> group
(<tt>smp_rmb()</tt> and <tt>smp_load_acquire()</tt>)
can be thought of as providing
ordering by restricting execution, for example, waiting for previous reads
to complete before executing subsequent instructions.
(In practice, hardware architects have all sorts of optimizations at
their disposal that provide the needed ordering without necessarily
actually waiting.)
The ordering properties of any member of the
<a href="#Bell File: Classes of Fences"><tt>rd-dep-fence</tt></a>
and
<tt>exec-order-fence</tt> groups do not propagate outside of that member's
process.
Such fences cannot provide global ordering except in situations involving only
causal reads-from (<tt>rf</tt>) links; any non-causal coherence or
from-read links (<tt>co</tt> or <tt>fr</tt>, respectively) require
a stronger type of barrier.
In addition, <tt>smp_load_acquire()</tt> only orders trailing loads
unless it is paired with <tt>smp_store_release()</tt>.

<p>
The members of the <tt>propagation-fence</tt> group include
<a href="#Bell File: Classes of Fences">strong-fence</a>
(<tt>smp_mb()</tt> and <tt>synchronize_rcu()</tt>)
in addition to <tt>smp_wmb()</tt>, <tt>smp_store_release()</tt>,
and <tt>rcu_assign_pointer()</tt>.
These barriers all provide some form of
<a href="#Memory barriers">cumulativity</a>,
and when the <tt>smp_store_release()</tt> and <tt>rcu_assign_pointer()</tt>
are paired with <tt>smp_load_acquire()</tt>, all of them provide
<a href="#Memory barriers">B-cumulativity</a>.
Either way, as the name suggests, the effects of these barriers propagate
to other processes.

<p>
Finally, <tt>ordering-fence</tt> is simply the union of
<tt>exec-order-fence</tt> and <tt>propagation-fence</tt>,
that is, the set of fence-like things that do not rely on dependencies.

<h3><a name="Cat File: Release Sequences">
Cat File: Release Sequences</a></h3>

<p>
The next portion of the file defines C11-style
<a href="http://en.cppreference.com/w/cpp/atomic/memory_order#Release_sequence">release sequences</a>
described
<a href="#release sequences">above</a>:

<blockquote>
<pre>
 35 (* Determine the release sequences *)
 36 let rel-seq = [ReleaseAssign] ; coi? ; (rf ; rmw)*
 37 let po-rel-seq = po ; rel-seq
</pre>
</blockquote>

<p>
The <tt>rel-seq</tt> relation links any release operation to any
later store to that same variable from that same thread, as well
as to any sequence of read-modify-write atomic operations to that
same variable, as long as that sequence is not interrupted by
a non-read-modify-write update.
The <tt>po-rel-seq</tt> relation then restricts <tt>rel-seq</tt>
to a given thread.

<h3><a name="Cat File: Intra-Thread Ordering">
Cat File: Intra-Thread Ordering</a></h3>

<p>The next portion of the file defines the intra-thread ordering
relationships described
<a href="#Execution ordering: Preserved Program Order and fences">earlier</a>.
Here &ldquo;intra-thread&rdquo; means that the ordered accesses are within
the same thread.
Some of the relationships will reference other threads.

<blockquote>
<pre>
 43 (* On Alpha, rd-dep-fence makes addr, dep-rfi, and rdw strong *)
 44 let dep = addr | data
 45 let dep-rfi = dep ; rfi
 46 let rd-addr-dep-rfi = (addr | dep-rfi)+ &amp; rd-dep-fence
 47 let rdw = po-loc &amp; (fre ; rfe)
 48 let rd-rdw = rdw &amp; rd-dep-fence
 49 let po-loc-ww = po-loc &amp; (W*W)
 50 let detour = (po-loc &amp; (coe ; rfe)) \ (po-loc-ww ; po-loc)
 51 let addrpo = addr ; po
</pre>
</blockquote>

<p>The <tt>addr</tt> and <tt>data</tt>
relations define address and data dependencies respectively, and
the <tt>dep</tt> relation is simply their union.
An address dependency occurs when a previously loaded value is used
to form the address of a subsequent load or store within the same thread.
A data dependency occurs when a previously loaded value is used to form
the value stored by a subsequent store within the same thread.
The <tt>dep-rfi</tt> relation extends <tt>dep</tt> with an
internal <tt>rf</tt> relation, which implies that the
<tt>dep</tt> must have been a read-to-write dependency.

<p>
However, the Linux kernel does not respect read-to-read address dependencies
unless: (1)&nbsp;The dependency is headed by <tt>rcu_dereference()</tt>
or <tt>lockless_dereference()</tt> or
(2)&nbsp;There is an <tt>smp_read_barrier_depends()</tt> between the
load heading the dependency chain and the dependent memory reference.
This requirement for a special operation helps to document the intent,
and also allows architectures to include any special instructions
required to enforce dependency ordering, for example, DEC Alpha
requires a memory barrier if the dependent access is a read.

<p>
The <tt>rd-addr-dep-rfi</tt> relation therefore contains only those sequences
of address dependencies (and <tt>dep-rfi</tt> relations)
that are headed by <tt>lockless_dereference()</tt>
or <tt>rcu_dereference()</tt> or that span an
<tt>smp_read_barrier_depends()</tt>.
This relation excludes any read-to-read dependencies
that DEC Alpha won't provide ordering for.

<p>
The &ldquo;<tt>rdw</tt>&rdquo;
relation contains load-store pairs within a given thread,
where the load and store are to the same variable, but where at least
one store to this same variable from some other thread intervened
between this thread's load and store.
The <tt>rd-rdw</tt> relation contains relations from <tt>rdw</tt>
that are headed by <tt>lockless_dereference()</tt>
or <tt>rcu_dereference()</tt> or that span an
<tt>smp_read_barrier_depends()</tt>.
The <tt>po-loc-ww</tt> relation links pairs of writes by the same thread
to the same variable.
This relation helps to define the <tt>detour</tt> relation, which
links writes that are overwritten by some other process, whose
value is returned by a subsequent read in the first process,
but without an intervening write to that same variable within the
first process.
Finally, the <tt>addrpo</tt> relation
relates operations heading address dependencies with any operations
following the dependent operation in program order.

<p><a name="Quick Quiz 21"><b>Quick Quiz 21</b>:</a>
Why would an operation following an address dependency get any special
treatment?
After all, there does not appear to be any particular ordering relationship
in the general case.
<br><a href="#qq21answer">Answer</a>

<h3><a name="Cat File: Obscured Writes">Cat File: Obscured Writes</a></h3>

As described in the
<a href="#Adjustments for ARM">ARM</a>
section, writes can be
<a href="#ARM obscured writes">obscured</a>
under certain conditions.
The following section of the Cat file accounts for this:

<blockquote>
<pre>
 53 (* The set of writes that are bounded by the end of the thread
 54    or by a fence before the next write to the same address *)
 55 let BOUNDED-W = W \ domain(po-loc-ww \ ordering-fence)
 56 (* The set of "non-obscurable" writes on ARM *)
 57 let NOW = domain(rfe) | range(rmw) | ReleaseAssign |
 58     BOUNDED-W | domain(detour)
 59 (* The set of "obscurable" writes *)
 60 let OW = W \ NOW
 61 (* The set of reads which might be forwarded from obscurable writes *)
 62 let OR = range(rfi &amp; (OW*R))
</pre>
</blockquote>

<p>
There are a number of reasons why a given write might not be
&ldquo;obscurable&rdquo;, and the first two relations form the full
set of non-obscurable writes.
The <tt>BOUNDED-W</tt> set contains those writes that cannot be
obscured either due to them being the last write in the thread
(hence the subtraction of the domain of <tt>po-loc-ww</tt>)
or due to them being ordered against some later access
(hence the subtraction of the domain of <tt>ordering-fence</tt>).
The <tt>NOW</tt> set then adds writes that are read by some
other process (<tt>domain(rfe)</tt>),
writes that are part of an atomic read-modify-write operation
(<tt>range(rmw)</tt>),
writes having release semantics (<tt>ReleaseAssign</tt>), and
writes that were overwritten by a write in some other process,
with that other process's write being read by a later read
in the first process, but without another intervening write
executed by the first process (<tt>domain(detour)</tt>).

<p>
The <tt>OW</tt> set then forms the set of obscurable writes
by subtracting the set of non-obscurable writes from the set
of all writes.
Even though a write might be obscured, its value might nevertheless be
forwarded to later reads by that same thread, and this set of reads
is formed in <tt>OR</tt>.
The <tt>nco</tt> relation is that subset of the <tt>co</tt>
relation that links only from non-obscurable writes.
However, note that <tt>nco</tt> might contain links <i>to</i>
obscurable writes.
Finally, the <tt>ncoe</tt> relation is that subset of the <tt>co</tt>
relation that links from a non-obscurable write to some (possibly
obscurable) write to that same variable by some other process.

<h3><a name="Cat File: Preserved Program Order">
Cat File: Preserved Program Order</a></h3>

<p>
The next section of the file defines several flavors of
&ldquo;preserved program order&rdquo;, which is abbreviated as <tt>ppo</tt>.
These take into account special properties of both
<a href="#Alpha ppo modifications">Alpha</a> and
<a href="#Adjustments for ARM">ARM</a>:

<blockquote>
<pre>
 67 let strong-ppo = rd-addr-dep-rfi | ordering-fence |
 68     ((dep | ctrl | addrpo) &amp; (R*W))
 69 let Alpha-strong-ppo = strong-ppo | rd-rdw | detour |
 70     (po-loc &amp; ((M\OW\OR)*W))
 71 let ARM-strong-ppo = strong-ppo | addr | dep-rfi
 72 let ppo = Alpha-strong-ppo | ARM-strong-ppo | rdw
 73
 74 let rfe-ppo = strong-ppo | (ARM-strong-ppo ; ppo* ; Alpha-strong-ppo)
 75 let po-relass-acq-hb = (po ; (rfe &amp; (ReleaseAssign*Acquire)) ; rfe-ppo) |
 76                (po-ul ; next-crit ; lk-po)
</pre>
</blockquote>

<p>
The basic point of the <tt>ppo</tt> relations is to arrive at the set
of relations providing ordering within the context of a single process.
The <tt>strong-ppo</tt> relation includes a number of components:

<ol>
<li>	Dependencies enforced by <tt>lockless_dereference()</tt>,
	<tt>rcu_dereference()</tt>, or <tt>smp_read_barrier_depends()</tt>
	(<tt>rd-addr</tt>), but possibly including internal reads from
	dependent writes;
<li>	Accesses separated by a sufficiently strong ordering fence
	(<tt>ordering-fence</tt>);
<li>	Dependencies leading to writes
	(<tt>((dep | ctrl | addrpo) &amp; (R*W))</tt>).
</ol>

<p>
Next are the aspects of <tt>ppo</tt> limited by ARM in the
<tt>ARM-strong-ppo</tt> relation, all of which are again added
to <tt>strong-ppo</tt>:

<ol>
<li>	Address dependencies (<tt>addr</tt>) and
<li>	Read-to-write dependencies of any sort where a later read
	within that same thread returns the value written
	(<tt>dep-rfi</tt>).
</ol>

<p>
Next are the aspects of <tt>ppo</tt> limited by DEC Alpha in the
<tt>Alpha-strong-ppo</tt> relation, all of which are added to
<tt>strong-ppo</tt>:

<ol>
<li>	Read-to-read dependencies involving only one variable
	whose ordering is enforced by
	<tt>lockless_dereference()</tt>, <tt>rcu_dereference()</tt>, or
	<tt>smp_read_barrier_depends()</tt>, and which also have
	an intervening write to this variable from some other process
	(<tt>rd-rdw</tt>);
<li>	A write followed by a read from the same variable within the
	same process, with no intervening write to that same variable
	within that same process, but where the read returns the value
	written by some other process (<tt>detour</tt>);
<li>	A pair of accesses to the same variable by the same process,
	but excluding pairs of writes where the first write is
	obscurable
	(<tt>(po-loc &amp; ((M\OW\OR)*W))</tt>.
</ol>

<p><a name="Quick Quiz 22"><b>Quick Quiz 22</b>:</a>
You said that these were <tt>ppo</tt> relations limited by DEC Alpha,
but obscurable writes are an ARM limitation.
What gives?
<br><a href="#qq22answer">Answer</a>

<p>
This leads to <tt>ppo</tt> itself, which combines
<tt>Alpha-strong-ppo</tt>, <tt>ARM-strong-ppo</tt>, and
<tt>rdw</tt>.
Recall that <tt>rdw</tt> links pairs of reads from the same variable
within the same process, where there was an intervening write to that
variable by some other process.

<p><a name="Quick Quiz 23"><b>Quick Quiz 23</b>:</a>
But <tt>ARM-strong-ppo</tt> (and thus <tt>ppo</tt>) includes <tt>addr</tt>,
which links reads to later dependent reads, which DEC Alpha does not respect.
How is this supposed to work?
<br><a href="#qq23answer">Answer</a>

<p>
Next, <tt>rfe-ppo</tt> allows <tt>ppo</tt> relations to be chained
together (within the same process, of course).

<p>
Finally, the <tt>po-relass-acq-hb</tt> relation links pairs of accesses
ordered by a single link of a release-acquire chain, which might be
a store-release read by a load-acquire or might be an lock release
followed by the corresponding lock acquisition.

<h3><a name="Cat File: Cumulativity">Cat File: Cumulativity</a></h4>

<p>
The following relations define
<a href="#Execution ordering: write propagation and cumulativity">cumulativity</a>,
which is loosely related to the
concept of transitivity:

<blockquote>
<pre>
 78 (* Release paired with Acquire is both A- and B-cumulative *)
 79 let AB-cum-hb = strong-fence | po-relass-acq-hb
 80 let A-cum-hb = AB-cum-hb | po-relass | po-rel-seq
 81 let B-cum-hb = AB-cum-hb | wmb
</pre>
</blockquote>

<p><a name="Quick Quiz 24"><b>Quick Quiz 24</b>:</a>
Why don't these relations match those shown in the
<a href="#Execution ordering: write propagation and cumulativity">
Execution ordering: write propagation and cumulativity</a> section?
<br><a href="#qq24answer">Answer</a>

<p>
The <tt>AB-cum-hb</tt> relation includes strong fences and
release-acquire pairs, both of which come closest to providing
full transitivity.
The <tt>A-cum-hb</tt> relation includes <tt>AB-cum-bh</tt>, and also
links memory accesses to later
release operations in the same thread, and furthermore takes
release sequences into account.
Both of these release-related relations provide ordering with certain
prior accesses by other threads, hence A-cumulativity.
Finally, the <tt>B-cum-hb</tt> relation also includes <tt>AB-cum-bh</tt>,
and adds writes ordered by <tt>smp_wmb()</tt>, which provides ordering
with certain later accesses by other threads, hence B-cumulativity.

<h3><a name="Cat File: Happens-Before">Cat File: Happens-Before</a></h3>

The next portion of the file combines the effects of dependencies,
barriers and grace periods to arrive at a causally ordered
<a href="#Execution ordering: the happens-before check">happens-before</a>
(<tt>hb</tt>) relationship.

<blockquote>
<pre>
 83 let hb0 = (ppo* ; Alpha-strong-ppo) | (rfe ; rfe-ppo)
 84 let propbase0 = propagation-fence | (rfe? ; A-cum-hb)
 85
 86 let rec B-cum-propbase = (B-cum-hb ; hb* ) |
 87     (rfe? ; AB-cum-hb ; hb* )
 88     and propbase = propbase0 | B-cum-propbase
 89     and short-obs = ((ncoe|fre) ; propbase+ ; rfe) &amp; int
 90     and obs = short-obs |
 91     ((hb* ; (ncoe|fre) ; propbase* ; B-cum-propbase ; rfe) &amp; int)
 92     and hb = hb0 | (obs ; rfe-ppo)
 93
 94 acyclic hb as happens-before
 95 irreflexive (short-obs ; Alpha-strong-ppo) as observation
</pre>
</blockquote>

<p>
The <tt>hb</tt> relation has two base cases for its mutually
assured recursive definition, <tt>hb0</tt> and <tt>propbase0</tt>.

<p>
The <tt>hb0</tt> relation is either a sequence of intrathread
<tt>ppo</tt> relations followed by an <tt>Alpha-strong-ppo</tt>
or a read that returns a value from some other process's write
followed by an <tt>rfe-ppo</tt> relation that links to accesses
that will remain ordered with respect to the initial <tt>rfe</tt>.

<p>
The <tt>propbase0</tt> relation is either a fence having B-cumulativity
or an optional read from some other process followed by one
A-cumulative step.

<p>
The general idea behind the <tt>hb</tt> relation is to build a series
of steps that provide ordering, with B-cumulative steps at the beginning
of the series and A-cumulative steps at the end.
In some cases, it is possible to concatenate instances of such series
on either side of a sufficiently strong ordering construct.
Of course AB-cumulative steps can act either as B-cumulative steps or as
A-cumulative steps.

<p>
Taking the components of the mutually assured recursion for <tt>hb</tt>
in turn:

<ol>
<li>	The <tt>B-cum-propbase</tt> relation forms the B-cumulative
	start of an <tt>hb</tt> sequence, beginning with either
	(1)&nbsp;a strong fence,
	(2)&nbsp;an <tt>smp_wmb()</tt>, or
	(3)&nbsp;a read satisfied by some other process's write and
	followed by a strong fence or a release-acquire pair.
	Any of these possibilities may be followed by an
	<tt>hb</tt> relation.
<li>	The <tt>propbase</tt> relationship combines <tt>propbase0</tt>
	and recurses on <tt>B-cum-propbase</tt>.
<li>	The <tt>short-obs</tt> relation starts with a write or a
	read on one process, links via <tt>ncoe</tt> or <tt>fre</tt>
	(respectively) to another process, goes through at least one
	<tt>propbase</tt> step, then comes back to the original process
	via an <tt>fre</tt> link.
	As the name implies, a read executed a given process
	<a href="#Execution ordering: the obs relation">observes</a>
	a chain of events headed by either a prior read or a prior write
	executed by that same process.
<li>	The <tt>obs</tt> relation builds on <tt>short-obs</tt>,
	adding a sequence similar to <tt>short-obs</tt>, but with
	an additional sequence of zero or more <tt>hb</tt> at the
	beginning and an additional <tt>B-cum-propbase</tt>
	before the final <tt>rfe</tt>.
<li>	Finally, the <tt>hb</tt> relation starts with <tt>hb0</tt>
	relation and recurses on <tt>obs</tt> followed by <tt>rfe-ppo</tt>.
	The <tt>rfe-ppo</tt> allows <tt>hb</tt> to connect to another
	instance of itself.
</ol>

<p>
The <tt>hb</tt> relation is then declared to be acyclic and the concatenation
of <tt>short-obs</tt> and <tt>Alpha-strong-ppo</tt> is declared
irreflexive.

<p><a name="Quick Quiz 25"><b>Quick Quiz 25</b>:</a>
The <tt>hb</tt> relation seems to have a lot of moving parts, and
the choices seem a bit on the arbitrary side.
What gives?
<br><a href="#qq25answer">Answer</a>

<h3><a name="Cat File: Coherence Points">Cat File: Coherence Points</a></h3>

<p>
Even in weakly ordered systems, ordering extends somewhat beyond
strict causality, for example, it includes the notion of
<a href="#Coherence-point ordering: the propagation check">coherence points</a>.
The corresponding relations are described below.

<blockquote>
<pre>
 98 let strong-prop = fre? ; propbase* ; rfe? ; strong-fence ; hb* ; obs?
 99 let prop = (propbase &amp; (W*W)) | strong-prop
100 let cpord = nco | prop
101
102 acyclic cpord as propagation
</pre>
</blockquote>

<p>
The <tt>strong-prop</tt> relation extends the ordering of a strong
fence both forwards (<tt>hb* ; obs?</tt>) and backwards
(<tt>fre? ; propbase* ; rfe?</tt>).
The <tt>prop</tt> relation adds
2+2W-style ordering to </tt>strong-prop</tt>,
and <tt>cpord</tt> combines non-obscurable writes (<tt>nco</tt>) and
the aforementioned <tt>prop</tt>.
Finally, <tt>cpord</tt> is marked acyclic.

<p>
The happens-before and coherence-points machinery can be complex, but
fortunately, many common use cases take simple paths through this
machinery, for example:

<blockquote>
<a id="litmus12" href="C-ISA2+o-rel+acq-rel+acq-o.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#12</a>
<pre>
  1 C C-ISA2+o-rel+acq-rel+acq-o.litmus
  2
  3 {
  4 }
  5
  6 P0(int *a, int *b)
  7 {
  8   WRITE_ONCE(*a, 1);
  9   smp_store_release(b, 1);
 10 }
 11
 12 P1(int *b, int *c)
 13 {
 14   int r1;
 15
 16   r1 = smp_load_acquire(b);
 17   smp_store_release(c, 1);
 18 }
 19
 20 P2(int *c, int *a)
 21 {
 22   int r2;
 23   int r3;
 24
 25   r2 = smp_load_acquire(c);
 26   r3 = READ_ONCE(*a);
 27 }
 28
 29 exists
 30 (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
</pre>
</blockquote>

<p>
After all three threads have completed, is the outcome shown
on line&nbsp;30 possible?

<p>
Referring to the
<a href="strong-kernel.bell">Bell</a>
and
<a href="strong-kernel.cat">Cat</a>
files, we see that
line&nbsp;8&#10230;9 is a member of <tt>po</tt>,
line&nbsp;9&#10230;16 is a member of <tt>rfe</tt> and
furthermore is an example of <tt>(rfe &amp; (ReleaseAssign*Acquire))</tt>,
and line&nbsp;16&#10230;17 is a member of <tt>acq-po</tt>.
Because line&nbsp;17 is a write, this last pair is also a member of
<tt>(acq-po \ (R*R))</tt>, and thus a member of <tt>exec-order-fence</tt>,
of <tt>ordering-fence</tt>, of <tt>strong-ppo</tt>, and finally of
<tt>rfe-ppo</tt>.
But any member of the sequence
<tt>po;(rfe &amp; (ReleaseAssign*Acquire));rfe-ppo</tt>
(that is, line&nbsp;8&#10230;9&#10230;16&#10230;17,
which is line&nbsp;8&#10230;17)
is also a member of <tt>po-relass-acq-hb</tt> and thus of <tt>AB-cum-hb</tt>,
and also of <tt>B-cum-hb</tt>, and in turn of <tt>B-cum-propbase</tt>
and finally of <tt>propbase</tt>.

<p>
Line&nbsp;26&#10230;8 is a member of <tt>fre</tt>,
as noted in the paragraph above, line&nbsp;8&#10230;17
is a member of <tt>propbase</tt>,
and line&nbsp;17&#10230;25 is a member of <tt>rfe</tt>.
Therefore, line&nbsp;26&#10230;25 is a member of </tt>short-obs</tt>.

<p>
Line&nbsp;26&#10230;26 is a member of <tt>acq-po</tt>,
and because both are reads, also a member of
<tt>(acq-po &amp; (R*R))</tt>, and thus of <tt>Alpha-strong-ppo</tt>.

<p>
Finally, because line&nbsp;26&#10230;25 is a member of
</tt>short-obs</tt> and because line&nbsp;25&#10230;26
is a member of <tt>Alpha-strong-ppo</tt>, we have a cycle linking
line&#10230;26 to itself.
This cycle is prohibited by an <tt>irreflexive</tt> statement,
so the exists clause of
<a href="#litmus12">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#12</a>
cannot be satisfied.

<p>
This is confirmed by running the command:

<blockquote>
<pre>
herd7 -conf strong.cfg C-ISA2+o-rel+acq-rel+acq-o.litmus
</pre>
</blockquote>

<p>
Which produces the following output:

<blockquote>
<a id="litmus12" href="C-ISA2+o-rel+acq-rel+acq-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#12</a>
<pre>
 1 Test C-ISA2+o-rel+acq-rel+acq-o Allowed
 2 States 7
 3 1:r1=0; 2:r2=0; 2:r3=0;
 4 1:r1=0; 2:r2=0; 2:r3=1;
 5 1:r1=0; 2:r2=1; 2:r3=0;
 6 1:r1=0; 2:r2=1; 2:r3=1;
 7 1:r1=1; 2:r2=0; 2:r3=0;
 8 1:r1=1; 2:r2=0; 2:r3=1;
 9 1:r1=1; 2:r2=1; 2:r3=1;
10 No
11 Witnesses
12 Positive: 0 Negative: 7
13 Condition exists (1:r1=1 /\ 2:r2=1 /\ 2:r3=0)
14 Observation C-ISA2+o-rel+acq-rel+acq-o Never 0 7
15 Hash=9762857b08e4db85dbbf52a7b43068e9
</pre>
</blockquote>

The &ldquo;<tt>Never 0 7</tt>&rdquo; should be reassuring, given that
this cycle is analogous a series of lock releases and acquires, which
had jolly well better be fully ordered!

<p>
Let's now look at a roughly similar example:

<blockquote>
<a id="litmus13" href="C-W+WRC+o-rel+acq-o+o-mb-o.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#13</a>
<pre>
  1 C C-W+WRC+o-rel+acq-o+o-mb-o.litmus
  2
  3 {
  4 }
  5
  6 P0(int *a, int *b)
  7 {
  8   WRITE_ONCE(*a, 1);
  9   smp_store_release(b, 1);
 10 }
 11
 12 P1(int *b, int *c)
 13 {
 14   int r1;
 15   int r2;
 16
 17   r1 = smp_load_acquire(b);
 18   r2 = READ_ONCE(*c);
 19 }
 20
 21 P2(int *c, int *a)
 22 {
 23   int r3;
 24
 25   WRITE_ONCE(*c, 1);
 26   smp_mb();
 27   r3 = READ_ONCE(*a);
 28 }
 29
 30 exists
 31 (1:r1=1 /\ 1:r2=0 /\ 2:r3=0)
</pre>
</blockquote>

<p>
After all three threads have completed, is the result
shown on line&nbsp;31 possible?

<p>
A key point is that line&nbsp;18&#10230;25 and
line&nbsp;18&#10230;8 are both members of <tt>fre</tt>.
Furthermore, the only member of <tt>rfe</tt> is
line&nbsp;9&#10230;17.
This means that there cannot be a cycle in <tt>hb</tt>, which
requires at least one <tt>rfe</tt> for each <tt>fre</tt> in
the cycle.
The same observation applies to
<tt>(short-obs ; Alpha-strong-ppo)</tt>.
In addition, although <tt>cpord</tt> does not require an <tt>rfe</tt>
for each <tt>fre</tt>, it <i>does</i> require a <tt>strong-fence</tt>
for each <tt>fre</tt> (via <tt>strong-prop</tt>,
and there is only one <tt>smp_mb()</tt>,
which can cover only one of the two <tt>fre</tt> relations.

<p>
Can we somehow combine <tt>hb</tt> (for example, via <tt>propbase</tt>)
and <tt>cpord</tt> (via <tt>strong-prop</tt>) to pair an <tt>rfe</tt>
with one of the <tt>fre</tt> relations and a <tt>strong-fence</tt>
with the other?
The answer is &ldquo;no&rdquo; because the only relations feeding into
<tt>propbase</tt> that include <tt>fre</tt> must start and end within
the same process, and cannot have more <tt>fre</tt> relations than
<tt>rfe</tt> relations on that path.

<p>
This should not be too surprising, given the non-causal nature of
<tt>fre</tt> relations,
and can be confirmed by running the following command line:

<blockquote>
<pre>
herd7 -conf strong.cfg C-W+WRC+o-rel+acq-o+o-mb-o.litmus
</pre>
</blockquote>

<p>
Which results in the following output:

<blockquote>
<a id="litmus13" href="C-W+WRC+o-rel+acq-o+o-mb-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#13</a>
<pre>
 1 Test C-W+WRC+o-rel+acq-o+o-mb-o Allowed
 2 States 8
 3 1:r1=0; 1:r2=0; 2:r3=0;
 4 1:r1=0; 1:r2=0; 2:r3=1;
 5 1:r1=0; 1:r2=1; 2:r3=0;
 6 1:r1=0; 1:r2=1; 2:r3=1;
 7 1:r1=1; 1:r2=0; 2:r3=0;
 8 1:r1=1; 1:r2=0; 2:r3=1;
 9 1:r1=1; 1:r2=1; 2:r3=0;
10 1:r1=1; 1:r2=1; 2:r3=1;
11 Ok
12 Witnesses
13 Positive: 1 Negative: 7
14 Condition exists (1:r1=1 /\ 1:r2=0 /\ 2:r3=0)
15 Observation C-W+WRC+o-rel+acq-o+o-mb-o Sometimes 1 7
16 Hash=8e3c5d7d5d36f2b1484ff237e8d22f91
</pre>
</blockquote>

<p>
However, full barriers (<tt>smp_mb()</tt>) can be used to force the
Linux kernel to respect full non-causal ordering, and this is the
main job of the &ldquo;<tt>cpord</tt>&rdquo; relationship.
To see this, consider the following store-buffering litmus test
shown in
<a href="#litmus1">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>.

<p>
Can the cyclic outcome &ldquo;<tt>!r1&amp;&amp;!r2</tt>&rdquo;
called out in line&nbsp;25 really happen?

<p>
Line&nbsp;10&#10230;12 and 19&#10230;21 are members of <tt>mb</tt> and
thus of <tt>strong-fence</tt>,
while line&nbsp;12&#10230;19 and 21&#10230;10 are members of <tt>fre</tt>.
This means that line&nbsp;21&#10230;10&#10230;12 and
line&nbsp;12&#10230;19&#10230;21 are members of <tt>strong-prop</tt>,
and thus of <tt>prop</tt> and <tt>cpord</tt>.
This pair of <tt>cpord</tt> relations forms a cycle, and <tt>cpord</tt>
is constrained to be acyclic.
Therefore, the <tt>exists</tt> clause cannot be satisfied.

<p>
This is confirmed by the following command:

<blockquote>
<pre>
herd7 -conf strong.cfg C-SB+o-mb-o+o-mb-o.litmus
</pre>
</blockquote>

<p>
This command produces the following output:

<blockquote>
<a id="litmus1" href="C-SB+o-mb-o+o-mb-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#1</a>
<pre>
 1 Test C-SB+o-mb-o+o-mb-o Allowed
 2 States 3
 3 0:r1=0; 1:r2=1;
 4 0:r1=1; 1:r2=0;
 5 0:r1=1; 1:r2=1;
 6 No
 7 Witnesses
 8 Positive: 0 Negative: 3
 9 Condition exists (0:r1=0 /\ 1:r2=0)
10 Observation C-SB+o-mb-o+o-mb-o Never 0 3
11 Hash=a61f698662bb72c2ed1755812580d385
</pre>
</blockquote>

<p><a name="Quick Quiz 26"><b>Quick Quiz 26</b>:</a>
Is there an easy way to tell which definitions have effect for a
given litmus test?
<br><a href="#qq26answer">Answer</a>

<p><a name="Quick Quiz 27"><b>Quick Quiz 27</b>:</a>
Why does &ldquo;<tt>cpord</tt>&rdquo; prohibit a cycle containing two
&ldquo;<tt>fre</tt>&rdquo; relationships when &ldquo;<tt>hb</tt>&rdquo;
does not?
They are both acyclic, after all!
<br><a href="#qq27answer">Answer</a>

<h3><a name="Cat File: RCU">Cat File: RCU</a></h3>

<p>
The previous section showed how <tt>smp_mb()</tt> can restore
sequential consistency.
However, as Jade noted, <tt>synchronize_rcu()</tt> is even stronger
still, and therefore requires even more Cat-file code.
The final portion of the Cat file therefore covers
<a href="RCUguarantees.html">RCU</a>
relationships.

<p><a name="Quick Quiz 28"><b>Quick Quiz 28</b>:</a>
Say what???
How can anything possibly be stronger than sequential consistency???
<br><a href="#qq28answer">Answer</a>

<p>
RCU's fragment of the Cat file is as follows:

<blockquote>
<pre>
105 (* Propagation between strong fences *)
106 let rcu-order = hb* ; obs? ; cpord* ; fre? ; propbase* ; rfe?
107
108 (* Chains that can prevent the RCU grace-period guarantee *)
109 let gp-link = sync ; rcu-order
110 let cs-link = po? ; crit^-1 ; po? ; rcu-order
111 let rcu-path0 = gp-link |
112   (gp-link ; cs-link) |
113   (cs-link ; gp-link)
114 let rec rcu-path = rcu-path0 |
115   (rcu-path ; rcu-path) |
116   (gp-link ; rcu-path ; cs-link) |
117   (cs-link ; rcu-path ; gp-link)
118
119 irreflexive rcu-path as rcu
</pre>
</blockquote>

<p><a name="Quick Quiz 29"><b>Quick Quiz 29</b>:</a>
Why the special-purpose Cat code for RCU?
After all, given that there are RCU implementation, why not just translate a
representative implementation into the corresponding set of memory
accesses and memory barriers?
<br><a href="#qq29answer">Answer</a>

<p>
The <tt>rcu-order</tt> relation interfaces the RCU model to the rest
of the memory model, and defines what can order RCU read-side
critical sections and RCU grace periods from each other.
This relation can be roughly thought of as an arbitrarily long
set of sequences of events providing B-cumulativity and then A-cumultivity,
with intervening events providing strong ordering.

<p><a name="Quick Quiz 30"><b>Quick Quiz 30</b>:</a>
But <tt>rcu-order</tt> could be the empty relationship,
so that it would directly connect what preceded it with what followed it.
How can that be right?
<br><a href="#qq30answer">Answer</a>

<p>
The <tt>gp-link</tt> relation is an RCU grace period followed
by some sequence of events that provide sufficient ordering,
and the <tt>cs-link</tt> relation is an RCU read-side critical section
followed by some sequence of events that provide sufficient ordering.
Note that the <tt>cs-link</tt> relation
allows any access preceding an RCU read-side critical section
in that same thread to be used as evidence that an earlier grace period
is ordered before the critical section, and vice versa.
The importance of this is shown by the following litmus test:

<blockquote>
<a id="litmus14" href="C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#14</a>
<pre>
  1 C C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o.litmus
  2
  3 {
  4 }
  5
  6 P0(int *a, int *b)
  7 {
  8   int r1;
  9
 10   r1 = READ_ONCE(*a);
 11   synchronize_rcu();
 12   WRITE_ONCE(*b, 1);
 13 }
 14
 15 P1(int *b, int *c)
 16 {
 17   int r2;
 18
 19   rcu_read_lock();
 20   r2 = READ_ONCE(*b);
 21   WRITE_ONCE(*c, 1);
 22   rcu_read_unlock();
 23 }
 24
 25 P2(int *c, int *d)
 26 {
 27   int r3;
 28
 29   r3 = READ_ONCE(*c);
 30   rcu_read_lock();
 31   // do_something_else();
 32   rcu_read_unlock();
 33   WRITE_ONCE(*d, 1);
 34 }
 35
 36 P3(int *d, int *a)
 37 {
 38   int r4;
 39
 40   r4 = READ_ONCE(*d);
 41   synchronize_rcu();
 42   WRITE_ONCE(*a, 1);
 43 }
 44
 45 exists
 46 (0:r1=1 /\ 1:r2=1 /\ 2:r3=1 /\ 3:r4=1)
</pre>
</blockquote>

<p>
The normal usage of <tt>cs-link</tt> is illustrated by
<tt>P1()</tt>.
The <tt>cs-link</tt> definition could start at line&nbsp;20,
take a <tt>po</tt> step to the <tt>rcu_read_unlock()</tt> on
line&nbsp;13, step back to the <tt>rcu_read_lock()</tt> on line&nbsp;19,
and finally a <tt>po</tt> step to line&nbsp;21.
This implements the rule: &ldquo;If any part of an RCU read-side
critical section follows anything after a given RCU grace period,
then the entirety of that critical section follows anything preceding
that grace period&rdquo;, where the preceding grace period is the
one in <tt>P0()</tt>.

<p>
The more expansive usage is illustrated by <tt>P2()</tt>.
The <tt>cs-link</tt> definition could start at line&nbsp;29,
take a <tt>po</tt> step to the
<tt>rcu_read_unlock()</tt> on line&nbsp;32, then a
<tt>crit^-1</tt>, step back to the <tt>rcu_read_lock()</tt>
on line&nbsp;30, and finally a <tt>po</tt> step to
line&nbsp;33.
This allows <tt>cs-link</tt> (in conjunction with
<tt>rcu-order</tt>) to link the access on
line&nbsp;21 of <tt>P1()</tt> with the access on line&nbsp;40
of <tt>P3()</tt>.

<p>
Without this more expansive definition of <tt>cs-link</tt>,
the questionable outcome
<tt>r1&amp;&amp;r2&amp;&amp;r3&amp;&amp;r4</tt> is permitted, which
it is not, as can be seen by running:

<blockquote>
<pre>
herd7 -conf strong.cfg C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o.litmus
</pre>
</blockquote>

<p>
This gives the reassuring output:

<blockquote>
<a id="litmus14" href="C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#14</a>
<pre>
 1 Test C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o Allowed
 2 States 15
 3 0:r1=0; 1:r2=0; 2:r3=0; 3:r4=0;
 4 0:r1=0; 1:r2=0; 2:r3=0; 3:r4=1;
 5 0:r1=0; 1:r2=0; 2:r3=1; 3:r4=0;
 6 0:r1=0; 1:r2=0; 2:r3=1; 3:r4=1;
 7 0:r1=0; 1:r2=1; 2:r3=0; 3:r4=0;
 8 0:r1=0; 1:r2=1; 2:r3=0; 3:r4=1;
 9 0:r1=0; 1:r2=1; 2:r3=1; 3:r4=0;
10 0:r1=0; 1:r2=1; 2:r3=1; 3:r4=1;
11 0:r1=1; 1:r2=0; 2:r3=0; 3:r4=0;
12 0:r1=1; 1:r2=0; 2:r3=0; 3:r4=1;
13 0:r1=1; 1:r2=0; 2:r3=1; 3:r4=0;
14 0:r1=1; 1:r2=0; 2:r3=1; 3:r4=1;
15 0:r1=1; 1:r2=1; 2:r3=0; 3:r4=0;
16 0:r1=1; 1:r2=1; 2:r3=0; 3:r4=1;
17 0:r1=1; 1:r2=1; 2:r3=1; 3:r4=0;
18 No
19 Witnesses
20 Positive: 0 Negative: 15
21 Condition exists (0:r1=1 /\ 1:r2=1 /\ 2:r3=1 /\ 3:r4=1)
22 Observation C-LB+o-sync-o+rl-o-o-rul+o-rl-rul-o+o-sync-o Never 0 15
23 Hash=c792a4c620a9d5244c0bee80da2a90fa
</pre>
</blockquote>

<p>
In short, if anything within or preceding a given RCU read-side critical
section follows anything after a given RCU grace period, then it is
probably best if that entire RCU read-side critical section follows
anything preceding the grace period, and vice versa.

<p>
The <tt>rcu-path0</tt>
(RCU path base case) relation defines the three basic ways that
RCU provides ordering:

<ol>
<li>	A single <tt>synchronize_rcu()</tt> invocation, which
	in theory may be substituted for <tt>smp_mb()</tt>.
	(In practice, good luck with instances of <tt>smp_mb()</tt>
	in preempt-disabled regions of code, to say nothing of the
	disastrous degradation of performance.)
<li>	A <tt>synchronize_rcu()</tt> that is ordered before an
	RCU read-side critical section.
	This commonly used case guarantees that if some RCU read-side
	critical section extends beyond the end of a grace period,
	then all of that RCU read-side critical section happens after
	anything preceding that grace period.
	In other words, if any part of the critical section might happen
	after the <tt>kfree()</tt>, all of that critical section will
	happen after the corresponding <tt>list_del_rcu()</tt>.
	This case groups the RCU grace period in <tt>P0()</tt>
	and the RCU read-side critical section in <tt>P1()</tt>
	in the example above.
<li>	An RCU read-side critical section that is ordered before a
	<tt>synchronize_rcu()</tt>.
	This commonly used case guarantees that if some RCU read-side
	critical section extends before the beginning of a grace period,
	then all of that RCU read-side critical section happens before
	anything following that grace period.
	In other words, if any part of the critical section might happen
	before the <tt>list_del_rcu()</tt>, all of that critical section will
	happen before the corresponding the <tt>kfree()</tt>.
	This case groups the the RCU read-side critical section in
	<tt>P2()</tt> and RCU grace period in <tt>P3()</tt>
	in the example above.
</ol>

<p>
The recursive definition of <tt>rcu-path</tt> builds on the
<tt>rcu-path0</tt> base case.
Then <tt>(rcu-path;rcu-path)</tt> states that
if any two sequences of RCU grace periods and read-side critical sections
provide ordering, then the concatenation of those two sequences also
provides ordering, and applies to the <tt>P0()</tt>-<tt>P1()</tt>
and <tt>P2()</tt>-<tt>P3()</tt> groups in the example above,
thus guaranteeing that the questionable outcome
<tt>r1&amp;&amp;r2&amp;&amp;r3&amp;&amp;r4</tt> is forbidden.
On the other hand, the <tt>(gp-link;rcu-path;cs-link)</tt> states
that if some sequence of RCU grace periods and read-side critical sections
provides ordering, then ordering is still provided when that sequence
is preceded by <tt>synchronize_rcu()</tt> and followed by an RCU
read-side critical section.
Finally, line&nbsp;13's <tt>(cs-link;rcu-path;gp-link)</tt> states
that if some sequence of RCU grace periods and read-side critical sections
provides ordering, then ordering is still provided when that sequence
is preceded by an RCU read-side critical section and followed by
<tt>synchronize_rcu()</tt>.

<p>
The <tt>irreflexive</tt> statement prohibits <tt>rcu-path</tt> from looping
back on itself, in other words, this statement requires <tt>rcu-path</tt>
to provide ordering.

<p>
Another way of thinking of <tt>rcu-path</tt> is of a counter
and comparison, implemented recursively.
If there are at least as many calls to <tt>synchronize_rcu()</tt>
as there are RCU read-side critical sections in a given
<tt>rcu-path</tt>, ordering is guaranteed, otherwise not.

<p>
Let's use this machinery to analyze the prototypical RCU-deferred-free
scenario:

<blockquote>
<a id="litmus15" href="C-LB+rl-deref-o-rul+o-sync-o.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#15</a>
<pre>
  1 C C-LB+rl-deref-o-rul+o-sync-o.litmus
  2
  3 {
  4   a=x;
  5 }
  6
  7 P0(int **a)
  8 {
  9   int *r1;
 10   int r2;
 11
 12   rcu_read_lock();
 13   r1 = rcu_dereference(*a);
 14   r2 = READ_ONCE(*r1);
 15   rcu_read_unlock();
 16 }
 17
 18 P1(int **a, int *x, int *y)
 19 {
 20   WRITE_ONCE(*a, y);
 21   synchronize_rcu();
 22   WRITE_ONCE(*x, 1);  /* Emulate kfree(). */
 23 }
 24
 25 exists
 26 (0:r1=x /\ 0:r2=1)
</pre>
</blockquote>

<p>
The variable <tt>a</tt> initially references the variable <tt>x</tt>,
which is initially zero.
The <tt>P1()</tt> function sets variable <tt>a</tt> to reference
the variable <tt>y</tt> (also initially zero), then sets the value
of <tt>x</tt> to 1 to emulate the effects of <tt>kfree()</tt>.
Any RCU reader accessing and dereferencing <tt>a</tt> should therefore
see the value zero, so that the outcome <tt>r2</tt> should
be forbidden.
In other words, we would expect the cycle
20&#10230;22&#10230;14&#10230;15&#10230;12&#10230;13&#10230;20
to be forbidden.
Let's check!

<p>
Lines&nbsp;12&#10230;15 is a
<tt>crit</tt> relationship, while
lines&nbsp;20&#10230;22 is a <tt>sync</tt> relationship.
If the cycle is allowed,
Lines&nbsp;13&#10230;20 form an <tt>fre</tt> relationship
and lines&nbsp;22&#10230;14 form an <tt>rfe</tt> relationship.
This means that lines&nbsp;13&#10230;20 and lines&nbsp;22&#10230;14 are also
<tt>rcu-order</tt> relationships.
This means that the series 20&#10230;22&#10230;14 is a
<tt>gp-link</tt>
relationship.

<p>
Given that lines&nbsp;14&#10230;15 and&nbsp;12&#10230;13 are
<tt>po</tt> relationships,
the series 14&#10230;15&#10230;12&#10230;13&#10230;20 is a
<tt>cs-link</tt> relationship.
We therefore have an <tt>gp-link</tt> relationship
followed by a <tt>cs-link</tt> (or vice versa), so
that the series
20&#10230;22&#10230;14&#10230;15&#10230;12&#10230;13&#10230;20
is an <tt>rcu-path0</tt>
relationship, which means that this same series is also an
<tt>rcu-path</tt> relationship.
Because it ends where it starts, on line&nbsp;20, it is reflexive,
and thus forbidden.
The following command confirms this:

<blockquote>
<pre>
herd7 -conf strong.cfg C-LB+rl-deref-o-rul+o-sync-o.litmus
</pre>
</blockquote>

<p>
This command produces the following output:

<blockquote>
<a id="litmus15" href="C-LB+rl-deref-o-rul+o-sync-o.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#15</a>
<pre>
 1 Test C-LB+rl-deref-o-rul+o-sync-o Allowed
 2 States 2
 3 0:r1=x; 0:r2=0;
 4 0:r1=y; 0:r2=0;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (0:r1=x /\ 0:r2=1)
 9 Observation C-LB+rl-deref-o-rul+o-sync-o Never 0 2
10 Hash=4cac9d9e7ffa84096d8869e1ab199f09
</pre>
</blockquote>

<p>
Therefore, the RCU read-side critical section in <tt>P0()</tt>
cannot see the emulated <tt>kfree()</tt> following <tt>P1()</tt>'s
grace period, which should be some comfort to users of RCU.

<p><a name="Quick Quiz 31"><b>Quick Quiz 31</b>:</a>
Why does
<a href="#litmus15">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#15</a>'s
<tt>exists</tt> clause specify <tt>0:r1=x</tt>?
Isn't the second clause (<tt>0:r2=1</tt>) forbidden in and of itself?
<br><a href="#qq31answer">Answer</a>

<p>
But suppose we add another RCU read-side critical section to the mix,
in the following somewhat inane but hopefully instructive example?

<blockquote>
<a id="litmus16" href="C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#16</a>
<pre>
  1 C C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu.litmus
  2
  3 {
  4   a=x;
  5 }
  6
  7 P0(int **a)
  8 {
  9   int *r1;
 10   int r2;
 11
 12   rcu_read_lock();
 13   r1 = rcu_dereference(*a);
 14   r2 = READ_ONCE(*r1);
 15   rcu_read_unlock();
 16 }
 17
 18 P1(int **a, int *y, int *z)
 19 {
 20   WRITE_ONCE(*a, y);
 21   synchronize_rcu();
 22   WRITE_ONCE(*z, 1);
 23 }
 24
 25 P2(int *x, int *z)
 26 {
 27   int r3;
 28
 29   rcu_read_lock();
 30   r3 = READ_ONCE(*z);
 31   WRITE_ONCE(*x, 1);  /* Emulate kfree(). */
 32   rcu_read_unlock();
 33 }
 34
 35 exists
 36 (0:r1=x /\ 0:r2=1 /\ 2:r3=1)
</pre>
</blockquote>

<p>
Can the outcome <tt>r2</tt> happen now?

<p>
Lines&nbsp;12&#10230;15 and&nbsp;29&#10230;32 are
<tt>crit</tt> relationships, while
Lines&nbsp;20&#10230;22 is a <tt>sync</tt> relationship.
Lines&nbsp;22&#10230;30 and&nbsp;31&#10230;14 are <tt>rfe</tt>
relationships and lines&nbsp;13&#10230;20 are an <tt>fre</tt>,
which means that all are also
<tt>rcu-order</tt> relationships.
This means that the series 20&#10230;22&#10230;30 is a
<tt>gp-link</tt>
relationship.

<p>
Given that lines&nbsp;14&#10230;15 and&nbsp;12&#10230;13 are
<tt>po</tt> relationships,
the series
14&#10230;15&#10230;12&#10230;13&#10230;20 is a <tt>cs-link</tt>
relationship.
Similarly, because lines&nbsp;30&#10230;32 and&nbsp;29&#10230;31 are
<tt>po</tt> relationships,
the series 30&#10230;32&#10230;29&#10230;31&#10230;14
is also a <tt>cs-link</tt>
relationship.

<p>
We therefore have one <tt>cs-link</tt> relationship
followed by a <tt>gp-link</tt> relationship, which in
turn is followed by another <tt>cs-link</tt> relationship.
The <tt>cs-link</tt> relationship
14&#10230;15&#10230;12&#10230;13&#10230;20
can combine with the
<tt>gp-link</tt> relationship
20&#10230;22&#10230;30
to form the <tt>rcu-path0</tt> relationship
14&#10230;15&#10230;12&#10230;13&#10230;20&#10230;22&#10230;30.
However, there is no way to add the remaining <tt>cs-link</tt>
relationship 30&#10230;32&#10230;29&#10230;31&#10230;14,
so the cycle resulting in
<tt>r2</tt> can in fact happen.
This is confirmed by the command:

<blockquote>
<pre>
herd7 -conf strong.cfg C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu.litmus
</pre>
</blockquote>

<p>
Which produces the output:

<blockquote>
<a id="litmus16" href="C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#16</a>
<pre>
 1 Test C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu Allowed
 2 States 6
 3 0:r1=x; 0:r2=0; 2:r3=0;
 4 0:r1=x; 0:r2=0; 2:r3=1;
 5 0:r1=x; 0:r2=1; 2:r3=0;
 6 0:r1=x; 0:r2=1; 2:r3=1;
 7 0:r1=y; 0:r2=0; 2:r3=0;
 8 0:r1=y; 0:r2=0; 2:r3=1;
 9 Ok
10 Witnesses
11 Positive: 1 Negative: 5
12 Condition exists (0:r1=x /\ 0:r2=1 /\ 2:r3=1)
13 Observation C-LB+rl-deref-o-rul+o-sync-o+rl-o-o-rlu Sometimes 1 5
14 Hash=b591d622245952a2fc8eaad233203817
</pre>
</blockquote>

<p>
This should be no surprise, given that we have more RCU read-side
critical sections than we have grace periods.
This situation underscores the need to avoid doing inane things with RCU.
However, one nice thing about a memory model incorporating
RCU is that such inanity can now be detected, at least when it is
confined to relatively small code fragments.

</p><h2>Acknowledgments</h2>

<p>We owe thanks to H.&nbsp;Peter Anvin, Will Deacon, Andy Glew,
Derek Williams, Leonid Yegoshin, and Peter Zijlstra for their
patient explanations of their respective systems' memory models.
We are indebted to Peter Sewell, Sumit Sarkar, and their groups
for their seminal work formalizing many of these same memory models.
We all owe thanks to Dmitry Vyukov, Boqun Feng, and Peter Zijlstra for
their help making this human-readable.
We are also grateful to Michelle Rankin and Jim Wasko for their support
of this effort.

</p><p>This work represents the views of the authors and does not necessarily
represent the views of University College London, INRIA Paris,
Scuola Superiore Sant'Anna, Harvard University, or IBM Corporation.

</p><p>Linux is a registered trademark of Linus Torvalds.

</p><p>Other company, product, and service names may be trademarks or
service marks of others.

<h3><a name="Answers to Quick Quizzes">
Answers to Quick Quizzes</a></h3>

<a name="qq1answer"></a>
<p><b>Quick Quiz 1</b>:
But couldn't a CPU designer create a memory subsystem that did
allow writes to be taken back?


</p><p><b>Answer</b>:
Maybe someday they will.
However, such a CPU would still need to provide ordering,
and if it provided ordering similar to current CPU families,
it is quite possible that our current models would simply consider
the portion of the memory that allows prior writes to be taken back
to be part of the CPU rather than part of the memory subsystem.


</p><p><a href="#Quick%20Quiz%201"><b>Back to Quick Quiz 1</b>.</a>

<a name="qq2answer"></a>
<p><b>Quick Quiz 2</b>:
Why can't CPU designers use speculation to hide the slowness of
strong barriers?


</p><p><b>Answer</b>:
They can and they do.
However, they must take care when doing so, because the hardware absolutely
must respect the barriers' semantics.
This requires complex circuitry to detect cases where speculation must
be squashed, and can impose additional delays when rerunning the
speculated instructions.
So nothing comes for free, but speculation is indeed a powerful tool
that is heavily used by high-performance CPUs.


</p><p><a href="#Quick%20Quiz%202"><b>Back to Quick Quiz 2</b>.</a>

<a name="qq3answer"></a>
<p><b>Quick Quiz 3</b>:
Isn't this single coherence point a huge bottleneck on large systems?


</p><p><b>Answer</b>:
Not necessarily.
Although the model is presented in terms of a single coherence point,
the only real requirement is that there be a single coherence point
for a given variable at a given point in time.
This requirement is satisified by the cache line holding that variable,
which can move around as needed.
In addition, this means that the system can enjoy the scalability of
a coherence point per cache line, which should suffice even for the
very largest of systems.

<p>
But what if all the CPUs are writing to a single variable?

<p>
This does not sound like particularly enlightened software design, but
a scalable hardware implementation simply relies on the store buffers.
Given that there is one store buffer per CPU (or at least per core),
this should not limit scalability,
give or take constraints imposed by memory ordering.


</p><p><a href="#Quick%20Quiz%203"><b>Back to Quick Quiz 3</b>.</a>

<a name="qq4answer"></a>
<p><b>Quick Quiz 4</b>:
But how could the system possibly prevent some other write on some other
CPU from taking place between the time the RMW's read and write execute?
Is there some Big System Lock implemented in hardware that will totally
destroy scalability???


</p><p><b>Answer</b>:
It can't, but there is no need for a Big System Lock.
After all, it is not time that matters, but rather coherence order.
To see this, consider the following time-ordered sequence of events:

<ol>
<li>	CPU 0 executes the read portion of its RMW operation to variable x.
<li>	CPU 1 writes to x.
<li>	CPU 0 executes the write portion of its RMW operation.
</ol>

<p>
The system has the option of placing CPU&nbsp;1's write to x after
CPU 0's write to x in coherence order, which avoids the need for tight
(and thus expensive) coordination between the CPUs, while still preserving
the atomic nature of the RMW operation.

<p>
Another option is for the memory subsystem to cause CPU&nbsp;0's write
to <i>fail</i> in this circumstance.
On architectures that do this, RMW operations have to be implemented as a loop
in software, where the CPU goes back to the initial read
if the write portion is not successful.


</p><p><a href="#Quick%20Quiz%204"><b>Back to Quick Quiz 4</b>.</a>

<a name="qq5answer"></a>
<p><b>Quick Quiz 5</b>:
The terms &ldquo;A-cumulativity&rdquo; and &ldquo;B-cumulativity&rdquo;
aren't particularly mnemonic, are they?


</p><p><b>Answer</b>:
They are perfectly mnemonic.
The &lsquo;A&rsquo; stands for the French word <i>avant</i>, which
translates to &ldquo;before&rdquo;, and it is the A-cumulative barriers'
pre-sets that are modified by A-cumulativity.
The &lsquo;B&rsquo; stands for the Swahili word <i>baada</i>, which
translates to &ldquo;after&rdquo;, and it is the B-cumulative barriers'
post-sets that are modified by B-cumulativity.
<!-- I could also have chosen Hausa or Tajik.  Hausa is less familiar to
me than Swahili, and Tajik is written in Cyrillic, so Swahili it is! -->

<p>
Or you could just remember that &lsquo;A&rsquo; precedes &lsquo;B&rsquo;
in the Latin alphabet.


</p><p><a href="#Quick%20Quiz%205"><b>Back to Quick Quiz 5</b>.</a>

<a name="qq6answer"></a>
<p><b>Quick Quiz 6</b>:
By symmetry, shouldn't a B-cumulative barrier's post-set include all writes
that propagate to the barrier's CPU after the barrier is committed?


</p><p><b>Answer</b>:
Symmetry is in the eye of the beholder.
Beholders who care about hardware performance and scalability
(or, for that matter, clean semantics) will
prefer the definition in the list over the definition in this Quick Quiz's
question.
Working out why is left as an exercise for the reader.
[Hint: What should happen if a write on one CPU commits before
a barrier on another CPU, but the write doesn't propagate to the other CPU
until after the barrier has committed?]


</p><p><a href="#Quick%20Quiz%206"><b>Back to Quick Quiz 6</b>.</a>

<a name="qq7answer"></a>
<p><b>Quick Quiz 7</b>:
Given the steadily increasing number of transistors, why couldn't a CPU
analyze code to detect at least some classes of &ldquo;<tt>x == x</tt>&rdquo;
comparisons?


</p><p><b>Answer</b>:
Several existing CPU architectures guarantee that even trivial conditionals
will provide ordering, so they have no reason to perform such an analysis.
However, a new CPU family might well carry out such analyses.
If this happened, this CPU family would probably need to provide an option
to suppress trivial-conditional detection in order to correctly execute
pre-existing code.
But if this hardware optimization came into being and proved sufficiently
valuable, it might be necessary to adjust accordingly.


</p><p><a href="#Quick%20Quiz%207"><b>Back to Quick Quiz 7</b>.</a>

<a name="qq8answer"></a>
<p><b>Quick Quiz 8</b>:
Given all these constraints, how can weak-memory CPUs possibly expect to
attain any benefits of any sort compared to strong-memory CPUs?


</p><p><b>Answer</b>:
This argument between proponents of strong and weak memory ordering has
been going on for some decades, so we do not expect to be able to settle
it here.
Nevertheless, even with all these constraints there's still plenty of
wiggle room.
And don't forget, strong-memory CPUs are also subject to all these
restrictions.


</p><p><a href="#Quick%20Quiz%208"><b>Back to Quick Quiz 8</b>.</a>

<a name="qq9answer"></a>
<p><b>Quick Quiz 9</b>:
Following up on exercise for the reader in the <tt>detour</tt>
relationship, what happens if the value from the write is forwarded
to that thread's later read?


</p><p><b>Answer</b>:
Then there will be no <tt>detour</tt> link from the write to the read,
since the <tt>rfe</tt> term in <tt>detour</tt> requires the read to
obtain its value from a write in a different thread.
As a result, the read is not forced to execute after the write.


</p><p><a href="#Quick%20Quiz%209"><b>Back to Quick Quiz 9</b>.</a>

<a name="qq10answer"></a>
<p><b>Quick Quiz 10</b>:
What about RMW (read-modify-write) instructions, such as <tt>xchg()</tt>
or <tt>atomic_inc()</tt>?
Don't they constitute both a read and a write?


</p><p><b>Answer</b>:
Yes, RMW instructions do constitute both a read and a write.
But <tt>herd</tt> represents such instructions
internally as a read event followed by a separate write event.
(And that is also how they are treated by the hardware.)
No single event is ever both a read and a write.


</p><p><a href="#Quick%20Quiz%2010"><b>Back to Quick Quiz 10</b>.</a>

<a name="qq11answer"></a>
<p><b>Quick Quiz 11</b>:
But this <tt>short-obs</tt> link goes backward from line&nbsp;20 to
line&nbsp;18!
How can a backward link on a single CPU represent a
&ldquo;happens-before&rdquo; ordering relation???


</p><p><b>Answer</b>:
It's true that unlike the other intra-CPU relations that make up <tt>hb</tt>,
<tt>short-obs</tt> and <tt>obs</tt> can create links that go backward
in program order.
There's nothing sinister going on here;
it's merely a reflection of the fact that modern CPUs can and do
execute instructions out of order.


</p><p><a href="#Quick%20Quiz%2011"><b>Back to Quick Quiz 11</b>.</a>

<a name="qq12answer"></a>
<p><b>Quick Quiz 12</b>:
Readers who go to the trouble of reading the actual definition of
<tt>cpord</tt> in the Linux-kernel strong memory model will see that
it includes the <tt>co</tt>, <tt>propbase & (W*W)</tt>, and <tt>strong-prop</tt>
terms mentioned earlier, but it does not include any terms corresponding to
the &ldquo;trivial&rdquo; case of a <tt>propbase</tt> or <tt>hb+</tt> link
starting from a read.
Why not?


</p><p><b>Answer</b>:
It turns out that the &ldquo;trivial&rdquo; terms aren't necessary.
Including them in the definition of <tt>cpord</tt> wouldn't hurt,
but it wouldn't change the model's predictions in any way.
For any cycle in <tt>cpord</tt> involving these terms, there is a
cycle already forbidden by the model without the terms.

<p>
As the simplest case, suppose each link in the cycle is an instance of
<tt>hb+ & (R*M)</tt> (i.e., a sequence of <tt>hb</tt> links starting
from a read).
Then the entire cycle is itself a cycle in <tt>hb</tt>, and so is forbidden
by the &ldquo;happens-before&rdquo; check.

<p>
For the more general case, suppose there is a cycle in which an instance
of <tt>hb+ & (R*M)</tt> follows one of the other terms making up <tt>cpord</tt>.
Since that other term must end in a read, it cannot be an instance of
<tt>co</tt> or <tt>propbase & (W*W)</tt>; hence it must be an instance
of <tt>strong-prop</tt>.
But the definition of <tt>strong-prop</tt> ends in <tt>hb*</tt>, so
<tt>strong-prop</tt> followed by a sequence of <tt>hb</tt> links is still
an instance of <tt>strong-prop</tt>.
Thus the two terms can be combined into a single <tt>strong-prop</tt> term.
In this way, all the instances of <tt>hb+ & (R*M)</tt> in the cycle
can be absorbed into the <tt>strong-prop</tt> terms,
leaving a forbidden cycle containing none of the &ldquo;trivial&rdquo;
terms at all.


</p><p><a href="#Quick%20Quiz%2012"><b>Back to Quick Quiz 12</b>.</a>

<a name="qq13answer"></a>
<p><b>Quick Quiz 13</b>:
Given how important split caches are for attaining full performance on
superscalar CPUs, why don't any non-Alpha architectures have split caches?


</p><p><b>Answer</b>:
Other architectures <i>do</i> have split caches.
However, these other architectures also have additional circuitry
that preserves read-to-read dependencies among accesses to different
banks of their split caches.


</p><p><a href="#Quick%20Quiz%2013"><b>Back to Quick Quiz 13</b>.</a>

<a name="qq14answer"></a>
<p><b>Quick Quiz 14</b>:
Why weren't adjustments needed for PowerPC, given that it has a weak
memory model?


</p><p><b>Answer</b>:
The reason that no adjustments were needed for PowerPC was that we
started with PPCMEM's Power memory model.
Alternatively, one could argue that all necessary adjustments for
PowerPC were made at the very beginning of this effort.
For those keeping score, the fact that PowerPC's release-acquire chains
do not provide full ordering does cause significant heartburn in some
circles.


</p><p><a href="#Quick%20Quiz%2014"><b>Back to Quick Quiz 14</b>.</a>

<a name="qq15answer"></a>
<p><b>Quick Quiz 15</b>:
Why weren't adjustments needed for Itanium, given that it allows
reads to the same variable to be reordered?


</p><p><b>Answer</b>:
Because <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> use volatile
accesses, which compile to <tt>ld,acq</tt> and <tt>st,rel</tt>
instructions, respectively.
These instructions provide the single-variable-SC guarantee needed
by the Linux kernel.


</p><p><a href="#Quick%20Quiz%2015"><b>Back to Quick Quiz 15</b>.</a>

<a name="qq16answer"></a>
<p><b>Quick Quiz 16</b>:
But what if some new CPU had an even weaker memory model than
Alpha, ARM, and PowerPC?
Mightn't that invalidate a lot of Linux-kernel code?


</p><p><b>Answer</b>:
In theory, it might.
In practice, we expect that the Linux kernel community would be
highly motivated to include memory-barrier instructions in the
new CPU's arch-specific code
so as to minimize (or perhaps even eliminate) core Linux-kernel modifications.
We also hope that this prospect will encourage future CPU designers and
architects to avoid the need for excessive numbers of memory-barrier
instructions.


</p><p><a href="#Quick%20Quiz%2016"><b>Back to Quick Quiz 16</b>.</a>

<a name="qq17answer"></a>
<p><b>Quick Quiz 17</b>:
Given that this is about memory barriers, why
&ldquo;<tt>instructions F[Barriers]</tt>&rdquo; instead of perhaps
&ldquo;<tt>instructions B[Barriers]</tt>&rdquo;?


</p><p><b>Answer</b>:
&ldquo;Memory barriers&rdquo; are also sometimes called
&ldquo;memory fences&rdquo;.
This can be confusing, but both terms are used so we might
as well get used to it.
Besides, the &ldquo;<tt>B</tt>&rdquo; instruction class
was already reserved for Branches.


</p><p><a href="#Quick%20Quiz%2017"><b>Back to Quick Quiz 17</b>.</a>

<a name="qq18answer"></a>
<p><b>Quick Quiz 18</b>:
Why wouldn't &ldquo;<tt>let sync = fencerel(Sync)</tt>&rdquo;
work just as well as the modified definition?


</p><p><b>Answer</b>:
The modified definition is necessary because the model needs to recognize that
code like:

<blockquote>
<pre>
WRITE_ONCE(*x, 1);
synchronize_rcu();
synchronize_rcu();
r2 = READ_ONCE(*y);
</pre>
</blockquote>

<p>
will insert two grace periods between the memory accesses, not just one.
With the modified definition, there is a &ldquo;<tt>sync</tt>&rdquo;
pair linking the
<tt>WRITE_ONCE()</tt> to the first <tt>synchronize_rcu()</tt> as well as
a pair linking that event to the <tt>READ_ONCE()</tt>,
so it is possible to pass from the write to the read via two links.
With the &ldquo;<tt>let sync = fencerel(Sync)</tt>&rdquo; definition,
there would be no link from the <tt>WRITE_ONCE()</tt> to the
first <tt>synchronize_rcu()</tt>.
Consequently there would be a path from the write to the read
involving one link, but no path involving two.


</p><p><a href="#Quick%20Quiz%2018"><b>Back to Quick Quiz 18</b>.</a>

<a name="qq19answer"></a>
<p><b>Quick Quiz 19</b>:
This strong model is insanely complex!!!
How can anyone be expected to understand it???


</p><p><b>Answer</b>:
Given that this model is set up to be as strong as reasonably possible given
the rather wide variety of memory models that the Linux kernel runs
on, it is actually surprisingly simple.
Furthermore, this model has a tool that goes with it, which is more
than can be said of <tt>memory-barriers.txt</tt>.

<p>
Nevertheless, it is quite possible that this model should be carefully
weakened, if it turns out that doing so simplifies the model
without invalidating any use cases.
Simpler but weaker models can be found
<a href="weak2-kernel.cat">here</a> and
<a href="weak3-kernel.cat">here</a>.


</p><p><a href="#Quick%20Quiz%2019"><b>Back to Quick Quiz 19</b>.</a>

<a name="qq20answer"></a>
<p><b>Quick Quiz 20</b>:
Why aren't these additional classes of fences in the
<a href="strong-kernel.bell">Bell file</a>
where the other classes live?


</p><p><b>Answer</b>:
Because <tt>exec-order-fence</tt>, <tt>propagation-fence</tt>, and
<tt>ordering-fence</tt> aren't needed by either the
<a href="weak2-kernel.cat">weak2</a> or
<a href="weak3-kernel.cat">weak3</a> model,
both of which share the
<a href="strong-kernel.bell">Bell file</a>.


</p><p><a href="#Quick%20Quiz%2020"><b>Back to Quick Quiz 20</b>.</a>

<a name="qq21answer"></a>
<p><b>Quick Quiz 21</b>:
Why would an operation following an address dependency get any special
treatment?
After all, there does not appear to be any particular ordering relationship
in the general case.


</p><p><b>Answer</b>:
It turns out that PowerPC guarantees that writes following an
address-dependency pair are guaranteed not to be reordered before
the load heading up the dependency pair, as can be seen from this
<a href="PPC-LB+addrs-po.litmus">load-buffering litmus test</a>
and its <a href="PPC-LB+addrs-po.litmus.out">output</a> (note the
&ldquo;Never&rdquo; on the last line) and from this
<a href="PPC-MP+lwsync+addr-po.litmus">message-passing litmus test</a>
and its <a href="PPC-MP+lwsync+addr-po.litmus.out">output</a>.

<p>
Why would PowerPC and other architectures provide such ordering
from a load to an unrelated store?
Because until the load completes, the CPU can't tell whether or not
the store is unrelated.
If the load ends up causing its dependent access to target
the same address that is used by the &ldquo;unrelated&rdquo;
store, then the accesses are no longer unrelated and the CPU must
provide ordering between them.
Since the CPU can't know what ordering requirements there might be until
the load completes, all later writes must wait for the load.

<p>
There's a second reason.
Until the load completes, the CPU can't tell whether the dependent access
will cause an addressing exception.
If an exception does occur then later stores should not be executed,
even if they are unrelated.

<p>
But what about loads?
Don't they have the same ordering requirements?

<p>
Indeed they do, but the CPU can safely speculate such loads, squashing the
speculation if it later learns that there was an unexpected address
collision or an exception.
For more information on this dependency/ordering corner case, please see
section 10.5 of
<a href="http://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf">A Tutorial Introduction to the ARM and POWER Relaxed Memory Models</a>.
Other sections cover many other interesting corner cases.


</p><p><a href="#Quick%20Quiz%2021"><b>Back to Quick Quiz 21</b>.</a>

<a name="qq22answer"></a>
<p><b>Quick Quiz 22</b>:
You said that these were <tt>ppo</tt> relations limited by DEC Alpha,
but obscurable writes are an ARM limitation.
What gives?


</p><p><b>Answer</b>:
Left to itself, DEC Alpha would provide ordering in cases where ARM
obscures reads and writes, which means that the model must be very careful
to <i>not</i> provide ordering in these cases.
After all, the model cannot forbid outcomes that the ARM architecture
could allow.
Therefore, the
(<tt>(po-loc &amp; ((M\OW\OR)*W))</tt> limits Alpha's <tt>po-loc</tt>
ordering to relations linking from non-obscurable reads and writes.
If short, it is necessary to weaken Alpha a little bit in order to
properly model ARM's obscurable accesses.


</p><p><a href="#Quick%20Quiz%2022"><b>Back to Quick Quiz 22</b>.</a>

<a name="qq23answer"></a>
<p><b>Quick Quiz 23</b>:
But <tt>ARM-strong-ppo</tt> (and thus <tt>ppo</tt>) includes <tt>addr</tt>,
which links reads to later dependent reads, which DEC Alpha does not respect.
How is this supposed to work?


</p><p><b>Answer</b>:
The <tt>po-relass-acq-hb</tt> relation is used only for A-cumulativity,
so it is not guaranteeing that the dependent read sees the &ldquo;right&rdquo;
data, but rather the A-cumulative behavior of a later ordering construct.


</p><p><a href="#Quick%20Quiz%2023"><b>Back to Quick Quiz 23</b>.</a>

<a name="qq24answer"></a>
<p><b>Quick Quiz 24</b>:
Why don't these relations match those shown in the
<a href="#Execution ordering: write propagation and cumulativity">
Execution ordering: write propagation and cumulativity</a> section?


</p><p><b>Answer</b>:
That section documents the original PowerPC-based model,
and does not include later changes, for example, those required to
accommodate Alpha and ARM.
Therefore, the <tt>cat</tt> code shown in that section differs somewhat
from the current model.


</p><p><a href="#Quick%20Quiz%2024"><b>Back to Quick Quiz 24</b>.</a>

<a name="qq25answer"></a>
<p><b>Quick Quiz 25</b>:
The <tt>hb</tt> relation seems to have a lot of moving parts, and
the choices seem a bit on the arbitrary side.
What gives?


</p><p><b>Answer</b>:
This is the strong model, which intentionally trades away simplicity
to get added strength.
The added strength implies added complexity because the strong model
is necessarily limited by the various weaknesses of the hardware that
the Linux kernel runs on.

<p>
A simpler but weaker model can be found
<a href="weak-kernel.cat">here</a>,
and is described
<a href="WeakModel.html">here</a>.


</p><p><a href="#Quick%20Quiz%2025"><b>Back to Quick Quiz 25</b>.</a>

<a name="qq26answer"></a>
<p><b>Quick Quiz 26</b>:
Is there an easy way to tell which definitions have effect for a
given litmus test?


</p><p><b>Answer</b>:
One very straightforward approach is to edit the .cat and .bell files
to remove &ldquo;<tt>acyclic</tt>&rdquo; or
&ldquo;<tt>irreflexive</tt>&rdquo; statements.
For example, for the above store-buffering litmus test, removing
the &ldquo;<tt>acyclic cpord as propagation</tt>&rdquo; allows
the cyclic outcome.

<p>
Alternatively, you can pass the
&ldquo;<tt>-skipcheck propagation</tt>&rdquo; argument-line argument to
<tt>herd7</tt>.
However, editing the .bell and .cat files to omit different elements
can be an extremely educational activity.


</p><p><a href="#Quick%20Quiz%2026"><b>Back to Quick Quiz 26</b>.</a>

<a name="qq27answer"></a>
<p><b>Quick Quiz 27</b>:
Why does &ldquo;<tt>cpord</tt>&rdquo; prohibit a cycle containing two
&ldquo;<tt>fre</tt>&rdquo; relationships when &ldquo;<tt>hb</tt>&rdquo;
does not?
They are both acyclic, after all!


</p><p><b>Answer</b>:
The difference is that &ldquo;<tt>hb</tt>&rdquo; requires that any
path including an &ldquo;<tt>fre</tt>&rdquo; relationship begin and
end at the same thread.
Therefore, no matter how you string &ldquo;<tt>hb</tt>&rdquo;
relationships together, they cannot prohibit a cycle that goes
through two &ldquo;<tt>fre</tt>&rdquo; relationship before returning
to the original thread, and thus cannot prohibit the store-buffering
litmus test.
In contrast, the &ldquo;<tt>strong-prop</tt>&rdquo; relationship that
leads up to the &ldquo;<tt>cpord</tt>&rdquo; relationship makes no
same-thread restriction, which means that &ldquo;<tt>cpord</tt>&rdquo;
can forbid a cycle containing more than one &ldquo;<tt>fre</tt>&rdquo;
relationship.


</p><p><a href="#Quick%20Quiz%2027"><b>Back to Quick Quiz 27</b>.</a>

<a name="qq28answer"></a>
<p><b>Quick Quiz 28</b>:
Say what???
How can anything possibly be stronger than sequential consistency???


</p><p><b>Answer</b>:
Easily.

<p>
To see this, recall the store-buffering example from the previous section,
in which <tt>smp_mb()</tt> prevented any executions that were not
simple interleavings, in other words, it prohibits the cyclic outcome
&ldquo;<tt>!r1&amp;&amp;!r2</tt>&rdquo;.
If we replace the first <tt>smp_mb()</tt> with <tt>synchronize_rcu()</tt>,
replace the second <tt>smp_mb()</tt> with with an RCU read-side
critical section, and reverse <tt>P1()</tt>'s memory references,
we get the following:

<blockquote>
<a id="litmus17" href="C-LB+o-sync-o+rl-o-o-rul.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#17</a>
<pre>
  1 C C-LB+o-sync-o+rl-o-o-rul.litmus
  2
  3 {
  4 }
  5
  6 P0(int *a, int *b)
  7 {
  8   int r1;
  9
 10   r1 = READ_ONCE(*a);
 11   synchronize_rcu();
 12   WRITE_ONCE(*b, 1);
 13 }
 14
 15 P1(int *b, int *a)
 16 {
 17   int r2;
 18
 19   rcu_read_lock();
 20   r2 = READ_ONCE(*b);
 21   WRITE_ONCE(*a, 1);
 22   rcu_read_unlock();
 23 }
 24
 25 exists
 26 (0:r1=1 /\ 1:r2=1)
</pre>
</blockquote>

<p>
It turns out that <tt>synchronize_rcu()</tt> is so strong that it
is able to forbid the cyclic outcome &ldquo;<tt>r1&amp;&amp;r2</tt>&rdquo;
<i>even though</i> <tt>P1()</tt> <i>places no ordering constraints whatsoever
on its two memory references</i>.

<p>
Now <i>that</i> is strong ordering!

<p>
There is of course no free lunch.
On systems having more than one CPU, the overhead of
<tt>synchronize_rcu()</tt> is orders of magnitude greater than that of
<tt>smp_mb()</tt>.
You get what you pay for!


</p><p><a href="#Quick%20Quiz%2028"><b>Back to Quick Quiz 28</b>.</a>

<a name="qq29answer"></a>
<p><b>Quick Quiz 29</b>:
Why the special-purpose Cat code for RCU?
After all, given that there are RCU implementation, why not just translate a
representative implementation into the corresponding set of memory
accesses and memory barriers?


</p><p><b>Answer</b>:
Because the goal of the Linux-kernel memory model's RCU is not to
emulate some specific
RCU implementation, but rather to closely approximate what might be called
<a href="https://en.wikipedia.org/wiki/Platonism">platonic</a>
RCU, thereby providing precise semantics without unnecessarily constraining
implementations.
All known concrete RCU implementations provide stronger semantics than
the Linux-kernel memory model's RCU (let alone
platonic RCU), but different implementations are stronger in different ways.
For example, SRCU uses read-side memory barriers on the one hand and
Tree RCU has elaborate and extremely strong update-side ordering
on the other.

<p>
The following litmus test is a case in point:

<blockquote>
<a id="litmus18" href="C-rcu-relacq1.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#18</a>
<pre>
  1 C C-rcu-relacq1.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x)
  7 {
  8   WRITE_ONCE(*x, 1);
  9 }
 10
 11 P1(int *x, int *y)
 12 {
 13   rcu_read_lock();
 14   r0 = READ_ONCE(*x);
 15   rcu_read_unlock();
 16   smp_wmb();
 17   WRITE_ONCE(*y, 1);
 18 }
 19
 20 P2(int *x, int *y)
 21 {
 22   r0 = READ_ONCE(*y);
 23   smp_rmb();
 24   r1 = READ_ONCE(*x);
 25 }
 26
 27 exists
 28 (1:r0=1 /\ 2:r0=1 /\ 2:r1=0)
</pre>
</blockquote>

<p>
Because there are no RCU grace periods, the RCU read-side critical sections
have no effect on ordering, which means that the cycle in this litmus
test is allowed:

<blockquote>
<a id="litmus18" href="C-rcu-relacq1.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#18</a>
<pre>
 1 Test C-rcu-relacq1 Allowed
 2 States 8
 3 1:r0=0; 2:r0=0; 2:r1=0;
 4 1:r0=0; 2:r0=0; 2:r1=1;
 5 1:r0=0; 2:r0=1; 2:r1=0;
 6 1:r0=0; 2:r0=1; 2:r1=1;
 7 1:r0=1; 2:r0=0; 2:r1=0;
 8 1:r0=1; 2:r0=0; 2:r1=1;
 9 1:r0=1; 2:r0=1; 2:r1=0;
10 1:r0=1; 2:r0=1; 2:r1=1;
11 Ok
12 Witnesses
13 Positive: 1 Negative: 7
14 Condition exists (1:r0=1 /\ 2:r0=1 /\ 2:r1=0)
15 Observation C-rcu-relacq1 Sometimes 1 7
16 Hash=9878b5f38ed2ce07a4954babadec09e3
</pre>
</blockquote>

<p>
But suppose we translate the RCU primitives to normal accesses using
<a href="https://github.com/paulmckrcu/litmus/blob/master/RCUxlate/RCUrelacq.sh">Alan Stern's release-acquire transformation script</a>,
which adds a release store to
a <tt>csend01</tt> variable to the end of the RCU read-side critical section:

<blockquote>
<a id="litmus19" href="C-rcu-relacq1-relacq.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#19</a>
<pre>
  1 C C-rcu-relacq1-relacq.litmus
  2
  3 {
  4 }
  5
  6 P0(int *x)
  7 {
  8   WRITE_ONCE(*x, 1);
  9 }
 10
 11 P1(int *x, int *y, int *csend01)
 12 {
 13   r0 = READ_ONCE(*x);
 14   smp_store_release(csend01, 1);
 15   smp_wmb();
 16   WRITE_ONCE(*y, 1);
 17 }
 18
 19 P2(int *x, int *y)
 20 {
 21   r0 = READ_ONCE(*y);
 22   smp_rmb();
 23   r1 = READ_ONCE(*x);
 24 }
 25
 26 exists
 27 (1:r0=1 /\ 2:r0=1 /\ 2:r1=0)
</pre>
</blockquote>

<p>
This transformation is correct for most RCU-related
litmus tests, but incorrectly prohibits the cycle in
<a href="#litmus18">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#18</a>:

<blockquote>
<a id="litmus19" href="C-rcu-relacq1-relacq.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#19</a>
<pre>
 1 Test C-rcu-relacq1-relacq Allowed
 2 States 7
 3 1:r0=0; 2:r0=0; 2:r1=0;
 4 1:r0=0; 2:r0=0; 2:r1=1;
 5 1:r0=0; 2:r0=1; 2:r1=0;
 6 1:r0=0; 2:r0=1; 2:r1=1;
 7 1:r0=1; 2:r0=0; 2:r1=0;
 8 1:r0=1; 2:r0=0; 2:r1=1;
 9 1:r0=1; 2:r0=1; 2:r1=1;
10 No
11 Witnesses
12 Positive: 0 Negative: 7
13 Condition exists (1:r0=1 /\ 2:r0=1 /\ 2:r1=0)
14 Observation C-rcu-relacq1-relacq Never 0 7
15 Hash=947aeac1dc0f87ac9796edfcadc8bb4a
</pre>
</blockquote>

<p>
As far as we know, it is not possible to produce a transformation from
RCU primitives to normal memory accesses that exactly implements
the Linux kernel memory model's RCU.
There is a transformation that works in all known cases, but:
(1)&nbsp;It requires &ldquo;ghost&rdquo; memory accesses that are
unaffected by normal memory barriers,
(2)&nbsp; It requires &ldquo;ghost-buster&rdquo; memory barriers that
order all accesses, including ghost accesses, and
(3)&nbsp;We don't have a proof that it exactly matches the Linux
kernel memory model's RCU.

<p>
In addition, model performance is quite important.
After all, developers need answers in seconds or minutes, not days or weeks.
The scalability of the Linux-kernel memory model's RCU code and of the
release-acquire transformation are shown in the following table,
with each cell linking to the corresponding litmus test:

<table cellpadding="3" border=3 align="center"><tbody>
<tr><th rowspan=3>Transform</th>
	<th colspan=9>Number of Grace Periods and Critical Sections</th>
</tr>
<tr>	<td colspan=9 align="center">(Execution times in CPU-seconds)</td>
</tr>
<tr>
	<th align="right">1</th>
		<th align="right">2</th>
			<th align="right">3</th>
				<th align="right">4</th>
					<th align="right">5</th>
						<th align="right">6</th>
							<th align="right">7</th>
								<th align="right">8</th>
									<th align="right">9</th>
</tr>
<tr><td>Linux Kernel Memory Model's RCU</td>
	<td align="right"><a href="perf/C-RW-G+RW-R.litmus">0.00</a></td>
		<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R.litmus">0.02</a></td>
			<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">0.11</a></td>
				<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">0.68</a></td>
					<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">3.65</a></td>
						<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">22.30</a></td>
							<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">111.89</a></td>
								<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">1,020.01</a></td>
									<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">4,259.7</a></td>
</tr>
<tr><td>Release-Acquire RCU</td>
	<td align="right"><a href="perf/C-RW-G+RW-R-relacq.litmus">0.03</a></td>
		<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R-relacq.litmus">22.96</a></td>
			<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R-relacq.litmus">331,152.43</a></td>
</tr>
</tbody></table>

<p>
Given these performance results, we hypothesize that the vast majority
of developers would prefer to use the Linux kernel memory model's RCU, which
provides reasonable response time even for unreasonable 14-process
litmus tests with seven grace periods and seven critical sections.
Even a more-unreasonable 18-process litmus test with nine grace
periods and nine critical sections completes in about an hour.
In contrast, the release-acquire requires several <i>days</i> of CPU time,
even for an eminently reasonable litmus test with only six processes.

<p>
However, the above performance results ran with the default <tt>herd</tt>
behavior,
in which it computes and lists all possible final states.
Many developers would instead be interested only in whether or not the
final state indicated by the &ldquo;<tt>exists</tt>&rdquo; clause is
reachable.
The &ldquo;<tt>-speedcheck fast</tt>&rdquo; command-line argument tells
<tt>herd</tt> to check only for that final state, which results in the
large speedups shown in the following table:

<table cellpadding="3" border=3 align="center"><tbody>
<tr><th rowspan=3>Transform</th>
	<th colspan=9>Number of Grace Periods and Critical Sections</th>
</tr>
<tr>	<td colspan=9 align="center">(Execution times in CPU-seconds with &ldquo;<tt>-speedcheck fast</tt>&rdquo;)</td>
</tr>
<tr>
	<th align="right">1</th>
		<th align="right">2</th>
			<th align="right">3</th>
				<th align="right">4</th>
					<th align="right">5</th>
						<th align="right">6</th>
							<th align="right">7</th>
								<th align="right">8</th>
									<th align="right">9</th>
</tr>
<tr><td>Linux Kernel Memory Model's RCU</td>
	<td align="right"><a href="perf/C-RW-G+RW-R.litmus">0.00</a></td>
		<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R.litmus">0.00</a></td>
			<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">0.01</a></td>
				<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">0.03</a></td>
					<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">0.20</a></td>
						<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">1.06</a></td>
							<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">5.46</a></td>
								<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">27.62</a></td>
									<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R+RW-G+RW-R.litmus">139.83</a></td>
</tr>
<tr><td>Release-Acquire RCU</td>
	<td align="right"><a href="perf/C-RW-G+RW-R-relacq.litmus">0.00</a></td>
		<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R-relacq.litmus">1.33</a></td>
			<td align="right"><a href="perf/C-RW-G+RW-R+RW-G+RW-R+RW-G+RW-R-relacq.litmus">8,940.16</a></td>
</tr>
</tbody></table>

<p>
Here, the Linux-kernel memory model's RCU completes in reasonable time all
the way out to the 18-process monster, which takes a little more than two
minutes to complete.
Although the release-acquire RCU runs much faster with
&ldquo;<tt>-speedcheck fast</tt>&rdquo; than without, it still takes
more than two hours for the six-process litmus test (three grace periods
and three critical sections), which is not at all suitable for interactive use.
One problem is that release-acquire RCU has twice as many variables
as does the Linux-kernel memory model's RCU, second problem is that the
release-acquire RCU has <tt>(N+1)</tt> times as many reads as
does the Linux-kernel memory model's RCU, and a final problem
is that release-acquire RCU's litmus tests have a complex
&ldquo;<tt>exists</tt>&rdquo;
clause, while in contrast the Linux-kernel memory model's RCU's
litmus tests all have simple disjunctions.
Roughly speaking, the overhead of the former increases as the factorial
of the number of variables, while the latter two increases as two to the
power of the number of reads.

<p>
All of these considerations motivated us to include RCU directly in
the Cat model, rather than relying on scripted translations of RCU
primitives to memory accesses and memory barriers.


</p><p><a href="#Quick%20Quiz%2029"><b>Back to Quick Quiz 29</b>.</a>

<a name="qq30answer"></a>
<p><b>Quick Quiz 30</b>:
But <tt>rcu-order</tt> could be the empty relationship,
so that it would directly connect what preceded it with what followed it.
How can that be right?


</p><p><b>Answer</b>:
It is not just right, but absolutely necessary.
This permits a pair of consecutive grace periods to do the right thing.
For example, consider the following litmus test, where, as usual,
<tt>a</tt>, <tt>b</tt>, and&nbsp;<tt>c</tt> are initially all zero:

<blockquote>
<a id="litmus20" href="C-LB+o-sync-sync-o+rl-o-o-rul+rl-o-o-rul.litmus">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#20</a>
<pre>
  1 C C-LB+o-sync-sync-o+rl-o-o-rul+rl-o-o-rul.litmus
  2
  3 {
  4 }
  5
  6 P0(int *a, int *b)
  7 {
  8   int r1;
  9
 10   r1 = READ_ONCE(*a);
 11   synchronize_rcu();
 12   synchronize_rcu();
 13   WRITE_ONCE(*b, 1);
 14 }
 15
 16 P1(int *b, int *c)
 17 {
 18   int r2;
 19
 20   rcu_read_lock();
 21   r2 = READ_ONCE(*b);
 22   WRITE_ONCE(*c, 1);
 23   rcu_read_unlock();
 24 }
 25
 26 P2(int *c, int *a)
 27 {
 28   int r3;
 29
 30   rcu_read_lock();
 31   r3 = READ_ONCE(*c);
 32   WRITE_ONCE(*a, 1);
 33   rcu_read_unlock();
 34 }
 35
 36 exists
 37 (0:r1=1 /\ 1:r2=1 /\ 2:r3=1)
</pre>
</blockquote>

<p>
If <tt>rcu-order</tt> did not permit an empty relationship,
the pair of <tt>synchronize_rcu()</tt> invocations on lines&nbsp;4 and&nbsp;5
would not be serialized, but would instead effectively merge into a
single <tt>synchronize_rcu()</tt>.
Thus, the possibility of an empty <tt>rcu-order</tt> is
absolutely required to forbid the undesirable outcome
<tt>r1&amp;&amp;r2&amp;&amp;r3</tt>:

<blockquote>
<a id="litmus20" href="C-LB+o-sync-sync-o+rl-o-o-rul+rl-o-o-rul.litmus"> Outcome for Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#20</a>
<pre>
 1 Test C-LB+o-sync-sync-o+rl-o-o-rul+rl-o-o-rul Allowed
 2 States 7
 3 0:r1=0; 1:r2=0; 2:r3=0;
 4 0:r1=0; 1:r2=0; 2:r3=1;
 5 0:r1=0; 1:r2=1; 2:r3=0;
 6 0:r1=0; 1:r2=1; 2:r3=1;
 7 0:r1=1; 1:r2=0; 2:r3=0;
 8 0:r1=1; 1:r2=0; 2:r3=1;
 9 0:r1=1; 1:r2=1; 2:r3=0;
10 No
11 Witnesses
12 Positive: 0 Negative: 7
13 Condition exists (0:r1=1 /\ 1:r2=1 /\ 2:r3=1)
14 Observation C-LB+o-sync-sync-o+rl-o-o-rul+rl-o-o-rul Never 0 7
15 Hash=44ee0f607659a74ea40149d1ca3d80f5
</pre>
</blockquote>


</p><p><a href="#Quick%20Quiz%2030"><b>Back to Quick Quiz 30</b>.</a>

<a name="qq31answer"></a>
<p><b>Quick Quiz 31</b>:
Why does
<a href="#litmus15">Strong&nbsp;Model&nbsp;Litmus&nbsp;Test&nbsp;#15</a>'s
<tt>exists</tt> clause specify <tt>0:r1=x</tt>?
Isn't the second clause (<tt>0:r2=1</tt>) forbidden in and of itself?


</p><p><b>Answer</b>:
Try it and see what happens!


</p><p><a href="#Quick%20Quiz%2031"><b>Back to Quick Quiz 31</b>.</a>


</p><p>
           
</div> <!-- ArticleText -->
<p><a name="Comments"></a>


</div><!-- Printable -->
</td> <!-- MC -->
</tr></table></td>
</tr></table><!-- endpage -->
            
        </body></html>
        
